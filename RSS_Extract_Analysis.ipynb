{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ff468e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: feedparser in /home/karenguzman/.local/lib/python3.10/site-packages (6.0.12)\n",
      "Requirement already satisfied: sgmllib3k in /home/karenguzman/.local/lib/python3.10/site-packages (from feedparser) (1.0.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bs4 in /home/karenguzman/.local/lib/python3.10/site-packages (0.0.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/karenguzman/.local/lib/python3.10/site-packages (from bs4) (4.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/karenguzman/.local/lib/python3.10/site-packages (from beautifulsoup4->bs4) (4.15.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/karenguzman/.local/lib/python3.10/site-packages (from beautifulsoup4->bs4) (2.6)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement urllib.parse (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for urllib.parse\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install feedparser\n",
    "!pip install bs4\n",
    "!pip install urllib.parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d0be89",
   "metadata": {},
   "source": [
    "First using Feedparser to get links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7ee24b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Intro DS Syllabi at 2-year Colleges', 'https://docs.google.com/spreadsheets/d/1wihCoaD5Ei-11kxzowDjp_v0gXX5LNb_DdXwsBswknw/edit?gid=0#gid=0'), ('Introduction to Data Science | University of Stavanger', 'https://www.uis.no/en/course/DAT540_1'), ('Open Access Data Science Resource by Data Science Discovery at the University of Illinois', 'https://discovery.cs.illinois.edu/'), ('Columbia | Foundations of Data Science: Syllabus', 'https://www.columbia.edu/~cs2035/courses/orca2500.S18/syllabus.html'), ('Delta College MTH 225 - Introduction to Data Science - Modern Campus Catalog™', 'https://catalog.delta.edu/preview_course_nopop.php?catoid=15&coid=31564'), ('Data Science (DS) 210 | Johnson County Community College Catalog', 'https://catalog.jccc.edu/coursedescriptions/ds/#DS_210'), ('Undergrad Intro DS Syllabi', 'https://docs.google.com/spreadsheets/d/1HTnAukzyXh0wM411MMeiNjR-O1sXTmIwX8GqzQgPxIY/edit?gid=0#gid=0'), ('C S 8A: INTRODUCTION TO DATA SCIENCE Foothill College', 'https://catalog.foothill.edu/course-outlines/C-S-8A/'), ('Smith Syllabus SDS 192: Interterm 2021', 'https://beanumber.github.io/sds192/syllabus.html'), ('Introduction to Data Science Graduate Certificate: Loyola University Chicago', 'https://catalog.luc.edu/undergraduate/continuing-professional-studies/introduction-data-science-certificate/#curriculumtext'), ('INFO 2950 - Syllabus | Cornell', 'https://info2950.infosci.cornell.edu/course-syllabus.html'), ('Syllabus — Foundations of Data Science (2023) | CUNY', 'https://gofilipa.github.io/fds-spring-23/syllabus.html'), ('ECE 4803: Mathematical Foundations of Data Science (2020) | Georgia Tech', 'https://mdav.ece.gatech.edu/ece-4803-fall2020/'), ('Syllabus | Introduction to Data Science | LSU', 'https://introdatasci.dlilab.com/syllabus/'), ('MIT OpenCourseWare Syllabus | Introduction to Computational Thinking and Data Science | Electrical Engineering and Computer Science', 'https://ocw.mit.edu/courses/6-0002-introduction-to-computational-thinking-and-data-science-fall-2016/pages/syllabus/'), ('Princeton ORF 525: Statistical Foundations of Data Science', 'https://fan.princeton.edu/fan/classes/525.html'), ('Intro to Data Science Syllabus | UC San Diego', 'https://dsc10.com/syllabus/'), ('STAT 107 (Spring 2022): Data Science Discovery at The University of Illinois', 'https://discovery.cs.illinois.edu/stat107-sp22/'), ('CSE 180 Intro to Data Science, Spring 2019 - Syllabus | University of Washington', 'https://courses.cs.washington.edu/courses/cse180/21sp/syllabus/#syllabus'), ('Washington State University | Intro to Data Science (2015)', 'https://eecs.wsu.edu/~assefaw/CptS483-06/'), ('Syllabus | Intro to Data Science | William & Mary (2021)', 'https://ds-wm.github.io/course/intro/syllabus/index.html'), ('University of Zurich | Department of Informatics | Foundations of Data Science (Graduate)', 'https://www.ifi.uzh.ch/en/dast/teaching/FDS.html'), ('DSCI 101 : Foundations of Data Science I | Oregon University School of Computer and Data Sciences', 'https://scds.uoregon.edu/ds/undergraduate-program/courses/dsci-101'), ('International Data Science in Schools Project', 'http://www.idssp.org/pages/purpose.html'), ('UVA DS1001: Repo for Foundations of Data Science', 'https://github.com/UVADS/DS1001'), ('15.1 Introduction to data science | OpenStax', 'https://openstax.org/books/introduction-python-programming/pages/15-1-introduction-to-data-science'), ('DSC 10 | Principles of Data Science at UCSD', 'https://dsc10.com/'), ('STA 199 - Introduction to Data Science | Mine Çetinkaya-Rundel', 'https://mine-cr.com/teaching/sta199/'), ('Introduction to Data Science Curriculum | UCLA', 'https://www.ucladatascienceed.org/introduction-to-data-science-curriculum'), ('Introduction to Data Science | UC Berkeley', 'https://amplab.github.io/datascience-sp14/'), ('University of Amersterdam Introduction Data Science: Data Preprocessing (6011P0286Y)', 'https://github.com/doanthevu1910/uva-introduction-data-science'), ('UC Berkeley Data 8', 'http://www.data8.org/')]\n",
      "Found 32 entries\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "feed = feedparser.parse('https://bg.raindrop.io/rss/public/47223284')\n",
    "\n",
    "print([(e.title, e.link) for e in feed.entries])\n",
    "print(f\"Found {len(feed.entries)} entries\")\n",
    "\n",
    "entries = []\n",
    "#entries is now our URL list from RSS feed\n",
    "for e in feed.entries:\n",
    "    title = getattr(e, \"title\", \"\")\n",
    "    link = getattr(e, \"link\", \"\")\n",
    "    entries.append({\"title\":title, \"link\":link})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72b94fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "def extract_text_from_url(url) -> dict:\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Ensure we notice bad responses\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # Remove script and style elements\n",
    "    for tag in soup(['script', 'style']):\n",
    "        tag.decompose()\n",
    "\n",
    "    # Get text\n",
    "    text = soup.get_text(separator='\\n')\n",
    "    lines = [line.strip() for line in text.splitlines() if line.strip()]\n",
    "\n",
    "    return {\n",
    "        \"url\": url,\n",
    "        \"text\": \"\\n\".join(lines)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16b492fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to extract https://www.columbia.edu/~cs2035/courses/orca2500.S18/syllabus.html: 403 Client Error: Forbidden for url: https://www.columbia.edu/~cs2035/courses/orca2500.S18/syllabus.html\n",
      "Failed to extract https://fan.princeton.edu/fan/classes/525.html: 403 Client Error: Forbidden for url: https://fan.princeton.edu/fan/classes/525.html\n"
     ]
    }
   ],
   "source": [
    "urls = [entry['link'] for entry in entries]\n",
    "\n",
    "with open('rss_extracted_texts.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for url in urls:\n",
    "        try:\n",
    "            extracted = extract_text_from_url(url)\n",
    "            f.write(json.dumps(extracted, ensure_ascii=False) + '\\n')\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract {url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d3b9ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 30 documents.\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "with open('rss_extracted_texts.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        docs.append(json.loads(line)[\"text\"])\n",
    "print(f\"Extracted {len(docs)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5af5506e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intro ds syllabi at 2year colleges  google sheets javascript isnt enabled in your browser so this file cant be opened enable and reload this browser version is no longer supported please upgrade to a supported browser intro ds syllabi at 2year colleges tab external share sign in file edit view insert format data tools extensions help accessibility debug unsaved changes to drive accessibility view only loading a b c d e f g h i j k l m n o p q r s t u v w x y z 1 course name department college pr\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def clean_text(t):\n",
    "    t = t.lower()\n",
    "    t = re.sub(r'\\s+', ' ', t)  # Replace multiple whitespace with single space\n",
    "    t = re.sub(r'[^a-z0-9\\s]', '', t)  # Remove non-alphanumeric characters\n",
    "    return t.strip()\n",
    "cleaned_docs = [clean_text(doc) for doc in docs]\n",
    "print(cleaned_docs[0][:500])  # Print first 500 characters of the first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dee0d1a",
   "metadata": {},
   "source": [
    "TF-IDF to see dominant terms per course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "660b4cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   term     tfidf\n",
      "1308               data  0.193209\n",
      "3931            science  0.079908\n",
      "1235             course  0.076207\n",
      "1344       data science  0.070035\n",
      "4406           students  0.053151\n",
      "1027              class  0.045188\n",
      "641         assignments  0.041192\n",
      "3655             python  0.039753\n",
      "2493                lab  0.037275\n",
      "4817                use  0.034547\n",
      "1067               code  0.033417\n",
      "2584           learning  0.031096\n",
      "2377       introduction  0.030351\n",
      "2085           homework  0.028954\n",
      "3626            project  0.027242\n",
      "2112              hours  0.027191\n",
      "930             catalog  0.025981\n",
      "491            analysis  0.025846\n",
      "1733              final  0.024902\n",
      "628          assignment  0.024622\n",
      "2615            lecture  0.024401\n",
      "4939               work  0.024232\n",
      "2168                ids  0.024187\n",
      "4916               week  0.024007\n",
      "3615        programming  0.023897\n",
      "4832              using  0.023799\n",
      "2380  introduction data  0.023188\n",
      "1146           computer  0.023009\n",
      "3590        probability  0.022977\n",
      "373            academic  0.022905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features = 5000,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(cleaned_docs)\n",
    "\n",
    "#top terms globally\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "tfidf_means = X.mean(axis=0).A1\n",
    "\n",
    "top = pd.DataFrame({\n",
    "    'term': feature_names,\n",
    "    'tfidf': tfidf_means\n",
    "}).sort_values(by='tfidf', ascending=False).head(30)\n",
    "\n",
    "print(top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
