{"url": "https://docs.google.com/spreadsheets/d/1wihCoaD5Ei-11kxzowDjp_v0gXX5LNb_DdXwsBswknw/edit?gid=0#gid=0", "text": "Intro DS Syllabi at 2-year Colleges - Google Sheets\nJavaScript isn't enabled in your browser, so this file can't be opened. Enable and reload.\nThis browser version is no longer supported. Please upgrade to a supported browser.\nIntro DS Syllabi at 2-year Colleges\nTab\nExternal\nShare\nSign in\nFile\nEdit\nView\nInsert\nFormat\nData\nTools\nExtensions\nHelp\nAccessibility\nDebug\nUnsaved changes to Drive\nAccessibility\nView only\nLoading...\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\nK\nL\nM\nN\nO\nP\nQ\nR\nS\nT\nU\nV\nW\nX\nY\nZ\n1\nCourse Name\nDepartment\nCollege\nPrereqs\nProgram Language\nNotes\nLink to Syllabi or Program\nLink to Program\n2\nSTAT 101: Introduction to Data Science\nMath\nJoliet Junior College\nNA\nR\nData overview; tools; summary data; ethics and data sources; ethics in research; hypotheses; data analysis life cycle; data viz; data presentation\nhttps://drive.google.com/file/d/14CFEfWblmLuPXLUDPf5GgFSx-lYssjec/view?usp=sharing\n3\nCSC-124: Introduction to Data Science Programming\nCS\nWakeTech\nNA\nnoSQL\nScripting languages, noSQL databases, database scalability, performance metrics and tuning. Upon completion, students should be able to use programming techniques to investigate data sets and algorithms.\nhttps://www.waketech.edu/programs-courses/credit/data-science/class-descriptions\n4\nMAT-235 Introduction to Data Science\nMath\nAnne Arundel Community College\nC or better in any college level math course or\nCTP-160 Python\nPython\nTopics include causality, single and multivariable data manipulation, data visualization and generation, statistical inference, statistical modeling, and machine learning.\nhttps://www.aacc.edu/course-search/course/introduction-to-data-science.php\n5\nCE-COMP 2239 - Intro to Machine Learning and Data Science featuring Python (Workforce Certificate)\nSUNY Westchester Community College\nNA\nPython, SQL\nFoundations of problem solving, statistical algorithms, and machine learning models using Jupyter Notebooks within the Anaconda, Visual Studio Code, and Google Colab programming environments. Also basics of SQL databases as data sources and Docker containerization platform for model deployment.\nhttps://www.sunywcc.edu/academics/majors-programs/introduction-to-data-science-and-machine-learning/\n6\nDATA 101 Introduction to Data Science\nMath, Stats, Data Science\nMontgomery College\nC or better in\nMATH 117\n/\nMATH 117A\n,\nMATH 217\n,\nBSAD 210\nR\nhttps://www.montgomerycollege.edu/_documents/offices/eass/data-101-syllabus.pdf\nhttps://catalog.montgomerycollege.edu/preview_course_nopop.php?catoid=8&coid=11413\n7\nCSC 221 - Introduction to Problem Solving and Programming\nScience, Math, & Engineering\nLaurel Ridge Community College\nMTH 245\n&\nMTH 263\nNA\nFirst of three-course sequence (CSC 221, CSC 222, CSC 223) which focuses on mathematical problem solving skills, algebraic modeling and functions, and use of variables.\nhttps://laurelridge.edu/degree/science-computational-and-data-science-major/\n8\nITD 145 Applied Data Science Techniques\nIT\nNorth Virginia Community College\nNone\nPython\nReviews the fundamentals of descriptive and inferential statistics, probability, and distributions, as well as basic dataset manipulation and plotting techniques. Focuses on application to real datasets using graphical user interface (GUI) software tools as well as Python\nhttps://www.nvcc.edu/courses/itd/itd145.html\n9\nDSC 141 Data Science I Fundamentals\nDivision of Math, Engineering Technology and Computer Science\nEssex County College\nC or better in CSC 121\nand\nMTH 101\nNA\nData acquisition, cleaning and transformation, visualization, and distribution\nhttps://catalog.essex.edu/about-academic-divisions/math-engineering-technology-computer-science-division/computer-science-data-science-as/\n10\nINFO 2646 - Introduction to Data Science\nIT\nMetropolitan Community College\nMATH 1410\nR\nData science project lifecycle, data wrangling, data viz and exploration, clustering, classification, regression, ML, NN\nhttps://mycatalog.mccneb.edu/preview_program.php?catoid=22&poid=6892\n11\nMATH 261: Introduction to Data Science\nMath and CS\nDrury University\nMATH 227 and CSCI 152\nNA\nData acquisition, cleaning of data, transformation of data, analysis of data, and interpretation of data. Analysis of data includes an introduction to both statistical and machine learning techniques.\nhttps://www.drury.edu/course/introduction-to-data-science/\n12\nMTH 225 - Introduction to Data Science\nMath and CS\nDelta College\nMTH 208W\nor\nMTH 208AW\nor\nMTH 209W\nor\nMTH 209AW\nmay be taken previously or concurrently.\nSQL\nProgramming/algorithms; statistical analysis and data viz; modeling; data wrangling; databases and data management; communication\nhttps://catalog.delta.edu/preview_course_nopop.php?catoid=15&coid=31564\n13\nDAT101: Introduction to Data Science\nMath\nCape Cod Community College\nMAT150\nR\nData collection, exploratory data analysis, predictive modeling, and effective communication\nCCCC-DAT101-Introduction-to-Data-Science-2023.pdf\n14\nDSCI 101 Introduction to Data Science\nComputer | Math | Data\nHarford College\nNone\nR\nData wrangling, cross-validation, inference\nhttps://catalog.harford.edu/programs-study-majors/degrees/datascience-as/#programrequirementstext\n15\nDS 210 Introduction to Data Science\nData Science Program\nJohnson County Community College\nNA\nNA\nData science/big data; ethics; data science life cycle; data sources and storage; ETL process; ETL programming; real world problems and solutions; communication\nhttps://catalog.jccc.edu/coursedescriptions/ds/\n16\nDS 150: Data Intuition and Insight\nMath\nBrigham Young University-Idaho\nNA\nNone\nhttps://byuidatascience.github.io/services/ds150/\n17\nCOP1044 Introduction to Data Science Using Python\nApplied Sciences and Technology Division\nTallahassee State College\nCOP1000\nPython\nPython for basic statistics, the NumPy module for manipulation of array-based data, Pandas for manipulation of heterogeneous and labeled data, Matplotlib for publication-quality visualizations, and IPython for interactive execution and sharing of code\nhttps://catalog.tsc.fl.edu/preview_program.php?catoid=22&poid=2519\n18\nDAT 1001 | Introduction to Data Science\nCommunity College of Denver\nNone\nNA\nData collection, data wrangling and storage, inference statistics, and data viz.\nhttps://catalog.ccd.edu/programs-courses/courses/dat/\n19\nDAT 1001 | Introduction to Data Science\nFrontrage Community College\nNone\nNA\nData collection, data wrangling and storage, inference statistics, and data viz.\nhttps://frontrange.smartcatalogiq.com/en/current/catalog/courses/dat-data-science/1000/dat-1001\n20\nMATH 211 Introduction to Data Science\nMath\nSkyline College\nNone\nPython\nhttps://catalog.skylinecollege.edu/current/courses/mathematics/math-211.php\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\nQuotes are not sourced from all markets and may be delayed up to 20 minutes. Information is provided 'as is' and solely for informational purposes, not for trading purposes or advice.\nDisclaimer\nRead me\nSyllabi\nClosest Equivalents if no DS\nA browser error has occurred.\nPlease hold the Shift key and click the Refresh button to try again."}
{"url": "https://www.uis.no/en/course/DAT540_1", "text": "Establishing a secure connection ...\nHold tight\nWe are establishing a secure\nconnection.\nThis website is using a security service to protect\nitself from online attacks. We are checking your browser\nto establish a secure connection and keep you safe.\n...\nPlease enable JavaScript to continue.\nRequest ID:\n21f47924c3a03b8714ad31d1a16ad1a5"}
{"url": "https://discovery.cs.illinois.edu/", "text": "Welcome to Data Science Discovery! - Data Science Discovery\nData Science Discovery\nUniversity of Illinois Urbana-Champaign\nHome\nLearn\nMicroProjects\nGuides\nSyllabus\nAbout\nData Science\nDISCOVERY\nAn open-access data science resource with a mission to create the most valuable Data Science resource available, as a public good from The University of Illinois.\nProfessor-Guided Lessons and Practice Problems\nLearn Data Science with Professors Wade Fagen-Ulmschneider and Karle Flanagan that contain written explanations, example worksheets, practice questions, and more!\nStart with Lecture #1: \"What is Data Science?\"\nView All 43 Lessons â\nMicroProjects: Real Data Science in Under an Hour\nGuided, detailed projects that provide \"micro\" exploration of a new dataset. Each MicroProject is designed to give you a real data science experience in Python in under an hour!\nStart with\n#1:Trends in High School GPAs\nView All MicroProjects â\nGuides for Common Data Science Techniques\nShort, solution-focused examples of common tasks in Data Science. We create several new guides each week, so there is constantly something new!\nGuide:\n3 Ways to Calculate the RMSE in Python\n(New!)\nGuide:\nRemoving Duplicates From a DataFrame\nGuide:\nPython Data Types\nView All 34 Guides â\nDatasets for Your Own Projects\nClean, documented, and relevant datasets for Data Science. As we use a new dataset in any of our courses or research, we add the dataset here for you to use!\nDataset:\nPerception of Probability Words Dataset\n(New!)\nDataset:\nCourse Catalog Dataset\nView All 18 Datasets â\nLearn Data Science!\nModule 1: Basics of Data Science with Python\n\"Basics of Data Science with Python\" provides a strong introduction of the field of Data Science. You will understand best practices in designing good, great, and ideal experiments, use Python to load data into DataFrame, and manipulate DataFrames in Python to explore subsets of data.\n1-01\nÂ»\nWhat is Data Science?\n1-02\nÂ»\nPython for Data Science: Introduction to DataFrames\n1-03\nÂ»\nRow Selection with DataFrames\n1-04\nÂ»\nTypes of Data\n1-05\nÂ»\nDataFrames with Conditionals\n1-06\nÂ»\nExperimental Design and Blocking\n1-07\nÂ»\nObservational Studies, Confounders, and Stratification\n1-08\nÂ»\nLists and Functions in Python\nModule 2: Exploratory Data Analysis\n\"Exploratory Data Analysis\" teaches about the tools and techniques to begin to do exploratory data analysis on real-world datasets. You will learn several methods of analyzing statistical properties of the data and how to calculate and apply these properties using Python. Finally, you will create simple data visualizations showing an overview of the data.\n2-01\nÂ»\nExploratory Data Analysis Overview\n2-02\nÂ»\nDescriptive Statistics\n2-03\nÂ»\nAdding Rows and Columns to a DataFrame\n2-04\nÂ»\nGrouping Data in Python\n2-05\nÂ»\nHistograms\n2-06\nÂ»\nQuartiles and Box Plots\n2-07\nÂ»\nBasic Data Visualization in Python\nModule 3: Simulation and Distributions\n\"Simulation and Distributions\" provides an exploration into the world of computer simulations. Beginning with simulating simple events, like rolling a dice where the expected outcome is known, you gradually build increasingly complex simulations. You will find many simulations result in common distributions, such as the Normal Distribution, which you will learn has many interesting properties all its own.\n3-01\nÂ»\nOverview of Simulation\n3-02\nÂ»\nRandom Numbers in Python\n3-03\nÂ»\nFor-Loops in Python\n3-04\nÂ»\nSimple Simulations in Python\n3-05\nÂ»\nSample Space\n3-06\nÂ»\nConditionals in Python\n3-07\nÂ»\nFunctions in Python\n3-08\nÂ»\nNormal Distribution\n3-09\nÂ»\nLaw of Large Numbers\nModule 4: Prediction and Probability\n\"Prediction and Probability\" begins with a deep-dive into probability and using probabilities to make informed predictions on future events. You will complete dozens of problems on basic probability, explore how to describe dependent probabilistic events, and use Python to make predictions under uncertainty.\n4-01\nÂ»\nProbability Introduction\n4-02\nÂ»\nMulti-event Probability: Multiplication Rule\n4-03\nÂ»\nComplements and Special Cases\n4-04\nÂ»\nMulti-event Probability: Addition Rule\n4-05\nÂ»\nConditional Probability\n4-06\nÂ»\nBayes' Theorem\nModule 5: Towards Machine Learning\n\"Towards Machine Learning\" applies all of the foundational knowledge applied in the previous modules to using modern techniques to help computers discover common similarities in data and to predict future outcomes based on previously-seen events. Completion of this and all other modules provides you with the ability to advance to dedicated machine learning courses.\n5-01\nÂ»\nOverview of Machine Learning\n5-02\nÂ»\nCorrelation\n5-03\nÂ»\nSimple Linear Regression\n5-04\nÂ»\nLinear Regression in Python (sk-learn)\n5-05\nÂ»\nTest/Train Split\n5-07\nÂ»\nClustering\nModule 6: Polling, Confidence Intervals, and the Normal Distribution\n\"Polling, Confidence Intervals, and the Normal Distribution\" starts with an exploration of different sampling techniques. You will learn how bias and sampling variability can affect the results of surveys. From that, you know how to use expectation and inference as a way to make predictions and decisions under uncertainty.\n6-01\nÂ»\nRandom Variables\n6-02\nÂ»\nBernoulli & Binomial Random Variables\n6-03\nÂ»\nPython Functions for Random Distributions\n6-04\nÂ»\nCentral Limit Theorem\n6-05\nÂ»\nPolling and Sampling\n6-06\nÂ»\nConfidence Intervals\n6-07\nÂ»\nHypothesis Testing\nData Science Discovery is an open-source data science resource created by The University of Illinois with support from The Discovery Partners Institute, the College of Liberal Arts and Sciences, and The Grainger College of Engineering. The aim is to support basic data science literacy to all through clear, understandable lessons, real-world examples, and support."}
{"url": "https://catalog.delta.edu/preview_course_nopop.php?catoid=15&coid=31564", "text": "MTH 225 - Introduction to Data Science -\nJavascript is currently not supported, or is disabled by this browser. Please enable Javascript for full functionality.\nSkip to Content\nPlease enable JavaScript to view this page.\nPlease enable JavaScript to view this page.\nPlease enable JavaScript to view this page.\nPlease enable JavaScript to view this page.\nAcademics\nAcademic Calendar\nAcademic Resources\nAccreditations\nCatalog\nConvenience\nDegrees & Certificates\nEngaged Learning\nExplore Courses\nExplore Programs\nFaculty\nOnline Learning\nSearch for Classes\nTransfer\nAdmissions & Aid\nFuture Students\nCosts & Financial Aid\nServices & Support\nAcademic Advising\nCareer Services\nCounseling Services\nDisability Resources\nCosts & Financial Aid\nLibrary\nRegistration\nSafety Services\nTesting\nTranscripts\nTutoring\nVeteran Services\nWriting & Presentation Support\nCampus Life\nArt\nAthletics\nChoirs\nClubs & Organizations\nCommunity Involvement\nFitness & Pool\nGuest Speakers & Special Events\nStudy Abroad\nSustainability\nDiscover Delta\nDirectory\nEmployment\nInfo For\nFuture Students\nCurrent Students\nFaculty & Staff\nParents\nAlumni\nCommunity\nBusiness & Tech Training\nPortal\nSearch\nDonate\nBroadcasting\nPlanetarium\nWorkforce Training\nSustainability\nAbout Us\n1961 Delta Road\nUniversity Center, MI 48710\n989-686-9000\nContact Us\nA-Z Index\nLocations & Maps\nSafety\nAthletics\nBookstore\nLibrary\nPool & Fitness\nBoard of Trustees\nPublic Meeting Notices\nEquity\nPrivacy Statement\n©\n2018 Delta College\nDelta College\nDec 13, 2025\n2025 - 2026 Catalog\nSelect a Catalog\n2025 - 2026 Catalog\n2024 - 2025 Catalog [ARCHIVED CATALOG]\n2023 - 2024 Catalog [ARCHIVED CATALOG]\n2022 - 2023 Catalog [ARCHIVED CATALOG]\n2021 - 2022 Catalog [ARCHIVED CATALOG]\n2020 - 2021 Catalog [ARCHIVED CATALOG]\n2019 - 2020 Catalog [ARCHIVED CATALOG]\n2018 - 2019 Catalog [ARCHIVED CATALOG]\n2017-2018 [ARCHIVED CATALOG]\nGlobal Search\nCatalog Search\nChoose Search Location\nSelect an option\nCourses\nPrograms\nHierarchy Items\nOther Content\nEntire Catalog\nSearch Keyword Field\nWhole Word/Phrase\nAdvanced Search\nCatalog Navigation\nCatalog Home\nPrograms by Division\nPrograms A-Z\nCourse Descriptions\nWelcome\nStudents Rights and Responsibilities\nEnrollment\nTransfer, Validation, and Program Overview\nAcademic Policies and Information\nCourse Information and Prerequisites\nReferences\nSearch for Classes\nCareer Credentials\nMy Portfolio\nHELP\n2025 - 2026 Catalog\nPrint-Friendly Page (opens a new window)\nFacebook this Page (opens a new window)\nTweet this Page (opens a new window)\nAdd to Portfolio (opens a new window)\nMTH 225 - Introduction to Data Science\nCredits:\n3\nInstructional Contact Hours:\n3\nIntroduces the main tools and ideas in the data scientist's toolbox. Provides an overview of the data, questions, techniques, and tools that data analysts and data scientists use. Provides a conceptual introduction to the ideas behind turning data into actionable knowledge and tools that will be used to analyze this data. Examines collecting, cleaning, and sharing data. Demonstrates how to communicate results through visualizations.\nPrerequisite(s):\nMTH 208W\nor\nMTH 208AW\nor\nMTH 209W\nor\nMTH 209AW\nmay be taken previously or concurrently.\nCorequisite(s):\nNone\nLecture Hours:\n45\nLab Hours:\n0\nMeets MTA Requirement:\nNone\nPass/NoCredit:\nYes\nOutcomes and Objectives\nDemonstrate relevant programming abilities.\nCode simple algorithms in a high-level programming language.\nFormulate simple algorithms to solve problems and code them in a high-level language appropriate for data science work (e.g., Python, SQL, R, Java).\nCreate algorithms of moderate complexity and implement them in a data science programming language appropriate for data science work.\nDemonstrate proficiency with statistical analysis of data.\nPerform standard data visualization and formal inference procedures and interpret the results.\nChoose appropriately from a wider range of descriptive and inferential methods for analyzing data and interpret the results contextually.\nConstruct statistical models, assess the fit of such models to the data, and apply the models in real-world contexts.\nDemonstrate the ability to build and assess data-based models.\nDemonstrate an understanding of what a model is and how to use a given model.\nDemonstrate use of more complex models and begin to construct models of their own.\nRecognize that different models fit and perform better than others and measure fit and performance appropriately.\nExecute statistical analyses with professional statistical software.\nGenerate simple statistical summaries using on-line tools or software not designed for statistical analyses (e.g., Excel).\nCreate a wide range of visual and numerical data summaries and perform basic inferential procedures (confidence intervals and significance tests) using menu-driven statistical software.\nApply complex models using dedicated statistical software (e.g., R, Minitab, SAS).\nDemonstrate skill in data management\nOrganize data after the data have been collected and cleaned and use data in the form in which the data are given.\nPerform basic data cleaning and transform variables to facilitate analysis.\nAcquire and clean data and move information in and out of relational databases.\nDemonstrate skills in acquisition of data, combining data from multiple sources, and data wrangling.\nDescribe the fundamental elements of relational database management systems.\nExplain the basic concepts of relational data model, entity-relationship (ER) model, relational database design, relational algebra, and SQL.\nDesign ER models to represent simple database application scenarios.\nConvert the ER model to relational tables, populate relational database and formulate SQL queries on data.\nImprove the database design by normalization.\nBecome familiar with basic database storage structures and access techniques: file and page organizations, indexing methods (e.g., B tree, hashing).\nApply data science concepts or methods to solve problems in real-world contexts.\nChoose appropriate data management strategies, perform relevant analyses, interpret and apply the results to inform understanding, and solve specific problems in context.\nCommunicate solutions to problem effectively.\nCommunicate to a technical audience.\nBack to Top\n|\nPrint-Friendly Page (opens a new window)\nFacebook this Page (opens a new window)\nTweet this Page (opens a new window)\nAdd to Portfolio (opens a new window)\nAll\ncatalogs\n© 2025 Delta College.\nPowered by\nModern Campus Catalog™\n."}
{"url": "https://catalog.jccc.edu/coursedescriptions/ds/#DS_210", "text": "Data Science (DS) | Johnson County Community College Catalog\nSkip to Content\nAZ Index\nCatalog Home\nJCCC Home\nData Science (DS)\nCatalog Home\n›\nCredit Course Descriptions (A-Z List)\n›\nData Science (DS)\nSearch catalog\nSearch\n2025-26 Catalog\n2025-26 Catalog\nProgram Search\nCredit Course Descriptions (A-​Z List)\nToggle Credit Course Descriptions (A-​Z List)\nAccounting (ACCT)\nAmerican Sign Language (ASL)\nAnimation (ANI)\nAnthropology (ANTH)\nArchitecture (ARCH)\nArt (ART)\nArt History (ARTH)\nAstronomy (ASTR)\nAutomation Engineer Technology (AET)\nAutomotive Technology (AUTO)\nBiology (BIOL)\nBusiness (BUS)\nBusiness Law (BLAW)\nBusiness Office Technology (BOT)\nChemistry (CHEM)\nCollege Success (COLL)\nCommunication Studies (COMS)\nComputer Information Systems (CIS)\nComputer Support Specialist (CSS)\nComputer Science (CS)\nConstruction Management (CMGT)\nCriminal Justice (CJ)\nData Science (DS)\nDental Hygiene (DHYG)\nDietary Managers (DIET)\nDrafting/​CAD/​AutoCAD (DRAF)\nEconomics (ECON)\nEducation and Early Childhood (EDUC)\nElectrical Technology (ELTE)\nElectronics (ELEC)\nEmergency Medical Science (EMS)\nEngineering (ENGR)\nEnglish (ENGL)\nEnglish for Academic Purposes (EAP)\nEntrepreneurship (ENTR)\nEnvironmental Science (EVRN)\nFashion Merchandising/​Design (FASH)\nFilm and Media Studies (FMS)\nFire Services Administration (FIRE)\nFloriculture (FLR)\nForeign Language (FL)\nGame Development (GAME)\nGeoscience (GEOS)\nGlobal &​ International Studies (GIST)\nGraphic Design (GDES)\nHealth Care (HC)\nHealth Care Interpreting (HCI)\nHealthcare Information Systems (HCIS)\nHealth Occupations (AVHO)\nHeating,Vent.,Air Conditioning (HVAC)\nHistory (HIST)\nHonors Program (HON)\nHorticulture (HORT)\nHospitality Management (HMGT)\nHospitality Mgt Pastry Baking (HMPB)\nHumanities (HUM)\nInformation Technology (IT)\nInterior Design (ITMD)\nInternational Studies Abroad (ISAP)\nJournalism/​Media Communication (JOUR)\nLeadership (LEAD)\nLegal Studies (LAW)\nLibrary (LIBR)\nMarketing Management (MKT)\nMathematics (MATH)\nMed Info &​ Revenue Management (MIRM)\nMetal Fabrication and Welding (MFAB)\nMusic (MUS)\nNeurodiagnostic Technology (NDT)\nNursing (NURS)\nPhilosophy (PHIL)\nPhotography (PHOT)\nPhysical Ed, Health &​ Rec (HPER)\nPhysical Science (PSCI)\nPhysics (PHYS)\nPlumbing (PLUM)\nPolitical Science (POLS)\nPractical Nursing (PN)\nPsychology (PSYC)\nPublic Health (PH)\nRailroad Conductor (RRTC)\nRailroad Industrial Technology (RRIT)\nRailroad Operations (RRT)\nReading (RDG)\nReligion (REL)\nRespiratory Care (RC)\nScience (SCI)\nSociology (SOC)\nSustainable Agriculture (SAG)\nTheater (THEA)\nVisual Design Applications (VDA)\nWeb Development and Digital Media (WEB)\nWomen and Gender Studies (WGS)\nDegree Requirements\nToggle Degree Requirements\nAssociate of Arts\nAssociate of Fine Arts\nAssociate of Science\nAssociate of Applied Science\nAssociate of General Studies\nDegrees and Certificates\nToggle Degrees and Certificates\nAccounting\nAnimation\nAutomation Engineer Technology\nAutomotive Technology\nBusiness Administration\nComputer Information Systems\nComputer Support Specialist\nConstruction Management\nCriminal Justice\nData Science\nDental Hygiene\nDrafting Technology\nEducation\nElectrical Technology\nElectronics Technology\nEmergency Medical Science\nFashion Merchandising and Design\nFine Arts\nFire Services Administration\nGame Development\nGeneral Sciences\nGeneral Studies\nGraphic Design\nHealth Care Interpreting\nHealth Information Systems\nHealth Occupations\nHealth and Wellness\nHeating, Ventilation and Air Conditioning (HVAC)\nHorticulture\nHospitality Management\nInformation Technology\nInterior Design\nLegal Studies\nLiberal Arts\nMarketing and Management\nMedical Information and Revenue Management\nMetal Fabrication/​Welding\nNeurodiagnostic Technology\nNursing\nPlumbing Technology\nRailroad Industrial Technology\nRailroad Operations\nRecording Arts\nRespiratory Care\nSustainable Agriculture\nWeb Technologies\nTransfer Guides\nToggle Transfer Guides\nAvila University\nToggle Avila University\nAccelerated BSN\nAvila Degree Programs\nAvila University Core Curriculum\nAvila University Transfer Information\nBusiness Administration, BSBA\nElementary Education/​Middle School Education, BS\nNursing\nSocial Work\nBaker University\nToggle Baker University\nBaker University General Education Requirements\nCentral Methodist University\nToggle Central Methodist University\nApplied Behavior Analysis\nCentral Methodist General Education Requirements\nRN to BSN\nCleveland University\nToggle Cleveland University\nAccelerated Pre-​Med Program (Doctor of Chiropractic)\nCleveland Transfer Information\nRadiologic Technology\nColumbia College\nCornell College\nCottey College\nCulver Stockton College\nDonnelly College\nDrake University\nDrury University\nToggle Drury University\nBachelor of Business Administration (Online)\nDrury Transfer Information\nHammons School of Architecture\nOrganizational Leadership Studies, BS with HR Track (Online)\nDunwoody College of Technology\nEmporia State University\nToggle Emporia State University\nBusiness B.S.\nElementary Education\nEmporia State University General Education Core Curriculum\nNursing, BSN\nSecondary Education Requirements\nSport Leadership and Recreation, BS\nFashion Institute of Technology\nToggle Fashion Institute of Technology\nTransfer Information for Fashion Institute of Technology\nFort Hays State University\nToggle Fort Hays State University\nAccounting\nElementary Education\nFort Hays State University General Education Requirements\nTransfer Information for Fort Hays State University\nGraceland University\nToggle Graceland University\nBusiness Management\nTransfer Information for Graceland University\nUnder Construction\nGrand Canyon University\nHesston College\nIowa State University\nJohnson and Wales University\nKansas Christian College\nKansas City Art Institute\nToggle Kansas City Art Institute\nKansas City Art Institute General Education Requirements\nTransfer Information for Kansas City Art Institute\nKansas State University\nToggle Kansas State University\nAgricultural Technology Management, BS &​ Biological Systems Engineering, BS &​ Environmental Engineer\nAgricultural Technology Management, BS &​ Biological Systems Engineering, BS &​ Environmental Engineer\nArchitectural Engineering, BS and Construction Science and Management, BS\nArchitecture Options, Planning &​ Design\nAthletic Training and Rehabilitation Sciences\nBachelor of Fine Arts\nBusiness Administration, BSBA\nChemical Engineering. BS\nCivil Engineering, BS\nComputer Science, BS, and Cybersecurity, BS\nDietetics, BS\nEarly Childhood Education\nElementary Education, BS\nFashion Studies\nHorticulture BS, Golf Course and Sports Turf Operations Specialization\nHorticulture, BS with Landscape Specialization\nHorticulture, BS with Production Specialization\nHorticulture, BS with Science Specialization\nHospitality Management, BS\nIndustrial Engineering, BS\nIntegrated Computer Science, BA, BS\nInterior Design, BS\nK-​State BA/​BS\nKansas State University General Education Requirements\nMechanical Engineering, BS, Nuclear Engineering, BS\nMusic, BM, BME\nSecondary Education, BS\nTransfer Information for Kansas State University\nLoyola University\t-​ Chicago\nMidAmerica Nazarene University\nMissouri Southern State University\nMissouri State University\nMissouri University of Science and Technology\nMissouri Western State University\nNebraska Wesleyan University\nNorthwest Missouri State University\nOttawa University — Main Campus\nOttawa University-​Kansas City\nOzark Christian College\nPalmer College of Chiropractic\nPark University\nToggle Park University\nPark University Liberal Education Requirements\nPeru State College\nPittsburg State University\nToggle Pittsburg State University\nPittsburg State University General Education\nRasmussen University\nResearch College of Nursing\nRockhurst University\nToggle Rockhurst University\nRockhurst University Core Requirements\nSaint Luke's College — Affiliated with Rockhurst University\nSavannah College of Art and Design\nSimpson College\nSouthwest Baptist University\nSouthwestern College of Professional Studies\nStephens College\nTruman State University\nUniversity of Arkansas\nUniversity of Central Missouri\nToggle University of Central Missouri\nUniversity of Central Missouri General Education Requirements\nUniversity of Central Oklahoma\nUniversity of Colorado-​Colorado Springs\nUniversity of Kansas\nToggle University of Kansas\nAerospace Engineering\nAnimation, BFA\nApplied Computing\nArchitectural Engineering\nArt History, BFA\nBA, BGS, and BS Degrees\nBachelor of Business Administration (BBA)\nBachelor of Science in Business\nChemical Engineering\nCivil Engineering\nClinical Lab Science, BS\nCommunity Health\nComputer Engineering\nComputer Science Engineering\nCybersecurity Engineering\nElectrical Engineering\nElementary Teacher Education, BSE\nExercise Science\nHealth Information Management\nIllustration, BFA\nInterior Architecture\nJournalism, BSJ\nKU Core 34 General Education Requirements\nKU-​Community College Nursing Dual Partnership Program\nMaster of Architecture\nMathematics\nMechanical Engineering\nNursing, BSN\nOnline Degree Completion Program, LA&​S BGS\nPetroleum Engineering\nPhysical Education Plus, BSE\nPre-​Medicine\nPre-​Occupational Therapy (Doctorate Program)\nPre-​Pharmacy\nPre-​Physical Therapy (Doctorate Program) &​ MS in Athletic Training\nRespiratory Care\nRespiratory Care AAS or Dual Degree\nSecondary Education, BSE (English)\nSecondary Education, BSE (History/​Government)\nSocial Work, BSW\nSport Management\nTheatre\nUnified Early Childhood\nUnified Elementary Education\nUniversity of Kansas Core 34 General Education Requirements\nVisual Art, BA\nVisual Art, BFA\nVisual Communication Design or Interaction Design, BFA\nUniversity of Kansas -​ Edwards Campus\nUniversity of Maryland Global Campus\nUniversity of Missouri-​Columbia\nToggle University of Missouri-​Columbia\nUniversity of Missouri-​Columbia General Education Requirements\nUniversity of Missouri-​Kansas City\nToggle University of Missouri-​Kansas City\nUniversity of Missouri-​Kansas City General Education Requirements\nUniversity of Nebraska -​ Kearney\nUniversity of Nebraska-​Omaha\nUniversity of Saint Mary-​Johnson County Campus\nUniversity of Saint Mary-​Main Campus\nWashburn University\nToggle Washburn University\nWashburn University General Education Program\nWebster University\nWestern Governors University\nWichita State University\nToggle Wichita State University\nWichita State University General Education Requirements\nWilliam Jewell College\nWilliam Woods University\nPast Catalogs\nAccessibility\nAccreditation\nNon-​Discrimination Statement\nTitle IX -​ Report Sexual Harassment/​Misconduct\nSearch the Credit Class Schedule\nSteps to Enroll\nTransfer Information &​ Services\nPrint Options\nCourses\nDS 210\nIntroduction to Data Science\n(3 Hours)\nIn this course, students receive an introduction to the main tools and ideas in the data scientist's toolbox. The course gives an overview of the data, questions, techniques and tools that data analysts and data scientists work with. This course provides a conceptual introduction to the ideas behind turning data into actionable knowledge and tools that will be used to analyze this data. The course will cover collecting, cleaning and sharing data. Additionally, this course will cover how to communicate results through visualizations.\nDS 220\nData Visualization\n(3 Hours)\nThis course introduces students to key design principles and techniques for interactively visualizing data. In addition to understanding how visual representations are used in the analysis and understanding of complex data, students will acquire data visualization skills, including designing effective visualizations and creating interactive visualizations using various tools.\nDS 230\nSQL for Data Analysis\n(3 Hours)\nIn this course, students will focus on how to apply the Structured Query Language (SQL) to data analysis tasks. Spreadsheets will be used for the visualization of data. Additionally, basic statistics will be covered. All data will be extracted from relational tables.\nDS 240\nIntroduction to Statistical Programming\n(3 Hours)\nStudents in this course will use a statistical programming language to perform effective data analysis. Students will acquire programming skills including reading data, accessing statistical packages, writing functions, debugging, profiling code, organizing code and commenting code.\nDS 260\nData Mining*\n(3 Hours)\nPrerequisites :\nDS 210\nand\nDS 240\n.\nThis course will provide students with an understanding of fundamental data mining methodologies and the ability to formulate and solve problems with these methodologies. Particular attention will be paid to the process of extracting data, analyzing it from many dimensions or perspectives, then producing a summary of the information in a useful form that identifies relationships within the data. The lectures will be complemented with hands-on experience with data mining software to allow development of execution skills.\nDS 270\nIntroduction to Machine Learning*\n(3 Hours)\nPrerequisites :\nDS 210\nand\nDS 240\n.\nThis introductory course gives an overview of machine learning concepts, techniques and algorithms. Supervised and unsupervised machine learning will be covered. Machine learning is an integral part of data analytics, which deals with developing data-driven insights for better designs and decisions and gives computers the ability to learn without being explicitly programmed.\nDS 280\nBig Data Architecture\n(3 Hours)\nThis course covers emerging big data architectures that deal with large amounts of unstructured and semi-structured data. This course is designed for developers who need to create applications to analyze big data stored in distributed file systems. Topics include file architecture, data retrieval, performance and data analysis.\nDS 210\nTitle:\nIntroduction to Data Science\nNumber:\nDS 210\nEffective Term:\n2025-26\nCredit Hours:\n3\nContact Hours:\n3\nLecture Hours:\n3\nDescription:\nIn this course, students receive an introduction to the main tools and ideas in the data scientist's toolbox. The course gives an overview of the data, questions, techniques and tools that data analysts and data scientists work with. This course provides a conceptual introduction to the ideas behind turning data into actionable knowledge and tools that will be used to analyze this data. The course will cover collecting, cleaning and sharing data. Additionally, this course will cover how to communicate results through visualizations.\nTextbooks:\nhttp://bookstore.jccc.edu/\nSupplies:\nRefer to the instructor's course syllabus for details about any supplies that may be required.\nObjectives\nDescribe data science in the context of big data.\nDiscuss the ethics of big data.\nDescribe and apply the data science life cycle.\nDescribe data.\nDescribe the extract, transform and load (ETL) process and why it is important.\nApply programming to the ETL process.\nAnalyze real-world problems based on data analysis techniques.\nExplain the solutions.\nContent Outline and Competencies:\nI. Data Science and Big Data\nA. Describe big data.\nB. Discuss examples of data science.\nC. Discuss case studies.\nII. Ethics of Big Data\nA. Explain identity.\nB. Discuss privacy.\nC. Discuss ownership.\nD. Demonstrate reputation.\nIII. Data Science Life Cycle\nA. Identify the problem.\nB. Identify available data sources.\nC. Prepare the data.\nD. Apply data analysis.\nE. Solve the problem.\nF. Explain the solutions.\nIV. Data\nA. Identify types of data.\nB. Demonstrate sources of data.\nC. Explain storage of data.\nD. Illustrate structured versus unstructured data.\nE. Discover messiness of data.\nV. ETL Process\nA. Extract data from data sources.\nB. Transform extracted data.\nC. Load transformed data.\nVI. ETL Programming\nA. Apply ETL basics.\nB. Employ data structures.\nC. Use programming language packages.\nVII. Real-World Problems\nA. Formulate the problem.\nB. Collect relevant data.\nC. Analyze the data.\nD. Apply the techniques using programming.\nVIII. Solutions\nA. Prepare solution documents.\nB. Justify solutions orally.\nC. Present visualizations.\nMethod of Evaluation and Competencies:\n35-50%    Exams and Quizzes\n20-40%    Assignments and Labs\n25-30%    Final Project and Presentation, ePortfolio Update\nTotal: 100%\nGrade Criteria:\n90 - 100% = A\n80 - 89% = B\n70 - 79% = C\n60 - 69% = D\n0 - 59% = F\nCaveats:\nStudent Responsibilities:\nDisabilities:\nJCCC provides a range of services to allow persons with disabilities to participate in educational programs and activities. If you are a student with a disability and if you are in need of accommodations or services, it is your responsibility to contact Access Services and make a formal request. To schedule an appointment with an Access Advisor or for additional information, you may send an\nemail\nor call Access Services at (913)469-3521. Access Services is located on the 2nd floor of the Student Center (SC 202).\nDS 220\nTitle:\nData Visualization\nNumber:\nDS 220\nEffective Term:\n2025-26\nCredit Hours:\n3\nContact Hours:\n3\nLecture Hours:\n3\nDescription:\nThis course introduces students to key design principles and techniques for interactively visualizing data. In addition to understanding how visual representations are used in the analysis and understanding of complex data, students will acquire data visualization skills, including designing effective visualizations and creating interactive visualizations using various tools.\nTextbooks:\nhttp://bookstore.jccc.edu/\nSupplies:\nRefer to the instructor's course syllabus for details about any supplies that may be required.\nObjectives\nDescribe data visualization in the context of big data.\nRecognize graphical integrity.\nDescribe and apply key design principles.\nDescribe techniques of data visualization.\nAnalyze various types of data sets.\nApply visualizations and basic statistics to analyze and understand data.\nAnalyze real-world problems based on data visualization techniques.\nDescribe the different types of visualizations and when to use them.\nIdentify what makes a visualization effective or ineffective.\nContent Outline and Competencies:\nI. Data Visualization and Big Data\nA. Identify misleading graphs.\nB. Illustrate stories with data.\nC. Discuss the audience.\nD. Discuss the story.\nII. Graphical Integrity\nA. Explain labeling.\nB. Demonstrate sourcing.\nC. Illustrate managing data relevance and density.\nIII. Key Design Principles\nA. Express the importance of context.\nB. Demonstrate exploratory and explanatory analysis.\nIV. Data Visualization Techniques\nA. Discuss choosing an effective visual.\n1. Clutter\n2. Decluttering\n3. Audience focus\n4. Accessibility\n5. Aesthetics\n6. Acceptance\nB. Explain storytelling.\nV. Data Sets\nA. Use data from the web.\nB. Select comma-separated value (CSV) files.\nC. Analyze text files.\nD. Manipulate relational tables.\nVI. Visualization Application\nA. Understand and use different types of visualizations to analyze and understand data.\nB. Use basic statistical formulas to analyze and understand data.\nVII. Real-World Problems\nA. Formulate the problem.\nB. Collect relevant data.\nC. Analyze the data.\nD. Apply the techniques of data visualization.\nVIII. Types of Visualizations and Uses\nA. Determine type of analysis to be visualized.\n1. Categorical\n2. Hierarchical\n3. Relational\n4. Temporal\n5. Spatial\nB. Design and apply appropriate visualization.\nIX. Effective and Ineffective Visualizations\nA. Evaluate visualizations for effectiveness.\nB. Propose improvements of visualizations.\nMethod of Evaluation and Competencies:\n35-50%    Exams and Quizzes\n20-40%    Assignments and Labs\n25-30%    Final Project and Presentation, ePortfolio Update\nTotal: 100%\nGrade Criteria:\n90 - 100% = A\n80 - 89% = B\n70 - 79% = C\n60 - 69% = D\n0 - 59% = F\nCaveats:\nStudent Responsibilities:\nDisabilities:\nJCCC provides a range of services to allow persons with disabilities to participate in educational programs and activities. If you are a student with a disability and if you are in need of accommodations or services, it is your responsibility to contact Access Services and make a formal request. To schedule an appointment with an Access Advisor or for additional information, you may send an\nemail\nor call Access Services at (913)469-3521. Access Services is located on the 2nd floor of the Student Center (SC 202).\nDS 230\nTitle:\nSQL for Data Analysis\nNumber:\nDS 230\nEffective Term:\n2025-26\nCredit Hours:\n3\nContact Hours:\n3\nLecture Hours:\n3\nDescription:\nIn this course, students will focus on how to apply the Structured Query Language (SQL) to data analysis tasks. Spreadsheets will be used for the visualization of data. Additionally, basic statistics will be covered. All data will be extracted from relational tables.\nTextbooks:\nhttp://bookstore.jccc.edu/\nSupplies:\nRefer to the instructor's course syllabus for details about any supplies that may be required.\nObjectives\nDescribe SQL in the context of data analysis.\nUse SQL queries.\nApply SQL to data exploration.\nUse basic statistics.\nApply SQL to time-related data analysis.\nApply SQL for business analysis.\nAnalyze real-world problems using SQL.\nExplain the solutions.\nContent Outline and Competencies:\nI. SQL and Data Analysis\nA. Discuss relevancy.\nB. Illustrate Select statement examples.\nII. SQL Queries\nA. Use the Select clause.\nB. Employ the From clause.\nC. Apply the Where clause.\nD. Illustrate the Group by clause.\nE. Apply the Having clause.\nF. Interpret the Order by clause.\nG. Use the Fetch and Offset clause.\nIII. Data Exploration\nA. Describe data exploration.\nB. Use spreadsheets for visualization.\nIV. Statistics\nA. Describe statistical concepts.\n1. Quantitative data\n2. Identifier data\n3. Categorical data\n4. Mean\n5. Mode\n6. Median\n7. Outliers\n8. Standard deviation\nB. Analyze data using statistics.\nV. Time-Related Data Analysis\nA. Describe concepts.\n1. Distributions\n2. Plots\n3. Correlation\n4. Causation\n5. Linear regression\n6. Hypothesis testing\nB. Analyze time-related data.\nVI. Business Analysis\nA. Describe various types of business analysis.\nB. Apply different SQL analysis techniques to relational data.\n1. Selection\n2. Filters\n3. Aggregates\n4. Joins\n5. Sorts\nVII. Real-World Problems\nA. Formulate the problem.\nB. Collect relevant data.\nC. Analyze the data.\nD. Apply analysis using SQL.\nVIII. Solutions\nA. Prepare solution documents.\nB. Justify solutions orally.\nC. Present visualizations.\nMethod of Evaluation and Competencies:\n35-50%    Exams and Quizzes\n20-40%    Assignments and Labs\n25-30%    Final Project and Presentation, ePortfolio Update\nTotal: 100%\nGrade Criteria:\n90 - 100% = A\n80 - 89% = B\n70 - 79% = C\n60 - 69% = D\n0 - 59% = F\nCaveats:\nStudent Responsibilities:\nDisabilities:\nJCCC provides a range of services to allow persons with disabilities to participate in educational programs and activities. If you are a student with a disability and if you are in need of accommodations or services, it is your responsibility to contact Access Services and make a formal request. To schedule an appointment with an Access Advisor or for additional information, you may send an\nemail\nor call Access Services at (913)469-3521. Access Services is located on the 2nd floor of the Student Center (SC 202).\nDS 240\nTitle:\nIntroduction to Statistical Programming\nNumber:\nDS 240\nEffective Term:\n2025-26\nCredit Hours:\n3\nContact Hours:\n3\nLecture Hours:\n3\nDescription:\nStudents in this course will use a statistical programming language to perform effective data analysis. Students will acquire programming skills including reading data, accessing statistical packages, writing functions, debugging, profiling code, organizing code and commenting code.\nTextbooks:\nhttp://bookstore.jccc.edu/\nSupplies:\nRefer to the instructor's course syllabus for details about any supplies that may be required.\nObjectives\nDescribe the statistical programming language in the context of big data.\nDescribe the statistical software environment.\nApply basic skills of a statistical programming language.\nUse the statistical programming language to access data.\nConstruct statistical programming language functions.\nUse the statistical programming language advanced data structures.\nAnalyze real-world problems using the statistical programming language.\nExplain the solutions.\nContent Outline and Competencies:\nI. Statistical Programming Language and Big Data\nA. Describe the statistical programming language.\nB. Describe the benefits of a statistical programming language.\nC. Apply the statistical programming language to big data.\nII. Statistical Programming Language Software Environment\nA. Use the statistical programming language integrated development environment (IDE).\nB. Explain the statistical programming language packages.\nIII. Statistical Programming Language\nA. Use variables.\nB. Demonstrate vectors.\nC. Construct control statements.\nD. Write loops.\nE. Create functions.\nF. Interpret missing data.\nIV. Data\nA. Use comma separated value (CSV) files.\nB. Employ spreadsheet data.\nC. Select databases.\nD. Manipulate data included with the statistical programming language.\nE. Use data from websites.\nV. Functions\nA. Memorize syntax.\nB. Use function arguments.\nC. Use return values.\nVI. Advanced Structures\nA. Use data frames.\nB. Employ lists.\nC. Construct matrices.\nD. Create arrays.\nVII. Real-World Problems\nA. Formulate the problem.\nB. Collect relevant data.\nC. Analyze the data.\nD. Apply the statistical programming language.\nVIII. Solutions\nA. Prepare solution documents.\nB. Justify solutions orally.\nC. Present visualizations.\nMethod of Evaluation and Competencies:\n35-50%    Exams and Quizzes\n20-40%    Assignments and Labs\n25-30%    Final Project and Presentation, ePortfolio Update\nTotal: 100%\nGrade Criteria:\n90 - 100% = A\n80 - 89% = B\n70 - 79% = C\n60 - 69% = D\n0 - 59% = F\nCaveats:\nStudent Responsibilities:\nDisabilities:\nJCCC provides a range of services to allow persons with disabilities to participate in educational programs and activities. If you are a student with a disability and if you are in need of accommodations or services, it is your responsibility to contact Access Services and make a formal request. To schedule an appointment with an Access Advisor or for additional information, you may send an\nemail\nor call Access Services at (913)469-3521. Access Services is located on the 2nd floor of the Student Center (SC 202).\nDS 260\nTitle:\nData Mining*\nNumber:\nDS 260\nEffective Term:\n2025-26\nCredit Hours:\n3\nContact Hours:\n3\nLecture Hours:\n3\nRequirements:\nPrerequisites:\nDS 210\nand\nDS 240\n.\nDescription:\nThis course will provide students with an understanding of fundamental data mining methodologies and the ability to formulate and solve problems with these methodologies. Particular attention will be paid to the process of extracting data, analyzing it from many dimensions or perspectives, then producing a summary of the information in a useful form that identifies relationships within the data. The lectures will be complemented with hands-on experience with data mining software to allow development of execution skills.\nTextbooks:\nhttp://bookstore.jccc.edu/\nSupplies:\nRefer to the instructor's course syllabus for details about any supplies that may be required.\nObjectives\nDescribe data mining in the context of big data.\nDescribe and apply a data mining methodology.\nIdentify inputs to the data mining process.\nProduce outputs from data mining process.\nAnalyze real-world problems using data mining techniques.\nExplain the solutions.\nContent Outline and Competencies:\nI. Data Mining and Big Data\nA. Explain data mining and machine learning.\nB. Explain patterns.\nC. Discuss examples.\nD. Discuss ethics.\nII. Data Mining Methodology\nA. Illustrate business understanding.\nB. Apply data understanding.\nC. Summarize data preparation.\nD. Employ modeling.\nE. Discuss evaluation.\nG. Create data flow diagrams.\nIII. Data Mining Process Inputs\nA. Determine sparse data.\nB. Handle missing values.\nC. Identify and treat outliers appropriately.\nD. Explain data.\nE. Transform data.\nF. Extract data using application programming interfaces (APIs).\nG. Extract data using web scraping.\nIV. Data Mining Process Outputs\nA. Produce a variety of supervised models.\nB. Produce a variety of unsupervised models.\nC. Employ time series analysis.\nD. Create dashboards.\nV. Real-World Problems\nA. Formulate the problem.\nB. Collect relevant data.\nC. Analyze the data.\nD. Apply the techniques of data mining.\nVI. Solutions\nA. Prepare solution documents.\nB. Justify solutions orally.\nC. Present visualizations.\nMethod of Evaluation and Competencies:\n35-50%    Exams and Quizzes\n20-40%    Assignments and Labs\n25-30%    Final Project and Presentation, ePortfolio Update\nTotal: 100%\nGrade Criteria:\n90 - 100% = A\n80 - 89% = B\n70 - 79% = C\n60 - 69% = D\n0 - 59% = F\nCaveats:\nStudent Responsibilities:\nDisabilities:\nJCCC provides a range of services to allow persons with disabilities to participate in educational programs and activities. If you are a student with a disability and if you are in need of accommodations or services, it is your responsibility to contact Access Services and make a formal request. To schedule an appointment with an Access Advisor or for additional information, you may send an\nemail\nor call Access Services at (913)469-3521. Access Services is located on the 2nd floor of the Student Center (SC 202).\nDS 270\nTitle:\nIntroduction to Machine Learning*\nNumber:\nDS 270\nEffective Term:\n2025-26\nCredit Hours:\n3\nContact Hours:\n3\nLecture Hours:\n3\nRequirements:\nPrerequisites:\nDS 210\nand\nDS 240\n.\nDescription:\nThis introductory course gives an overview of machine learning concepts, techniques and algorithms. Supervised and unsupervised machine learning will be covered. Machine learning is an integral part of data analytics, which deals with developing data-driven insights for better designs and decisions and gives computers the ability to learn without being explicitly programmed.\nTextbooks:\nhttp://bookstore.jccc.edu/\nSupplies:\nRefer to the instructor's course syllabus for details about any supplies that may be required.\nObjectives\nDescribe machine learning in the context of big data.\nDiscuss machine learning basics.\nUse structured and unstructured data.\nDescribe supervised machine learning algorithms.\nCreate supervised machine learning models.\nDescribe unsupervised machine learning algorithms.\nCreate unsupervised machine learning models.\nAnalyze real-world problems based on machine learning techniques.\nExplain the solutions.\nContent Outline and Competencies:\nI. Machine Learning and Big Data\nA. Discuss big data.\nB. Discuss artificial intelligence.\nII. Machine Learning Basics\nA. Define key terminology.\nB. Interpret key tasks.\nC. Illustrate algorithms.\nD. Demonstrate steps in developing an application.\nE. Employ programming libraries.\nIII. Structured and Unstructured Data\nA. Discuss supervised learning.\nB. Discuss unsupervised learning.\nIV. Supervised Machine Learning Algorithms\nA. Explain k-nearest neighbors.\nB. Explain decision trees and random forests.\nC. Explain linear regression.\nD. Explain multiple regression.\nV. Supervised Machine Learning Algorithms Application\nA. Create classification models.\nB. Create regression models.\nVI. Unsupervised Machine Learning Algorithms\nA. Explain association rules.\nB. Explain cluster analysis.\nVII. Unsupervised Machine Learning Algorithms Application\nA. Create association models.\nB. Create cluster analysis models.\nVIII. Real-World Problems\nA. Formulate the problem.\nB. Collect relevant data.\nC. Analyze the data.\nD. Apply the techniques of machine learning.\nIX. Solutions\nA. Prepare solution documents.\nB. Justify solutions orally.\nC. Present visualizations.\nMethod of Evaluation and Competencies:\n35-50%    Exams and Quizzes\n20-40%    Assignments and Labs\n25-30%    Final Project and Presentation, ePortfolio Update\nTotal: 100%\nGrade Criteria:\n90 - 100% = A\n80 - 89% = B\n70 - 79% = C\n60 - 69% = D\n0 - 59% = F\nCaveats:\nStudent Responsibilities:\nDisabilities:\nJCCC provides a range of services to allow persons with disabilities to participate in educational programs and activities. If you are a student with a disability and if you are in need of accommodations or services, it is your responsibility to contact Access Services and make a formal request. To schedule an appointment with an Access Advisor or for additional information, you may send an\nemail\nor call Access Services at (913)469-3521. Access Services is located on the 2nd floor of the Student Center (SC 202).\nDS 280\nTitle:\nBig Data Architecture\nNumber:\nDS 280\nEffective Term:\n2025-26\nCredit Hours:\n3\nContact Hours:\n3\nLecture Hours:\n3\nDescription:\nThis course covers emerging big data architectures that deal with large amounts of unstructured and semi-structured data. This course is designed for developers who need to create applications to analyze big data stored in distributed file systems. Topics include file architecture, data retrieval, performance and data analysis.\nTextbooks:\nhttp://bookstore.jccc.edu/\nSupplies:\nRefer to the instructor's course syllabus for details about any supplies that may be required.\nObjectives\nDescribe the importance of big data architecture.\nDescribe big data architectures.\nIdentify software technologies of big data architecture platforms.\nDescribe data-related technologies of big data architecture platforms.\nDescribe storage technologies of big data architecture platforms.\nEmploy big data architecture platforms for data analysis tasks.\nAnalyze real-world problems using big data architecture platforms and associated technologies.\nExplain the solution.\nContent Outline and Competencies:\nI. Big Data Architecture\nA. Illustrate storing.\nB. Demonstrate transforming.\nC. Describe analyzing.\nII. Architectures\nA. Explain data migration.\nB. Describe business uses.\nIII. Software Technologies\nA. Discuss open-source software.\n1. Data division\n2. Data analysis\n3. Multiple users\nB. Illustrate algorithms.\nIV. Data-Related Technologies\nA. Practice data retrieval.\nB. Practice data analysis.\nV. Storage Technologies\nA. Show file systems.\nB. Demonstrate performance issues and solutions.\nC. Practice storage and retrieval of non-relational data.\nD. Practice storage and retrieval of relational data.\nVI. Data Analysis Using Architecture Platform\nA. Use platform technologies for data analysis.\nB. Solve case studies.\nVII. Real-World Problems\nA. Formulate the problem.\nB. Collect relevant data.\nC. Analyze the data.\nD. Apply the techniques of big data architecture platforms and core technologies.\nVIII. Solutions\nA. Prepare solution documents.\nB. Justify solutions orally.\nC. Present visualizations.\nMethod of Evaluation and Competencies:\n35-50%    Exams and Quizzes\n20-40%    Assignments and Labs\n25-30%    Final Project and Presentation, ePortfolio Update\nTotal: 100%\nGrade Criteria:\n90 - 100% = A\n80 - 89% = B\n70 - 79% = C\n60 - 69% = D\n0 - 59% = F\nCaveats:\nStudent Responsibilities:\nDisabilities:\nJCCC provides a range of services to allow persons with disabilities to participate in educational programs and activities. If you are a student with a disability and if you are in need of accommodations or services, it is your responsibility to contact Access Services and make a formal request. To schedule an appointment with an Access Advisor or for additional information, you may send an\nemail\nor call Access Services at (913)469-3521. Access Services is located on the 2nd floor of the Student Center (SC 202).\nopens in\nnew window\nTaxpayer\n& Student Transparency Data\nFollow Johnson County Community College\nFacebook - opens in\nnew window\nTwitter - opens in\nnew window\nLinkedIn - opens in\nnew window\nYouTube - opens in\nnew window\nInstagram - opens in\nnew window\nMain Campus\n12345 College Blvd\nOverland Park, KS 66210\n913-469-8500\nContact JCCC\nAccessibility\nNon-Discrimination\nPrivacy\nCopyright\nConsumer\nInformation\nShopJCCC\nMedia Resources\nEvents\nAdministration\nJCCC\nAlert\nJCCC\nPolice\nPolice Phone:\n913-469-2500\nExplore\nCareers at JCCC\n© 2025-26 Johnson County Community College |\nTerms of Use\nBack to top\nClose this window\nPrint Options\nSend Page to Printer\nPrint this page.\nDownload Page (PDF)\nThe PDF will include all information unique to this page.\nDownload PDF of the entire 2025-2026 Catalog\nAll pages in the 2025-2026 catalog.\nThis course is approved by the Kansas Board of Regents for guaranteed transfer among all Kansas Regents public postsecondary institutions. Additional courses may also be eligible for transfer. Please visit a\nJCCC counselor\nor the JCCC Registrar's office, and the\nTransfer Kansas portal\nto learn more."}
{"url": "https://docs.google.com/spreadsheets/d/1HTnAukzyXh0wM411MMeiNjR-O1sXTmIwX8GqzQgPxIY/edit?gid=0#gid=0", "text": "Undergrad Intro DS Syllabi - Google Sheets\nJavaScript isn't enabled in your browser, so this file can't be opened. Enable and reload.\nThis browser version is no longer supported. Please upgrade to a supported browser.\nUndergrad Intro DS Syllabi\nTab\nExternal\nShare\nSign in\nFile\nEdit\nView\nInsert\nFormat\nData\nTools\nExtensions\nHelp\nAccessibility\nDebug\nUnsaved changes to Drive\nAccessibility\nComment only\nLoading...\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\nK\nL\nM\nN\nO\nP\nQ\nR\nS\nT\nU\nV\nW\nX\nY\nZ\nAA\nAB\n1\nCourse Name (YEAR)\nDepartment\nCollege\nPrereqs\nProgram Language\nNotes\nLink to Syllabi\n2\nSTA 301 (2024) Introduction to Data Science\nStatistics?\nUT Austin\nNone\nR\nSample vs. population; summary data; probability; data wrangling; linear models; variance; boostrap; p-values; CLT/inference. More Intro DS syllabi\nhere\n.\nhttps://drive.google.com/file/d/1seBv89WF8pLVBUGMTrUdGfZ6Zk8u0E0D/view?usp=sharing\n3\nSTAT 101 (NA) Introduction to Data Science\nMath\nJoliet Junior College\nNA\nR\nData overview; tools; summary data; ethics and data sources; ethics in research; hypotheses; data analysis life cycle; data viz; data presentation\nhttps://drive.google.com/file/d/14CFEfWblmLuPXLUDPf5GgFSx-lYssjec/view?usp=sharing\n4\nDAT 300 (2021) Mathematical Tools for Data Science\nMath\nArizona State University\nMAT 266 or 271; MAT 343\nPython\nVariables; linear functions; Python; derivatives; gradient descent; probability; variance; CLT\nhttps://webapp4.asu.edu/bookstore/viewsyllabus/2217/90316/pdf;jsessionid=E65F3E3C2990617F80004CA6C9F64D20\n5\nINFO 103 (2018) Introduction to Data Science\nComputing & Informatics\nDrexel\nNone\nData science overview; data science lifecycle; data types; big data; tools; data sources; data wrangling; storage; data summary; modeling; classification; project design; exemplar projects\nhttps://leipzig.github.io/Intro2DS/syllabus.pdf\n6\nCS365 (2023) Foundations of Data Science\nFaculty of Computing & Data Sciences\nBoston University\nCS 112; CS 131 (MA293); CS 132 (MA242); CS 237 (MA581)\nPython\nData viz; probability; statistical inference; ML; graphs; algorithms; SVD, PCA; optimization; data management\nhttps://tsourakakis.com/cs365-foundations-of-data-science-spring23/\n7\nINFO 2950 (2024) Introducation to Data Science\nInformation Science\nCornell\nMATH 1710; CS 1110 or CS 1112\nR\nStatistical diagnostics; data viz; data wrangling; summary data; regression;  inference boostrap;\nhttps://info2950.infosci.cornell.edu/course-syllabus.html\n8\nCSC 31167 (2022) Foundations of Data Science\nGrad Center\nCUNY\nNone\nPython\nData types; variables; Python; data wrangling; text analysis; project\nhttps://gofilipa.github.io/fds-spring-23/syllabus.html\n9\nCSCI S-101 (2022) Foundations of Data Science and Engineering\nComputer Science\nHarvard\nIntro Programming with Python; Intro CS\nPython\nDS and Statistical thinking; data types and Python; Data management; exploratory data analysis; data viz and communication; object oriented programming; ML; NLP\nhttps://scholar.harvard.edu/files/brucehuang/files/foundations_of_data_science_and_engineering_syllabus_draft_fall_2022.pdf\n10\nBIOL4800 (N.D.) Introduction to Data Science\nBiology\nLSU\nR\nhttps://introdatasci.dlilab.com/syllabus/\n11\nORF 525 (2025) Statistical Foundations of Data Science\nOperations Research\nPrinceton\nR\nBig data; multiple and nonparametric regression; penalized least squares; GLM; feature screening; ML; deep learning; graphical models; factor models and PCA.\nhttps://fan.princeton.edu/fan/classes/525.html\n12\nData 8 (2025) The Foundations of Data Science\nCollege of Computing, Data Science, and Society (CDSS)\nUC Berkeley\nPython\nDS; cause and effect; Python; data types; tables; data viz; functions; data management; probability; samples; models; CLT; uncertainty; A/B testing; causality; confidence intervals; correlation; residuals; classification; multiple linear regression; updating probabilities; computer vision\nhttps://www.data8.org/fa25/\n13\nDSC 10\nSchool of Computing, Information, and Data Sciences\nUC San Diego\nPython\nJupyter Notebooks/Python; data types; data management; functions; data viz; probability; simulation; sampling; bootstrapping; confidence intervals; CLT; hypothesis testing; OLS; residuals\nhttps://dsc10.com/syllabus/\n14\nDATA 300 6380 (2023) Foundaitons of Data Science\nUniversity of Maryland\nSTAT 200\nPython\nPython; data wrangling; data types; data viz; modeling; ML\nhttps://umgc.campusconcourse.com/view_syllabus?course_id=235327&public_mode=1\n15\nIntroduction to Data Science (2022)\nComputer Science or Mathematics\nUniversity of Utah\nCalculus\nPython\nPython; data summary; data types; hypothesis testing and inference; OLS; classification; data viz; clustering; PCA; network analysis; rating and ranking; data wrangling; NLP; ethics\nhttps://datasciencecourse.net/2022/syllabus/\n16\nDS 1001 (2025) Think Like a Data Scientist\nSchool of Data Science\nUVA\nNone\nData science overview; software; hardware; Github; data science lifecycle; data storytelling; data viz; ML; model development and evaluation; project\nhttps://github.com/UVADS/DS1001\n17\nSTAT 231 Data Science\nMathematics and Statistics Department\nAmherst College\nSTAT 111 or STAT 135 and COSC 111\nLast time this class was offered was in Spring 2022\nhttps://www.amherst.edu/academiclife/departments/courses/1718F/STAT/STAT-231-1718F\n18\nSTAT 36-200 (2017) Reasoning with Data\nStats\nCMU\ndata; exploratory data analysis; experimental design; probability; data types; sampling and confidence intervals; inference; OLS\nhttps://www.stat.cmu.edu/~rnugent/PUBLIC/teaching/200syllabus.pdf\n19\nCSE 180 | STAT 180 (2017) | INFO 370 Introduction to Data Science\nComputer Science Engineering\nUW\nPrecalculus\nPython\nIntro Python; data management; summary data; data viz; data sources; inference; ML; big data\nhttps://wstuetzle.github.io/IDS-syllabus-11-14-2017.html\n20\nCS 8A (2024) Introduction to Data Science\nComputer Science\nFoothill College\nPython\nobservational and experimental data; programming software; programming; data types and management; data viz; functions; probability; sampling; hypothesis testing; bootstrap and confidence intervals; CLT; OLS; classification; conditional probability; ethics\nhttps://catalog.foothill.edu/course-outlines/C-S-8A/\n21\nCAP 2757 (2023) Introduction to Data Science\nComputing and Information Sciences\nFIU\nPython Programming\nPython\nData Science overview and lifecycle; data types, sources, and sampling; linear algebra, probability, and optimization; data maanagement; data wrangling; summary data and hypothesis testing; modeling; data viz and communication; ethics; project-based learning\nhttps://drive.google.com/file/d/1JWrXU3c_6wyIS928WXyA5eT1SvsC538B/view?usp=sharing\n22\nME314 (2025) Introduction to Data Science and Machine Learning\nData Science Institute\nLSE\nPython and R\nData science; data types; summary data; probability and linear regression; causal inference; ML; unstructured data; text data; theory and empirical evidence\nhttps://drive.google.com/file/d/1EUZsBDvJA79I2W5mlwA3dMYJQu9nTsER/view?usp=sharing\n23\nSTA/CSI 2300 (2021) Introduction to Data Science\nStatistics or Computer Science\nBaylor\nNone\nR\nR; R markdown; exploratory data analysis; data wrangling; programming; graphics; Shiny; regression; variable selection; feature generation; clustering; classification; model validation; Github; teamwork; communication\nhttps://drive.google.com/file/d/17hR9TARtPj2yqn7nBm1vQUH6W-YspI5v/view?usp=sharing\n24\nSTT 180-001 (2021) Introduction to Data Science\nStatistics\nMichigan State\nCalculus\nR; programming; data sources and ethics; R markdown; data types and structures; functions; exploratory data analysis; summary data; data wrangling; simulations; CLT and sampling; hypothesis testing and inference; KNN and ML; databases and SQL\nhttps://drive.google.com/file/d/17hR9TARtPj2yqn7nBm1vQUH6W-YspI5v/view?usp=sharing\n25\nWilliam & Mary\nhttps://ds-wm.github.io/course/intro/syllabus/index.html\n26\nSTA 199 (2025) Introduction to Data Science\nStatistics\nDuke\nR\nhttps://sta199-f25.github.io/\n27\n6011P0286Y (2021-22) Introduction Data Science: Data Preprocessing\nEconomics and Business\nUniversity of Amsterdam\nR\nhttps://studiegids.uva.nl/xmlpages/page/2021-2022-en/search-course/course/92138\n28\nISC 2310: Computational Thinking for Data Science with Python\nScientific Computing\nFSU\nAlgebra\nPython\nhttps://www.dropbox.com/scl/fi/hll6h0dt3p7q6j35wgqyu/syllabus_2310_online.pdf?rlkey=ap0o6kmsqnkpuj1ygddj0wqzu&e=1&dl=0\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\nQuotes are not sourced from all markets and may be delayed up to 20 minutes. Information is provided 'as is' and solely for informational purposes, not for trading purposes or advice.\nDisclaimer\nSyllabi\nA browser error has occurred.\nPlease hold the Shift key and click the Refresh button to try again."}
{"url": "https://catalog.foothill.edu/course-outlines/C-S-8A/", "text": "C S 8A: INTRODUCTION TO DATA SCIENCE < Foothill College\nSkip to Content\nAZ Index\nCatalog Home\nFoothill College Home\nSearch catalog\nSubmit search\nAcademic Catalog\nToggle menu\nHome\nCourses\nIndex\n2025-2026 Edition\n2025-2026 Edition\nSearch Courses\nDegrees &​ Certificates\nAbout Us\nAcademic Calendar\nAcademic Policies\nCampus Information\nCareer Education &​ Apprenticeship Programs\nCommon Course Numbering\nDegree &​ Certificate Requirements\nFaculty &​ Staff\nFinancial Planning &​ College Costs\nOnline Education\nPrograms of Study\nStudent Life\nStudent Services\nCourses A-​Z\nCourse Outlines of Record\nC S 8A: INTRODUCTION TO DATA SCIENCE\nAddendum\nCatalog Archives\nIndex\nPrint Options\nHome\n›\nCourse Outlines of Record\n›\nC S 8A: INTRODUCTION TO DATA SCIENCE\nC S 8A: INTRODUCTION TO DATA SCIENCE\nFoothill College Course Outline of Record\nFoothill College Course Outline of Record\nHeading\nValue\nEffective Term:\nSummer 2024\nUnits:\n4.5\nHours:\n4 lecture, 2 laboratory per week (72 total per quarter)\nAdvisory:\nStudents will benefit from some experience with computer programming or statistics; demonstrated proficiency in English by placement via multiple measures OR through an equivalent placement process OR completion of ESLL 125 & ESLL 249.\nDegree & Credit Status:\nDegree-Applicable Credit Course\nFoothill GE:\nNon-GE\nTransferable:\nCSU/UC\nGrade Type:\nLetter Grade (Request for Pass/No Pass)\nRepeatability:\nNot Repeatable\nStudent Learning Outcomes\nA successful student will be able to analyze data using simulation models and statistical techniques such as calculation of summary statistics, calculation of confidence intervals, and regression, and will be able to interpret findings from these techniques.\nA successful student will be able to explain key data science concepts such as correlation vs. causation, randomness, sampling, and uncertainty.\nA successful student will be able transform raw data to a more interpretable format by creating tables, charts, and plots using a modern software language.\nDescription\nIntroduction to the fundamental concepts and computational skills needed to understand and analyze data arising from real-world phenomena. Topics include key data science concepts such as correlation vs. causation, randomness, sampling, uncertainty, predictive models, and classification. Using a tool such as Jupyter notebooks, students write code for transformation and use of data tables, simulation models, and A/B testing.\nCourse Objectives\nThe student will be able to:\nWrite and execute code in an environment such as Jupyter notebook.\nUse expressions, variables, comparisons, control statements, iteration, arrays, and function calls in writing a computer program.\nTransform raw data into tables and manipulate data tables using a package such as pandas, babypandas, or datascience.\nCreate and interpret a histogram, bar chart, line plot, and scatter plot.\nDefine and use a function in a computer program.\nGroup data by one or more attributes, apply a function (\"split-apply-combine\"), and interpret the results.\nJoin structured data tables.\nCalculate probability that an event occurs and describe the situations where probabilities are added vs. multiplied.\nExplain randomness, sampling, probability distributions, and sample mean at an introductory level.\nDescribe simulation models and the use of bootstrap.\nDesign, perform, and interpret hypothesis tests using simulation models.\nDescribe the meaning of variability in data.\nDescribe the relationship between sample size, accuracy of an estimate, and margin of error in light of the central limit theorem.\nCalculate and interpret confidence intervals.\nInterpret correlation coefficients.\nDescribe how linear and logistic regression can be used for predictive models.\nDescribe the general workings of classification.\nDistinguish between causation measured through randomized experiments vs. association observed and describe why trends do not necessarily describe causal scenarios.\nCourse Content\nObservational and experimental data\nTreatment/variable/feature, observation, outcome, association\nTreatment group, control group, randomization, randomized controlled experiment/trial\nComparison, causality\nUse of an environment like Jupyter notebook for writing and executing code\nIntroduction to programming\nExpressions\nNamed variables\nCall expressions\nNumeric and string data types\nComparisons\nArrays\nConditional statements\nIteration\nTables\nReading data into a table from a file\nSelecting columns\nSelecting rows by index or feature\nSorting tables\nData visualization\nScatter plots, line plots, and bar charts\nBest practices\nBinning data\nHistograms\nPlotting more than one category with scatter plots, line plots, and bar charts\nFunctions\nSignature\nDocstring\nBody\nReturn statement\nApplying functions to data tables\nApplying a function to a column\nClassifying by one variable (split-apply-combine)\nComputing counts, summary statistics, or other operations by group\nClassifying by more than one variable\nCreating pivot tables\nCombining information from two or more tables using inner, outer, left, or right join functions\nChance\nProbability as a fraction\nMultiplying probabilities\nAdding probabilities\nProbability of at least one event\nRandomness\nUse of random number generator\nSampling and empirical distributions\nSampling at random vs. deterministically\nSampling with and without replacement\nLaw of averages\nCreating a histogram of sampled values\nUniform distribution\nSimulations using random sampling\nTesting hypotheses\nComparing simulation results of numeric variables to expected distributions\nComparing simulation results of categorical variables to expected distributions\nStatistical bias\nNull vs. alternative hypotheses\nTest statistics\nP-values\nComparing samples\nObservational analysis with hypothesis testing\nRandomized controlled experiments\nMeta-analysis\nEstimation\nPercentiles\nBootstrap\nConfidence intervals\nCentral tendency and variability\nMean\nVariability\nStandard deviation\nNormal distribution\nCentral limit theorem\nRegression\nCorrelation\nLinear regression\nLeast squares\nResiduals\nRegression for prediction and inference\nFitted values\nInterpretation of regression coefficients and confidence intervals\nClassification\nTraining and testing datasets\nClassifier examples: nearest neighbor and decision trees\nMeasuring accuracy\nConditional probability\nExamples used throughout course\nEconomic data\nGeographic data\nDocument collections\nSocial networks\nPublic health\nSports\nLaw\nMedicine\nScience\nLiterature\nOther data science issues\nSocial and legal issues around data analysis\nPrivacy\nData ownership\nLab Content\nFamiliarization with an environment such as Jupyter\nNavigating the environment\nRunning code\nReading and understanding error messages\nExpressions\nUsing mathematical expressions\nDefining variables\nTable operations\nFinding total number of columns and rows\nFiltering by columns and rows\nCreating tables by typing in values or by reading from files\nData types and creating and extending tables\nString methods\nConverting between string and numeric data types\nCreating, operating on, and indexing arrays\nFunctions and visualizations\nCalling functions\nDefining functions\nMaking functions that call other functions\nApplying functions to columns of a table\nVisualizations\nCreating a histogram\nCreating a line plot\nCreating a scatter plot\nConditional statements, iteration, simulation\nWriting conditional statements\nCreating loops\nGenerating a random choice\nProducing random samples\nBuilding a simulation\nA/B testing\nDesigning a simulation\nChoosing and applying a test statistic\nInterpreting the result\nSample means\nDetermining a sample mean from the results of a simulation\nVarying parameters in a simulation to demonstrate concepts related to the Central Limit Theorem\nUsing bootstrapping to produce confidence intervals\nRegression\nAssessing correlation\nFitting a best fit line to a scatter plot\nUsing bootstrapping to produce a confidence interval on best fit line slope\nConditional probability\nOther\nImporting code modules or libraries\nSpecial Facilities and/or Equipment\n1. Instructor access to a cloud provider such as Google Cloud, Microsoft Azure, Amazon EC2, or IBM Cloud.\n2. A Kubernetes-based deployment of JupyterHub or similar and an assignment server that loads assignments into the students' environment.\n3. Student access to a computer lab with the latest version of Anaconda or similar and an appropriate web browser installed.\n4. Website or course management system with an assignment posting component and a forum component (where students can discuss course material and receive help from the instructor). This applies to all sections, including on-campus (i.e., face-to-face) offerings.\n5. When taught via distance learning, the college will provide a fully functional and maintained course management system through which the instructor and students can interact.\n6. When taught via distance learning, students must have currently existing email accounts and ongoing access to computers with internet capabilities.\nMethod(s) of Evaluation\nMethods of Evaluation may include but are not limited to the following:\nTests and quizzes\nLaboratory assignments and projects which include source code, sample runs, and documentation\nWritten homework\nFinal examination\nMethod(s) of Instruction\nMethods of Instruction may include but are not limited to the following:\nLectures which include data science concepts, example code, and analysis of data science examples\nOnline labs (for all sections, including those meeting face-to-face/on-campus), consisting of:\n1. A programming assignment webpage located on a college-hosted course management system or other department-approved internet environment. Here, the students will review the specification of each programming assignment and submit their completed lab work\n2. A discussion webpage located on a college-hosted course management system or other department-approved internet environment. Here, students can request assistance from the instructor and interact publicly with other class members\nDetailed review of programming assignments which includes model solutions and specific comments on the student submissions\nIn-person or online discussion which engages students and instructor in an ongoing dialog pertaining to all aspects of designing, implementing, and analyzing programs\nWhen course is taught fully online:\n1. Instructor-authored lecture materials, handouts, syllabus, assignments, tests, and other relevant course material will be delivered through a college-hosted course management system or other department-approved internet environment\n2. Additional instructional guidelines for this course are listed in the attached addendum of CS department online practices\nRepresentative Text(s) and Other Materials\nAdhikari, Ani, John DeNero, and David Wagner.\nComputational and Inferential Thinking: The Foundations of Data Science\n. 2022.\nTypes and/or Examples of Required Reading, Writing, and Outside of Class Assignments\nReading\nTextbook assigned reading averaging 30 pages per week\nReading the supplied handouts and modules averaging 10 pages per week\nReading online resources as directed by instructor though links pertinent to programming\nReading library and reference material directed by instructor through course handouts\nWriting\nWriting technical prose documentation that supports and describes the programs that are submitted for grades\nDiscipline(s)\nComputer Science\n© 2025-2026\nBack to top\nClose this window\nPrint Options\nSend Page to Printer\nPrint this page.\nDownload Page (PDF)\nThe PDF will include all information unique to this page.\nFoothill College Catalog 2025-2026 - Effective Fall 2025\nA PDF of the entire 2025-2026 catalog, effective Fall Quarter 2025.\nFoothill College Catalog - Summer 2025\nA PDF of the entire catalog, applicable to Summer Session 2025 only."}
{"url": "https://beanumber.github.io/sds192/syllabus.html", "text": "Syllabus\nSDS 192: Interterm 2021\nSyllabus\nSchedule\nStandards\nResources\nModern Data Science with R\nTroubleshooting R Markdown\nDataCamp\nSyllabus\nInstructor\nBen Baumer\nbbaumer@smith.edu\n413-585-3440\n@\nBaumerBen\nbeanumber\nbeanumber\nStudents hours:\nTuesdays and Thursdays from 9:30 am – 10:30 am ET\nby appointment\nall office hours\nvia Zoom\nOsman Keshawarz\n, Data Research and Statistics Counselor\nokeshawarz@smith.edu\nDrop-in hours:\nTuesdays and Thursdays from 6:00 pm – 8:20 pm ET\nby\nappointment\nall office hours via Zoom\nDescription\nAn introduction to data science using Python, R, and SQL. Students will learn how to scrape, process, and clean data from the web; manipulate data in a variety of formats; contextualize variation in data; construct point and interval estimates using resampling techniques; visualize multidimensional data; design accurate, clear, and appropriate data graphics; create data maps and perform basic spatial analysis; and query large relational databases. No prerequisites, but a willingness to write code is necessary.\nTextbooks\nRequired\nModern Data Science with R\n2nd edition\nBaumer, Kaplan, and Horton\nCRC Press, 2021\nWeb version:\nhttps://mdsr-book.github.io/mdsr2e\nPrint version:\n2nd edition is not out yet!!\n: ~$80. (\nCRC\n|\nAmazon\n)\n1st edition\n: ~$100. (\nCRC\n|\nAmazon\n)\nRecommended\nR for Data Science\nGarrett Grolemund and Hadley Wickham\nO’Reilly, 2017\nWeb version:\nhttp://r4ds.had.co.nz/\nSuggested as supplementary references:\nDataCamp\n, online programming courses for data science. Available for free.\nPlease be aware of\nsexual harassment incident!\nThe Visual Display of Quantitative Information\n, Edward Tufte, Graphics Press, 2001. Hardcover is $27-40.\nVisualize This!\nor\nData Points\n, Nathan Yau.\nPaperbacks ~$20\nFundamentals of Data Visualization\n, Claus O. Wilke, free online\nData Visualization: A practical introduction\n, Kieran Healy, free preview online\nClasses\nClasses meet Monday–Friday from 1:40 pm – 2:55 pm ET via Zoom. All classes will be recorded for asynchronous viewing. Attendance will not be taken. It is your decision to come to class or not. If you do come to class, please be prepared to participate fully. Class time will mostly consist of discussions, Q&A sessions, live coding demonstrations, and group work.\nEvening sessions will take place Tuesdays and Thursdays from 7:05 – 8:20 pm ET. These sessions have no agenda, and are reserved for collaborative studying, group project work, and other support mechanisms. Evening sessions will be led by Osman Keshawarz, the Data Research and Statistics Counselor at the Spinelli Center.\nThis is a 4-credit course, meaning that by federal guidelines, it should consume about 28 hours per week of your time. We meet for 7 hours per week. That means\nyou should be spending about 21 hours per week\n, or 3 hours per day, on this course\noutside of class.\nWarning:\nYou should be spending about 21 hours per week on this course outside of class.\nAccommodation\nSmith is committed to providing support services and reasonable accommodations to all students with disabilities. To request an accommodation, please register with the Disability Services Office at the beginning of the semester. To do so, call (413) 585-2071 to arrange an appointment with Laura Rauscher, Director of\nDisability Services\n.\nPolicies\nInclusion\nI am committed to fostering a classroom environment where all students thrive. I am committed to affirming the identities, realities and voices of all students, especially those from historically marginalized or underrepresented backgrounds. I am dedicated to creating a space where everyone in the class is respected, is free from discrimination based on race, ethnicity, sexual orientation, religion, gender identity, disability status, and other identities, and feel welcome and ready to learn at your highest potential.\nIf you have any concerns or suggestions for how to make this class more inclusive, please reach out to me.\nI am here to support your learning and growth as data scientists and people!\nAttendance\nYou choose whether you want to attend class. If you choose to attend, I expect your full attention. There is no penalty for not attending class.\nCollaboration\nImportant\nMuch of this course will operate on a collaborative basis, and you are expected and encouraged to work together with a partner or in small groups to study, complete homework assignments, and prepare for exams. However,\nall work that you submit for credit must be your own\n. Copying and pasting sentences, paragraphs, or\nblocks of code\nfrom another student or from online sources is not acceptable and will receive no credit. No interaction with anyone but the instructors is allowed on any exams or quizzes. All students, staff and faculty are bound by the Smith College Honor Code, which Smith has had since 1944.\nAcademic Honor Code Statement\nSmith College expects all students to be honest and committed to the principles of academic and intellectual integrity in their preparation and submission of course work and examinations. Students and faculty at Smith are part of an academic community defined by its commitment to scholarship, which depends on scrupulous and attentive acknowledgement of all sources of information, and honest and respectful use of college resources.\nCases of dishonesty, plagiarism, etc., will be reported to the Academic Honor Board.\nCode of Conduct\nImportant\nAs the instructor and assistants for this course, we are committed to making participation in this course a harassment-free experience for everyone, regardless of level of experience, gender, gender identity and expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, or religion. Examples of unacceptable behavior by participants in this course include the use of sexual language or imagery, derogatory comments or personal attacks, deliberate misgendering or use of “dead” names, trolling, public or private harassment, insults, or other unprofessional conduct.\nAs the instructor and assistants we have the right and responsibility to point out and stop behavior that is not aligned to this Code of Conduct. Participants who do not follow the Code of Conduct may be reprimanded for such behavior. Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the instructor.\nAll students, the instructor, the lab instructor, and all assistants are expected to adhere to this Code of Conduct in all settings for this course: lectures, labs, office hours, tutoring hours, and over Slack.\nThis Code of Conduct is adapted from the\nContributor Covenant\n, version 1.0.0, available\nhere\n.\nGrading\nThis course will employ\nstandards-based assessment\n. There are\n13 standards\n. Each standard will be assessed in both a\ngroup\nand\nindividual\nsetting. In each setting, each standard that is met earns a student one point. Each standard that is mastered earns a student two points. Points are redeemed for grades as follows:\ngrade\nrange\ncomment\nA+\n50–53\nlet me show you these PhD programs… 🎉\nA\n46–49\nyou’re applying for data science jobs, right?\nA-\n44–45\nhave you thought about being a Data Assistant?\nB+\n42–43\nwe should talk about an SDS major\nB\n40–41\nwell-prepared for the next challenge\nB-\n36–39\nC\n26–35\nsufficient progress to continue in SDS\nD\n20–25\nE\n0–19\nGroup points are earned by meeting standards on mini-projects, for which you will work primarily in pairs. Individual points are earned by meeting standards on quizzes, which will be administered via Moodle. One bonus point is available for exceptional active engagement with the class. Thus, there are\n53 total points possible\n(13 standards\n\\(\\times\\)\n2 settings\n\\(\\times\\)\n2 possible points + 1 possible engagement point). Please see\nAssignments\nbelow for more information.\nPlease read some\nguidelines for group work\n.\nAssignments\nCollected\nThese assignments are mandatory and graded.\nMini-Projects: You will work on five group projects over the course of the semester. These projects will be structured, but fairly open-ended to allow you be creative. Mini-projects are the mechanism through which you meet group standards, and are in many ways the most important part of the course.\nQuizzes: Quizzes are the mechanism through which you meet individual standards. Each standard will have one quiz administered via Moodle. Quizzes will consist involve computational assignments in\nR\nand/or\nSQL\n, possibly with written explanations. A student may attempt a quiz up to three times.\nOther ways to earn points\nThese assignments may or may not be collected or affect your grade.\nEngagement: Students can earn one bonus point through active participation in class, answering questions on or GitHub, or exceptional engagement with group work. This is\nnot\na given—only about one-quarter of students will earn this point.\nUncollected assignments\nThese assignments are not collected and will not affect your grade. However, I still expect that you will do them! These assignments are\nnot optional\nand are major component of your learning in this course.\nScreencasts: Each topic will have an associated screencast. You should watch the screencasts.\nReadings: Each topic will be associated with a different section of the book. You should read those sections of the book.\nLabs: Each topic will be accompanied by a lab assignment. You should attempt these labs assigments. Students are strongly encouraged to\nwork in pairs\nduring these labs.\nExtensions\nExtensions up to 24 hours will typically be granted\nwhen requested at least 24 hours in advance\n. Longer extensions, or those requested within 24 hours of a deadline will typically not be granted. Please plan accordingly. Please note that because many of the assignments in this class are collaborative, individual extensions for group assignments will be problematic.\nAll extended deadlines will appear on Moodle.\nWorkflow\nYou will complete all of your homework assignments in\nR Markdown\n. Unless otherwise noted, you should expect to submit your assignment by uploading an R Markdown file (with a\n.Rmd\nfile extension) to Moodle. You should use the template from the\nsds192\npackage\nfor all assignments.\nResources\nMoodle and course website\nThe\ncourse website\nand Moodle will be updated regularly with lecture handouts, project information, assignments, and other course resources. Homework and grades will be submitted to Moodle. Please check both regularly.\nComputing\nThe use of the\nR\nstatistical computing environment with the\nRStudio\ninterface is thoroughly integrated into the course. Both\nR\nand\nRStudio\nare free and open-source, and are installed on most computer labs on campus. Please see the\nResources\npage for help with\nR\n. If you have a Chromebook, you should be able to complete the assignments using the\nRStudio Server\n. Please see me if you don’t already have an account.\nUnless otherwise noted, you should assume that it will be helpful to bring a laptop to class. If you do not have a laptop, there are loaner laptops available – please contact me if you need one.\nCommunication\nGitHub Organization\nSlack\nis the primary mechanism for course-related discussions of all kinds.\nPlease do not email me with course-related questions!\nInstead, post these on\n#questions\non Slack. If discretion is absolutely necessary, private message me on Slack.\nWriting\nYour ability to communicate results—which may be technical in nature—to your audience—which is likely to be non-technical—is critical to your success as a data analyst. The assignments in this class will place an emphasis on the clarity of your writing.\nThe Spinelli Center\nThe\nSpinelli Center\n(now in Seelye 207) supports students doing quantitative work across the curriculum. In particular, they employ:\nData assistants\nwho will visit our class regularly. These are students who have taken this class before and are trained to help you with this material. Don’t be shy about flagging them down!\nStatistics TAs\navailable from 7:00–9:00pm on Sunday–Thursday evenings in Burton 301. These students are trained to help you with your statistics questions, but may or may not be able to help you with your R questions.\nA\nData Research and Statistics Counselor\n(Osman Keshawarz) who keeps both\ndrop-in hours\nand appointments. Students are welcome to email\nqlctutor@smith.edu\nto make an appointment with either the Data Counselor or one of the Data Assistants.\nYour fellow students are also an excellent source for explanations, tips, etc.\nTentative Schedule\nThe following outline gives a\nbasic\ndescription of the course. Please see the\ndetailed schedule\nfor more specific information about readings and assignments.\nWeek\nTopic\nReading\nAssignments\n1\ndata visualization\nMDSR\n, Ch. 1–2\n2\ngrammar of graphics\nMDSR\n, Ch. 3, 8\nmini-project\n3\ngrammar of data wrangling\nMDSR\n, Ch. 4–5\nmini-project\n4\niteration\nMDSR\n, Ch. 6–7\nmini-project\n5\nspatial data\nMDSR\n, Ch. 17–18\nmini-project\n6\ndatabase querying\nMDSR\n, Ch. 15–16\nmini-project\nCreated by\nBen Baumer\nand\nR. Jordan Crouser."}
{"url": "https://catalog.luc.edu/undergraduate/continuing-professional-studies/introduction-data-science-certificate/#curriculumtext", "text": "Introduction to Data Science Certificate: Loyola University Chicago\nSkip to Content\nAZ Index\nCatalog Home\nA-Z\nContact\nDirectories\nLocus\nSupport LUC\nLoyola University Chicago\n2025-2026 Academic Catalog\nMenu\nCatalog Contents\nA-Z Index\nPrograms\nCourses\nApply\nInfo\nVisit\nSearch catalog\nSubmit search\nApply Now\nGet Info\nCome Visit\nCatalog Contents\nA-Z Index\nPrograms\nCourses\nLoyola University Chicago\n1032 W. Sheridan Rd.\nChicago, IL 60660\n773.274.3000\n©\nCopyright & Disclaimer 2023\nLoyola University Chicago\n2025-2026 Catalog\nThe Academic Catalog is the official listing of courses, programs of study, academic policies and degree requirements for Loyola University Chicago. It is published every year in advance of the next academic year.\nPrograms\nCourse Descriptions\nUndergraduate\nGraduate and Professional\nAdditional Resources\nSchool and Academic Centers and Institutes\nAcademic Standards and Regulations\nProfessional License Disclosures\nAccreditation\nFaculty\nFacebook Icon\nTwitter Icon\nLinkedin icon\nInstagram Icon\nYoutube Icon\n2025-2026 Edition\n2025-2026 Edition\nPrograms\nUndergraduate Catalog\nArrupe College\nCollege of Arts and Sciences\nJohn Felice Rome Center\nMarcella Niehoff School of Nursing\nParkinson School of Health Sciences and Public Health\nPre-​Professional Programs\nQuinlan School of Business\nSchool of Communication\nSchool of Continuing and Professional Studies\nApplied Psychology (BA)\nApplied Psychology/​Public Service Leadership (BA/​MA)\nApplied Studies (BA)\nComputer Science Certificate\nCybersecurity Technology Management Certificate\nEnvironmental Policy/​Public Policy (BA/​MPP)\nEnvironmental Science/​Public Policy (BS/​MPP)\nEnvironmental Studies/​Public Policy (BA/​MPP)\nInformation Technology (BA)\nInformation Technology (BA/​MS)\nInformation Technology/​Computer Science (BA/​MS)\nInformation Technology/​Information Technology Leadership and Strategy (BA/​MPS)\nInformation Technology/​Instructional Design (BA/​MPS)\nIntroduction to Data Science Certificate\nManagement (BA)\nManagement/​Information Technology Leadership and Strategy (BA/​MPS)\nManagement/​Instructional Design (BA/​MPS)\nManagement/​Public Service Leadership (BA/​MA)\nNew Media Communication Certificate\nOrganizational Development and Leadership Certificate\nOrganizational Psychology Certificate\nParalegal Studies (BA)\nStrategic Digital Communication (BA)\nUser Experience Design Certificate\nWeb Design and Development Certificate\nWeb Technologies (BA)\nWeb Technologies/​Information Technology Leadership and Strategy (BA/​MPS)\nWeb Technologies/​Instructional Design (BA/​MPS)\nSchool of Education\nSchool of Environmental Sustainability\nSchool of Social Work\nAccelerated Bachelor's/​Master's Program\nUniversity Requirements\nGraduate and Professional Catalog\nSchool and Academic Centers and Institutes\nAccreditation\nAcademic Standards and Regulations\nProfessional License Disclosures\nFaculty\nCourse Descriptions\nSearch Courses\nArchived Catalogs\nPrint Options\nHome\n›\nUndergraduate Catalog\n›\nSchool of Continuing and Professional Studies\n›\nIntroduction to Data Science Certificate\nIntroduction to Data Science Certificate\nOverview\nCurriculum\nLearning Outcomes\nThis 3-course certiﬁcate introduces students to the key elements of Data Science: Python programming, SQL & database design, data processing, and analysis & visualization. The certificate provides any professional valuable, widely applicable, and transferable skills.\nCoursework explores the topics of data ethics and digital ethics. The certificate is intended to help prepare the student for a dynamic career in data analytic work, whether they seek to grow their existing career, switch to a career within the data science realm, or explore data science as a ﬁeld before committing to a degree program or advanced study in the topic.\nRelated Programs\nCertificate\nComputer Science Certificate\nCombined\nData Science (BS/MS)\nCurriculum\nCourse List\nCode\nTitle\nHours\nCertificate Requirements\nCOMP 251\nIntroduction  to Database Systems\n3\nCPST 291\nDynamic Programming Languages\n3\nCPST 325\nData Processing, Analysis, and Visualization\n3\nTotal Hours\n9\nOptional:\nCPST 265\nSpecial Topics\n– 1-3 credits of directed study. Student will solve a data science problem for a community non-proﬁt organization under the guidance of a faculty member. Larger projects will be 3 credit hours held only on the 16-week semester schedule for either fall or spring. Summer will not be an option for a 3-credit hour special topics course. Interested students should start the process at least 6-weeks before the semester where you will potentially complete the course.\nSuggested Sequence of Courses\nThe School of Continuing and Professional Studies provides a high-touch advising model in order to incorporate the professional and educational outcomes of the student as well as any transfer credit accepted.  In order to provide students with maximum flexibility in their education and because everyone’s academic background will vary, advisors will work directly with students to determine an appropriate sequence of courses starting at admission into their respective program based on their needs and expected time to completion.\nLearning Outcomes\nUpon completion of the certificate, graduates will be able to:\nCreate data analytic programs that perform rigorous statistical analyses to address real-world questions in the social sciences.\nEvaluate datasets to determine how variables have been measured and encoded, which statistical analyses can be performed upon them, and which data cleaning and preparation protocols are necessary in order to proceed.\nApply the relational model to solving real-world problems using SQL on standard DBMS platforms.\nApply the programming languages of Python and SQL to specific data analytic and visualization challenges, as well as to generate novel code.\nAnalyze the ethical considerations relevant to accurate data analysis and reporting.\nFacebook icon\nX Twitter icon\nLinkedin icon\nInstagram icon\nYoutube icon\nLoyola University Chicago\n1032 W. Sheridan Rd., Chicago, IL 60660\n773.274.3000\ndigitalteam@luc.edu\n© Copyright & Disclaimer 2024\nPrivacy Policy\nBack to top\nSearch catalog\nSearch\n×\nClose Search\nClose this window\nPrint Options\nSend Page to Printer\nPrint this page.\nDownload Page (PDF)\nThe PDF will include all information unique to this page."}
{"url": "https://info2950.infosci.cornell.edu/course-syllabus.html", "text": "INFO 2950 – Syllabus\nCourse information\nSyllabus\nGradescope\nGrades\nDiscussion forum\nCourse information\nOverview\nSyllabus\nSupport\nCourse staff\nSchedule\nUseful links\nFAQ\nComputing\nAccess\nCheatsheets\nLab\nLab 00 - Hello R!\nLab 01 - Data visualization\nLab - Project proposal\nLab 02 - Data tidying\nLab 03 - Git workflows\nLab 04 - Money in U.S. politics\nLab 05 - Smoking during pregnancy\nLab - Project draft peer review\nHomework\nHW 00 - Statistics diagnostic\nHW 01 - Data visualization\nHW 02 - Data wrangling\nHW 03 - Import + clean data\nHW 04 - Analyze socioeconomic data for countries\nHW 05 - Regressing socioeconomic data\nHW 06 - Prediction + Bootstrap\nHW 07 - Predicting attitudes towards marijuana\nHW 08 - Predicting Kickstarter funding\nExam\nExam 01\nExam 02\nProject\nDescription\nTips + resources\nExtra credit\nDescription\nTutorials\nOn this page\nINFO 2950 - Introduction to Data Science\nInstructor\nCourse logistics\nCourse description\nCourse learning objectives\nOffice hours\nTextbooks\nCourse community\nAcademic accommodations\nAccessibility\nCommunication\nWhere to get help\nEmail\nActivities & Assessment\nLectures (Prepare)\nApplication exercises (Practice)\nLabs (Perform)\nHomework (Perform)\nExams (Perform)\nProject (Perform)\nGrading\nCourse policies\nAcademic honesty\nExtra credit\nLate work & extensions\nRegrade requests\nCourse information\nSyllabus\nSyllabus\nModified\nApril 29, 2024\nINFO 2950 - Introduction to Data Science\nInstructor\nDr. Benjamin Soltoff\nOffice: Gates Hall 216\nEmail:\ninfo2950@cornell.edu\nOffice hours: Wednesdays 1-3pm (216 Gates Hall)\nCourse logistics\nMeets TuTh 10:10am - 11:24am for 28 sessions\nDiscussion sections meet Fridays at various times for 15 sessions\n4 credits, offered for a letter grade\nPrerequisites: (MATH 1710 or equivalent AND CS 1110 or CS 1112) OR permission of instructor\nCourse description\nThis is an applied introductory course for learners who wish to harness growing digital and computational resources. The focus of the course is on using data to identify patterns, evaluate the strength and significance of relationships, and generate predictions using\ndata\n. These techniques are implemented using a\nreproducible workflow\nthrough the use of programming languages and version control software. Major emphasis is placed on a pragmatic understanding of core principles of programming and packaged implementations of methods. Students will learn how to use data to make effective arguments, in a way that promotes the ethical usage of data.\nCourse learning objectives\nBy the end of the semester, you will…\nConduct exploratory data analysis through data wrangling and munging as well as visualizations and summary statistics.\nIdentify patterns in data to make predictions or to identify associations between variables.\nEvaluate the strength of patterns using statistical and substantive significance.\nImplement data science workflows using common, reproducible methods and software tools.\nUse data ethically and responsibly.\nOffice hours\nInstructor and undergrad TA OHs\n- you may attend office hours for any undergrad TA (as well as the instructor!)\nProject mentor OHs\n- please feel free to meet with your\nproject mentor\nif you have questions about your team projects.\nTextbooks\nAll books are\nfreely available online\n.\nR for Data Science, 2e\nGrolemund, Wickham\nO’Reilly, 2nd edition, 2022\nHard copy only available of 1st edition\nIntroduction to Modern Statistics\nÇetinkaya-Rundel, Hardin\nOpenIntro Inc., 1st Edition, 2021\nHard copy available\non Amazon\nCourse community\nWe want you to feel like you belong in this class and are respected. Cornell University (as an institution) and we (as human beings and instructors of this course) are committed to full inclusion in education for all persons. If for any reason you feel that we have failed these goals, please either let us know or\nreport it\n, and we will address the issue.\nServices and reasonable accommodations are available to persons with temporary and permanent disabilities, to students with DACA or undocumented status, to students facing mental health or other personal challenges, and to students with other kinds of learning challenges. Please feel free to let me know if there are circumstances affecting your ability to participate in class. Some resources that might be of use include:\nOffice of Student Disability Services:\nhttps://sds.cornell.edu\nCornell Health CAPS (Counseling & Psychological Services):\nhttps://health.cornell.edu/services/counseling-psychiatry\nUndocumented/DACA Student support:\nhttps://dos.cornell.edu/undocumented-daca-support/undergraduate-admissions-financial-aid\nAcademic accommodations\nWe want all students to have the opportunity to be successful in this course. Accommodations can help provide some flexibility and equitable classroom access.\nPer\nuniversity policy\n, this course provides the following accommodations:\nDisability Accommodations\nReligious-Observance Accommodations\nTitle IX Accommodations\nVarsity Athlete Accommodations\nMedical Accommodations\nMilitary Service\nOther Accommodations\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nStudent Disability Services\nis available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with Student Disability Services to\nrequest or update accommodations\nunder these circumstances.\nIf you have an approved SDS accommodation, please send a copy of this letter to the instructors at\ninfo2950@cornell.edu\nso we can ensure your accommodations are implemented in this course.\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course website:\ninfo2950.infosci.cornell.edu\n.\nAnnouncements will be posted through Canvas Announcements periodically. Please check Canvas (or ensure Canvas announcements are forwarded to your email) to ensure you have the latest announcements for the course.\nWhere to get help\nIf you have a question during lecture or discussion, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe course staff is here to help you be successful in the course. You are encouraged to attend office hours to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. Please use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted on the\ncourse discussion forum\n. There is a chance another student has already asked a similar question, so please check the other posts on GitHub Discussions before adding a new question. If you know the answer to a question posted on the discussion board, I encourage you to respond!\nEmail\nIf there is a question that’s not appropriate for the public forum, please email us at\ninfo2950@cornell.edu\n. Barring extenuating circumstances, we will respond to INFO 2950 emails within 48 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.\nActivities & Assessment\nThe activities and assessments in this course are designed to help you successfully achieve the course learning objectives. They are designed to follow the\nPrepare, Practice, Perform\nformat.\nPrepare\n: Includes reading assignments and lectures to introduce new concepts and ensure a basic comprehension of the material. The goal is to help you prepare for the in-class activities during lecture.\nPractice\n: Includes in-class application exercises where you will begin to apply the concepts and methods introduced in the prepare assignment. The activities will graded for completion, as they are designed for you to gain experience with the statistical and computing techniques before working on graded assignments.\nPerform\n: Includes labs, homework, exams, and the project. These assignments build upon the prepare and practice assignments and are the opportunity for you to demonstrate your understanding of the course material and how it is applied to analyze real-world data.\nLectures (Prepare)\nPart of the class time will be lectures that introduce new concepts or review topics from the preparation materials. Lectures will\nnot\nrepeat everything in the readings, they will instead highlight important and known to be complex concepts and will be supplemented with live coding activities. You are expected to attend every lecture.\nApplication exercises (Practice)\nA majority of the in-class lectures will be dedicated to working on Application Exercises (AEs). These exercises will give you an opportunity to apply the statistical concepts and code introduced in the prepare assignment. These AEs are due within one day of the corresponding lecture period. Specifically, AEs from Tuesday lectures are due Wednesday by 11:59 pm, and AEs from Thursday lectures are due Friday by 11:59 pm.\nBecause these AEs are for practice, they will be graded based on completion, i.e., a good-faith effort has been made in attempting all parts. Successful on-time completion of\nat least 85%\n(i.e. we drop the\nfour lowest grades\n) of AEs will result in full credit for AEs in the final course grade.\nLabs (Perform)\nIn labs, you will apply the concepts discussed in lecture to various data analysis scenarios, with a focus on the computation. Most lab assignments will be completed in teams, and all team members are expected to contribute equally to the completion of each assignment. You are expected to use the team’s Git repository on the course’s GitHub page as the central platform for collaboration. Commits to this repository will be used as a metric of each team member’s relative contribution for each lab, and there will be periodic peer evaluation on the team collaboration. Lab assignments will be completed using Quarto, correspond to an appropriate GitHub repository, and submitted for grading in Gradescope.\nLabs are due 11:59 pm on the indicated due date.\nThe lowest lab grade will be dropped at the end of the semester.\nHomework (Perform)\nIn homework, you will apply what you’ve learned during lecture and lab to complete data analysis tasks. You may discuss homework assignments with other students; however, homework should be completed and submitted individually. Similar to lab assignments, homework must be typed up using Quarto and GitHub and submitted as a PDF in Gradescope.\nHomework assignments are due 11:59 pm on the indicated due date.\nThe lowest homework grade will be dropped at the end of the semester.\nExams (Perform)\nThere will be two exams during the semester.\nOne take-home exam approximately halfway through the course.\nOne in-person final exam.\nMore details about the content and structure of the exams will be discussed during the semester.\nProject (Perform)\nThe purpose of the\nproject\nis to apply what you’ve learned throughout the semester to solve some sort of real-world problem. The project will be completed with your lab teams, and each team will present their work at the end of the semester.\nMore information about the project will be provided during the semester.\nGrading\nThe final course grade will be calculated as follows:\nCategory\nPercentage\nExams\n25%\nExam 01\n12%\nExam 02\n13%\nHomework\n25%\nProject\n25%\nLabs\n15%\nApplication Exercises\n10%\nThe final letter grade will be determined based on the following thresholds:\nLetter Grade\nFinal Course Grade\nA+\n>= 98\nA\n93 - 97.99\nA-\n90 - 92.99\nB+\n87 - 89.99\nB\n83 - 86.99\nB-\n80 - 82.99\nC+\n77 - 79.99\nC\n73 - 76.99\nC-\n70 - 72.99\nD+\n67 - 69.99\nD\n63 - 66.99\nD-\n60 - 62.99\nF\n< 60\nCourse policies\nAcademic honesty\nTL;DR: Don’t cheat!\nPlease abide by the following as you work on assignments in this course:\nYou may discuss individual homework and lab assignments with other students; however, you may not directly share (or copy) code or write up with other students. For team assignments, you may collaborate freely within your team. You may discuss the assignment with other teams; however, you may not directly share (or copy) code or write up with another team. Unauthorized sharing (or copying) of the code or write up will be considered a violation for all students involved.\nYou may not discuss or otherwise work with others on the exams. Unauthorized collaboration or using unauthorized materials will be considered a violation for all students involved. More details will be given closer to the exam date.\nReusing code\n: Unless explicitly stated otherwise, you may make use of online resources (e.g. StackOverflow) for coding examples on assignments. You may not directly copy and paste from these sources, but instead you need to adapt the code to fit your specific task. You must explicitly cite where you obtained the code using a code comment\n#\nimmediately near the appearance of the reused code in the file. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nUse of generative artificial intelligence (GAI)\n:\nCornell’s report on Generative Artificial Intelligence for Education and Pedagogy\noutlines many of the potential benefits and drawbacks to using GAI in the classroom. In this course, we see the value of coding assistants such as GitHub Copilot and ChatGPT to generate code from text. However as an introductory course, we need to ensure that GAI is not used as a substitute or replacement for student learning. GAI should not be used by students to replace your ability to think clearly. Students who use GAI should use it to\nfacilitate\n, rather than\nhinder\n, learning.\n✅\nGAI tools for reference purposes:\nYou may make use of the technology as a reference tool, similar to looking up the documentation for a function or Googling your problem. For example, I hate writing regular expressions. Absolutely loathe it. Say I have a dataset where I need to clean a character column to remove all words that are within double asterisk symbols. I might ask ChatGPT\nHow do I make a scatterplot using\nggplot2\nin R?\n❌\nGAI tools for writing my code/analysis:\nYou may not make use of the technology to complete substantive portions of your assignments for you. For example, you may not upload your data file to a GAI platform and ask it to create charts and statistical models for you.\n❌\nGAI tools for narrative:\nunless instructed otherwise, you may not use GAI to write narrative on assignments. In general, you may use generative AI as a resource as you complete assignments but not to answer the exercises for you.\nYou are ultimately responsible for the work you turn in; it should reflect\nyour\nunderstanding of the course content.\nAny violations in academic honesty standards as outlined in the\nCornell University Code of Academic Integrity\nand those specific to this course will result in a 0 for the assignment (or possibly more) and will be reported to the College of Engineering Academic Integrity Hearing Board.\nExtra credit\nStudents can earn up to a maximum of 1 percentage point towards their final grade through the\nextra credit assignment\n. This is the only opportunity for extra credit in the course.\nLate work & extensions\nThe due dates for assignments are there to help you keep up with the course material and to ensure the course staff can provide feedback within a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline. Note that the lowest homework and lab assignment will be dropped to accommodate such circumstances.\nLate work\nA\nslip day\nallows you to submit an assignment 24 hours after the deadline and still receive credit without a late penalty. You are provided with a total of\n6 slip days\nfor the entire semester. Slip days may be used on\nhomework and lab assignments\n. You can use up to 1 slip day for a given homework or lab assignment.\nTo use your slip days, just submit your assignment late. No need to email telling us you are submitting using your slip days. Check Canvas to see how many of your slip days you have used before submitting an assignment late.\nIf you use a slip day,\ndo not submit anything to Gradescope before the submission deadline\n. We may begin grading before the slip day deadline and we will grade whatever submission we see in Gradescope.\nIf you run out of slip days or fail to submit your assignment prior to the slip day deadline without prior permission then your assignment will not be accepted.\nThere is no late work accepted for application exercises, since these are designed to help you prepare for labs and homework.\nThere is no late work accepted for project components.\nThe late work policy for exams will be provided with the exam instructions.\nWaiver for extenuating circumstances\nIf you need a bit of extra time,\nplease use your slip days\n. Slip days are specifically intended for legitimate reasons for needing an extension like disability, religious observance, Title IX, student athletics, medical problems, and military service.\nIf using your slip days for accommodations is not working for you or if you have an SDS accommodation which includes deadline flexibility, you may request a deadline extension in-advance of the deadline. We will work with you to develop reasonable accommodations that align with your individual situation.\nTo request a deadline extension:\nCommit and push the work you have completed up to this point on the assignment.\nEmail\ninfo2950@cornell.edu\n. In your email clearly state\nThe assignment\nWhat you have already completed on the assignment.\nWhat you have left to complete.\nYour proposed deadline extension (e.g.\nMonday, February 8th at 11:59pm.\n)\nRegrade requests\nRegrade requests can be submitted beginning at noon the day after an assignment’s grade is posted, and must be submitted on Gradescope within a week of when an assignment is returned. Regrade requests will be considered if there was an error in the grade calculation or if you feel a correct answer was mistakenly marked as incorrect. Requests to dispute the number of points deducted for an incorrect response will not be considered. Note that by submitting a regrade request, the entire question will be graded which could potentially result in losing points.\nOverview\nSupport\nThis page is built with\nQuarto\n."}
{"url": "https://gofilipa.github.io/fds-spring-23/syllabus.html", "text": "Syllabus — Foundations of Data Science\nSkip to main content\nBack to top\nCtrl\n+\nK\nSyllabus\nCourse Schedule\nData Types and Variables\nFunctions\nLoops and Lists\nNLTK: nltk.book\nNLTK: cleaning part one\nNLTK: cleaning part two\nNLTK: text analysis\ntransformers: introduction\ntransformers: generating language\ntransformers: bias & discrimination\nhomework 0: install python (optional)\nhomework 1: data types and variables\nhomework 2: python basics\nhomework 3: text cleaning\nhomework 4: text analysis\nFinal Project\n.md\n.pdf\nSyllabus\nSyllabus\n#\nCSC 31167: Foundations of Data Science\nInstructor:  Filipa Calado\nEmail:\nfcalado\n@\ngradcenter\n.\ncuny\n.\nedu\nZoom address:\nhttps://nyu.zoom.us/my/filipa.calado\nOffice hours:\nhttps://www.bit.ly/calado_office\nThis course introduces the fundamental concepts and computational techniques of data science to all students, including those majoring in the Arts, Humanities, and Social Sciences. The course will focus on the critical approach to studying data, which emphasizes the importance of understanding and addressing the ways in which power and privilege in social systems shape the collection, analysis, and interpretation of data. This approach centers marginalized identities and experiences and the intersectionality of gender, sexuality, race, and class as factors that shape data creation, our methods for analyzing data, and the conclusions we can draw from it. Students will explore the ways in which a critical approach data science can be used to reinforce or challenge existing power structures and promote social justice.\nThis course begins by contextualizing race, gender, and sexuality as identity formations that are constituted by power structures. Students will then move to deconstructing the role that power and privilege have in shaping data collection and analytical methods, and the need to actively work to counteract these biases in the way we handle and interpret data. This course grounds discussion of intersectionality, power, and privilege with practical experimentation, introducing students to programmatic methods of data analysis with Python. Students will learn methods for inferential and compuational thinking by analyzing text-based data in Python. As they learn to code with Python, students will examine how bias infiltrates computational processes, examining firsthand how the necessity for standards and rules that enable computation can stymie the expression of real-world and human complexity and how statistical methods tend to overlook specificities and generalize difference. By the end of the course, students will have a grasp of how these computational methods for working with text contribute to the bias and toxicity of machine learning methods such as those used to create Large Language Models like\nChatGPT\n.\nThe course is designed for students who are new to statistics and programming. Students will make use of the Python programming language, but no computer science pre-requisites are required.\nPrerequisites: [NA]\nCo-Requisites: [NA]\nCredits/Hours: 3 Credits/3 Hours\nThis course satisfies Pathways Math and Quantitative Reasoning requirement.\nCourse Learning Outcomes:\nInterpret and draw appropriate inferences from quantitative representations, such as formulas, graphs, or tables.\nUse algebraic, numerical, graphical, or statistical methods to draw accurate conclusions and solve mathematical problems.\nRepresent quantitative problems expressed in natural language in a suitable mathematical format.\nEffectively communicate quantitative analysis or solutions to mathematical problems in written or oral form.\nEvaluate solutions to problems for reasonableness using a variety of means, including informed estimation.\nApply mathematical methods to problems in other fields of study.\nRequired Texts/Readings:\nThere is only one book for the course, which is free online: Lauren Klein and Catherine D’Ignazio, Data Feminism.\nhttps://data-feminism.mitpress.mit.edu/\nTechnology:\nIn-class lessons and homeworks are done in Jupyter notebooks. The notebooks assume a Python 3 installation with the standard modules from an Anaconda installation such as NLTK, Pandas, Numpy and Matplotlib. If you have trouble installing python, there are backup solutions, and please reach out to me.\nAssignments overview:\nHomework assignments (20%) - Short coding assignments meant to get you to demonstrate your comprehension of in-class lessons. Includes a short written component. Will be graded on effort rather than accuracy. Prompts are posted on the class website.\nParticipation (30%) - Students are expected to be actively engaged in class activities. This means paying attention to lessons and participating in class discussions. Students are expected to come to class having done the reading and being prepared to give their opinions. For a student who comes to every class (not counting excused absences), is actively listening and engaged, and speaks up at least once during class, they will get 100% on participation.\nFinal project (30%) - Group projects centered on posing a research question and doing exploratory analysis of a dataset. Includes a coding and written component, and groups will present their process and preliminary findings in the last week of class. Instructions will be distributed during the final unit.\nExams (20%) - Midterm and final exam which will assess students’ understanding of data analysis procedures as applied to their own research interests. Format will be jupyter notebooks.\nGrade distributions:\nHomework assignments (20%)\nExams (20%)\nParticipation (30%)\nFinal projects (30%)\nCourse overview:\nUnit 1: Introduction to Python programming\nUnit 2: Introduction to text analysis with NLTK\nUnit 3: Introduction to machine learning with Transformers\nnext\nCourse Schedule\nBy Filipa Calado\n© Copyright 2022."}
{"url": "https://mdav.ece.gatech.edu/ece-4803-fall2020/", "text": "ECE 4803: Mathematical Foundations of Data Science\nECE 4803: Mathematical Foundations of Data Science\nFall 2020\nOverview\nLectures and Notes\nAssignments\nInstructor\nMark Davenport\nEmail: mdav (at) gatech (dot) edu\nOffice Hours: By appointment.\nDescription\nThis course is an introduction to the mathematical foundations of data science and machine learning.  The central theme of the course is the use of linear algebra and optimization in posing and solving modern problems leveraging data focusing on applications in ECE.\nDownload the\nsyllabus\n.\nPrerequisites\nIntroductory courses in linear algebra and multivariable calculus are the main pre-requisites.  Most of the course will use the language of matrices and vectors.  Students should be comfortable with the use of matrices to represent systems of equations and the notion of taking a gradient of a function of many variables -- some existing familiarity with eigenvalues, eigenvectors, and eigenvalue decompositions will be extremely helpful. Familiarity with the basics of probability (especially random variables, expected value, and related notions) will also be useful in understanding some of the applications covered in the course. Finally, students should also have basic Python programming skills.\nInstruction Modality\nIn Fall 2020, ECE 4803 will be taught in a hybrid mode. What this will mean in this course is that, while we do have a room on campus reserved and available (Howey N210 on Tuesdays and Thursdays from 9:30-10:45am), I plan to actually deliver all lectures remotely.  These will be pre-recorded and available to watch at whatever time is most convenient for you. I will reserve our regularly scheduled class hours for (initially online) discussions, working extra examples, answering questions about the homeworks, etc.  These discussions will also be recorded for those who cannot attend.\nI expect that the course will be fully online (meaning that our discussions and office hours will be conducted via BlueJeans) for at least the first 6 weeks of class (September 24).  After that point, I hope to move these discussions to the campus during our regularly scheduled class time. In the event that we do this, I still plan to pre-record my technical lectures and use the class time for discussions and student presentations. I can continue to record these in-person meetings for those who cannot or do not want to attend. For those students who are uncomfortable attending in-person activities, it will be possible to complete this course fully online.\n(Note that the current estimate for the capacity of Howey N210 with social distancing is 8 -- if we move to the campus and there are more than 8 of us who wish to attend in person, we may have to create a rotating schedule for in-person attendance.)\nOur first class meeting will be Tuesday, August 18 at 9:30, via\nBlueJeans\nResources\nThere is no required text. Below is a list of books that I have found helpful over the years for learning (and teaching) the material in this class.\nLinear algebra\nLinear Algebra and its Applications\nby Strang.  (\namazon\n)\nNumerical Linear Algebra\nby Trefethen and Bau.  (\namazon\n)\nMatrix Analysis\nby Horn and Johnson.  (\namazon\n)\nProbability and statistics\nIntroduction to Probability\nby Bertsekas and Tsitsiklis.  (\namazon\n)\nElementary Probability for Applications\nby Durrett.  (\namazon\n)\nAll of Statistics\nby Wasserman.  (\namazon\n)\nOptimization\nConvex Optimization\nby Boyd and Vanderberghe.  (Available as a free pdf from\nauthor's website\n)\nOptimization Models\nby Calafiore and El Ghaoui.  (\namazon\n)\nNumerical Optimization\nby Nocedal and Wright.  (\namazon\n)\nLectures on Modern Convex Optimization\nby Ben-Tal and Nemirovski.  (\namazon\n)\nOptimization by Vector Space Methods\nby Luenberger.  (\namazon\n)\nMachine learning\nMachine Learning Refined\nby Watt, Borhani, and Katsaggelos.  (\namazon\n)\nLinear Algebra and Learning from Data\nby Strang.  (\namazon\n)\nThe Elements of Statistical Learning\nby Hastie, Tibshirani, and Friedman.  (Available as a free pdf from\nauthor's website\n)\nLearning from Data\nby Abu-Mostafa, Magdon-Ismail, and Lin.  (\namazon\n)\nPotpourri\nThe Drunkard's Walk: How Randomness Rules our Lives\nby Mlodinow.  (\namazon\n)\nAgainst the Gods: The Remarkable Story of Risk\nby Bernstein.  (\namazon\n)\nFooled by Randomness\nby Taleb.  (\namazon\n)\nThe Signal and the Noise\nby Silver.  (\namazon\n)\nThe Master Algorithm\nby Domingos.  (\namazon\n)\nData and Goliath\nby Schneier.  (\namazon\n)\nWeapons of Math Destruction\nby O'Neil.  (\namazon\n)\nAdditional online resources\nThe Matrix Cookbook\nA short, useful introduction to\nmatrix calculus\nIf you find anything else useful, let me know and I will post it here.\nTopics Covered\nThe method of least squares\nApplications and formulation: Regression and interpolation\nSolving least squares problems (Review of multivariable calculus)\nUnderstanding least squares problems (Review of linear algebra)\nComputing least squares solutions\nUnconstrained optimization\nConvex optimization\nGradient descent\nConjugate gradients\nAcceleration: The heavy ball method and Nesterov's optimal method\nNewton's method and quasi-Newton methods\nNon-smooth optimization\nStochastic gradient descent\nApplications: Approximation, filter design, tracking, logistic regression, neural networks\nConstrained optimization\nLagrange duality\nThe KKT conditions\nAlgorithms for constrained optimization\nLinear programming\nThe simplex algorithm\nSecond order cone programs\nSemidefinite programs\nApplications: Support vector machines, portfolio optimization, feature selection, optimal power flow, recommendation systems\nBeyond convex optimization\nInteger programming\nDynamic programming\nOptimization on graphs\nOptimization in game theory\nApplications: Error correction, optimal control, reinforcement learning, generative adversarial networks"}
{"url": "https://introdatasci.dlilab.com/syllabus/", "text": "Syllabus | Introduction to Data Science\nskip to content\nW3C\nSVG\nCourse (BIOL4800) at LSU.\nMain navigation\nMenu\nHome\nSyllabus\nSchedule & Materials\nAssignments\nFinal project\nReferences\nBlogs\ndark theme:\nSyllabus\nCourse overview\nWelcome to BIOL4800 section 3,\nIntroduction to Data Science\n. We are living in a rapidly changing world, with the current pandemic as an immediate example among many other complex issues (e.g., climate warming, biodiversity loss). Meanwhile, increasing large volumes of data have become available during the past decades because of advances in technology, measurement approaches, establishment of citizen science programs, etc. This increasing wealth of data provides opportunities to solve complex problems that were unsolvable previously, fueling the rise of the new field of data science. Data science is interdisciplinary and usually combines elements of computer programming, statistics, graphic design, communication, and domain knowledge. A data scientist normally needs to identify relevant questions, gather appropriate data from different sources, clean, organize, and manage datasets, extract useful information to generate answers to the questions, and communicate results with others.\nThis course will provide an introduction to data science by covering data science tools (e.g., command line, Git, etc.), basic to intermediate R programming, data management, data manipulation, data visualization, basic statistical models, and reproducible workflows to generate reports. This course will use R as the main programming language. However, the concepts and skills learned in this course will be easily transferable to other programming languages.\nLearning objectives\nOver the course, students should be able to:\nUse\nGit\nand\nGitHub\nto create repositories, manage projects, track changes of files, recover old versions of files, push/pull changes to/from remote repositories, discuss through issues, and submit pull requests\nBe able to use\nR\nto get, clean, explore, visualize data, and conduct simple statistic analyses\nOrganize the above processes into a\nproject\nor an R package\nUse unit tests in\nR\nto assure code functionality\nUse\nR Markdown\nto combine text, code, and results into reports, slides, or even websites (i.e.,\nliterature programming\n)\nGoogling\nInstructor\nDaijiang Li\nAssistant Profesoor\nPronouns: He/Him/His\nDepartment of Biological Sciences\nCenter for Computation & Technology\nLSU\nEmail address:\ndli30@lsu.edu\nMeeting times & locations\nTu/Th 9:00 - 10:20 AM\nClass location:\n206 Tureaud Hall\nOffice room: LSB125\nOffice hours: Tuesday 12-1 pm in LSB 125 or by appointment\nPre-requisites\nNo pre-requisties; ideally, you should have taken the BIOL 4800 FOUND COMP BIOLOGIST course.\nTextbook(s) and/or readings\nThere is no required text for the course. Online readings will be provided for each learning topic.\nSyllabus Subject to Change\nThis syllabus represents my current plans and objectives. As the semester progresses, those plans may need to change to enhance the classes learning opportunity. Such changes, communicated clearly, are not unusual (especially during a pandemic) and should be expected. Syllabus and grades will be available on Moodle. But the most up-to-date and current syllabus will always be available on the\ncourse web page\n.\nTechnology\nThis course will have lots of hands-on computing exercises during and after lectures. Therefore, students are strongly recommended to bring their own laptop to class. For students without access to a personal laptop, it is possible to check out one 💻 from the library (\nhttps://lib.lsu.edu/services/borrowing/gear)\n.\nAll softwares used in this course are free and cross platforms (macOS, Linux, or Windows operating systems). Main softwares that we will use are:\nGit\n(for version control),\nR\nand use\nRStudio\nas an integrated development environment (IDE).\nCourse Communications\nImportant notes about updates to the syllabus, clarifications of assignments, or changes to the schedule will be communicated via LSU email. Please be sure to check your account regularly. If you have an email that you would like to send to the entire class, please communicate with the course instructor before doing so. Short questions should be addressed to me via email\nonly\nafter searching online and did not find an answer. I will try to respond to your email within 48 hours. More complicated questions should be addressed to me in person either after class or during office hours or appointment scheduled. In addition, we will use the\nIssues\nfeature of\nGitHub\nto post questions and help each other.\nClassroom conduct\nI will strive to create a learning environment for students that supports a diversity of thoughts, perspectives, and experiences, and honors your identities (including race, gender, class, sexuality, religion, nationality, ability, etc.). I welcome and appreciate 🤝 any constructive criticisms, suggestions, ideas, comments, and any other feedbacks for the course.\nI encourage all of us to use welcoming and inclusive language, show respect toward others, and acknowledge our differences. As a student, you should also strive to respect and honor the diversity of your classmates. If something was said/done in class (by anyone) that made you feel uncomfortable, please talk to me about it.\nExamples of behavior that contributes to a positive environment for our\ncommunity include:\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes,\nand learning from the experience\nFocusing on what is best not just for us as individuals, but for the\noverall community\nExamples of unacceptable behavior include:\nThe use of sexualized language or imagery, and sexual attention or\nadvances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others' private information, such as a physical or email\naddress, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a\nprofessional setting\nNote\n: If you believe you have been a victim of an alleged violation of the\nCode of Student Conduct\n, or you are aware of such an alleged violation, you have the right to\nreport it to the University\n.\nExpectations\nLSU’s general policy states that for each credit hour, you (the student) should plan to spend at least two hours working on course related activities outside of class. Since this course is for three credit hours, you should expect to spend a minimum of six hours outside of class each week working on assignments for this course.\nEvaluation\nStudents will be evaluated on their knowledge of course content and ability to communicate their results via individual homework assignments (60%), their attendance and active participation in class (15%), and a final project (25%).\nHomework (60%)\nThere will be 7 homework assignments, with 10 points for each assignment. All assignments should be finished as\nRmarkdown\nfiles and I need to be able to reproduce all results by running it on my own computer. I expect that each student will complete the assignment independently (discussing about some questions is fine). The assignments are due by next Thursday before class.\nNo late assignment will be accepted\n, for any reason. So don’t wait until the last hour to do an assignment. Plan ahead and pace yourself. Instead of late assignment, I will drop your lowest score and use the other 6 scores for your final grade.\nAt least 5 assignments must be turned in to achieve a passing grade.\nParticipation (15%)\nA key component of data science is communicating your results with others. It is thus critical to attend class and participate in discussing of concepts, results, etc. Another important reason to come to class is that it is easier for us to overcome the computational and programming burdles that you likely will encounter. Attendance and participation will be worth 15 points.\nFinal project (25%)\nThe final project will demonstrate your knowledge of the course content and beyond. It will be a full report in an\nR Makrdown\nformat, mixed text with code, results, figures, tables, citations, etc. The final report should be in high quality and publishable with some additional effort later. The final project should be hosted on Github, organized as we discussed in class and should be fully reproducible. This means that I can clone your repository and re-run your files on my computer and get the same results.\nThe final project deadline is December 3rd.\nMore information about it can be found\nhere\n.\nGrading\nLSU has a plus-minus grading scale. There will be no curve.\ngrade\npercent\nA+\n> 97\nA\n93-97\nA-\n90-92\nB+\n87-89\nB\n83-86\nB-\n80-82\nC+\n77-79\nC\n73-76\nC-\n70-72\nD\n65-69\nF\n< 64\nAcademic integrity\nLouisiana State University adopted the Commitment to Community in 1995 to set forth guidelines for student behavior both inside and outside of the classroom.  The Commitment to Community charges students to maintain high standards of academic and personal integrity.  All students are expected to read and be familiar with the LSU Code of Student Conduct and Commitment to Community, found online at\nhttps://www.lsu.edu/saa/\n.  It is your responsibility as a student at LSU to know and understand the academic standards for our community.\nStudents who are suspected of violating the Code of Conduct will be referred to the office of Student Advocacy & Accountability. For undergraduate students, a first academic violation could result in a zero grade on the assignment or failing the class and disciplinary probation until graduation.  For a second academic violation, the result could be suspension from LSU.  For graduate students, suspension is the appropriate outcome for the first offense.\nFurther information is provided on the\nLSU website\nSpecial needs statement\nOur goal is to help you learn. Students who have any difficulty (either permanent or temporary) that might affect their ability to perform in class can contact us privately, or reach out to the LSU Disability Services staff.\nMore information on registering a disability is available at\nLSU Disability Services\n, located at 124 Johnston Hall. Contact the Center by telephone at 225-578-5919 or via email at\ndisability@lsu.edu\n."}
{"url": "https://ocw.mit.edu/courses/6-0002-introduction-to-computational-thinking-and-data-science-fall-2016/pages/syllabus/", "text": "Syllabus | Introduction to Computational Thinking and Data Science | Electrical Engineering and Computer Science | MIT OpenCourseWare\nBrowse Course Material\nSyllabus\nInstructor Insights\nReadings\nLecture Videos\nLecture Slides and Files\nAssignments\nSoftware\nCourse Info\nInstructors\nProf. Eric Grimson\nProf. John Guttag\nDr. Ana Bell\nDepartments\nElectrical Engineering and Computer Science\nAs Taught In\nFall\n2016\nLevel\nUndergraduate\nTopics\nEngineering\nComputer Science\nMathematics\nProbability and Statistics\nLearning Resource Types\ntheaters\nLecture Videos\nassignment\nProblem Sets\nnotes\nLecture Notes\nassignment\nProgramming Assignments\nDownload Course\nmenu\nsearch\nGive Now\nAbout OCW\nHelp & Faqs\nContact Us\nsearch\nGIVE NOW\nabout ocw\nhelp & faqs\ncontact us\n6.0002 | Fall 2016 | Undergraduate\nIntroduction to Computational Thinking and Data Science\nMenu\nMore Info\nSyllabus\nInstructor Insights\nReadings\nLecture Videos\nLecture Slides and Files\nAssignments\nSoftware\nSyllabus\nCourse Meeting Times\nLectures: 2 sessions / week, 1 hour / session\nRecitations: 1 sessions / week, 1 hour / session\nPrerequisites\n6.0001 Introduction to Computer Science and Programming in Python\nor permission of the instructor.\nCourse Information\nThis subject is aimed at students with little or no programming experience. It aims to provide students with an understanding of the role computation can play in solving problems. It also aims to help students, regardless of their major, to feel justifiably confident of their ability to write small programs that allow them to accomplish useful goals. The class will use the Python programming language.\nNote on 6.0001, 6.0002 and 6.00\n6.0001 (6 units): First half of term\n6.0002 (6 units): Second half of term\n6.00 (12 units): Full term\n6.00 satisfies all degree / minor requirements that can be satisfied by taking both 6.0001 and 6.0002.\nStudents taking 6.00 will attend the 6.0001 and 6.0002 lectures and do the problem set for 6.0001 and 6.0002. The 6.0001 final will serve as a 6.00 midterm. The 6.0002 final will serve as the 6.00 final.\nOCW has additional versions of 6.00 that include useful materials; this course will closely parallell the material covered in these versions:\n6.00SC Introduction to Computer Science and Programming\n6.00 Introduction to Computer Science and Programming\nGoals\nProvide an understanding of the role computation can play in solving problems.\nHelp students, including those who do not necessarily plan to major in Computer Science and Electrical Engineering, feel confident of their ability to write small programs that allow them to accomplish useful goals.\nPosition students so that they can compete for research projects and excel in subjects with programming components.\nTextbook\nThe textbook is\nGuttag, John.\nIntroduction to Computation and Programming Using Python: With Application to Understanding Data\n. 2nd ed. MIT Press, 2016. ISBN: 9780262529624. [Preview with\nGoogle Books\n] The book and the course lectures parallel each other, though there is more detail in the book about some topics. It is available both in hard copy and as an e-book.\nLecture and Recitation Attendance\nA significant portion of the material for this course will presented only in lecture, so students are expected to regularly attend lectures.\nRecitations give students a chance to ask questions about the lecture material or the problem set for the given week. Sometimes, new material may be covered in recitation. Recitation attendance is encouraged but not required.\nProblem Sets and Final Exam\nEach problem set will involve programming in Python. There will be 5 problem sets in the course.\nThere will be one final exam. The exam is open book / notes but\nnot\nopen Internet and\nnot\nopen computer. Please print whatever you may want to use during the quiz.\nGrading Policy\nGrades will be roughly computed as follows:\nACTIVITIES\nPERCENTAGES\nProblem sets\n50%\nCompletion of mandatory finger exercises\n10%\nFinal Exam\n40%\nProblem sets will be graded out of 10 points. Submissions that do not run will receive at most 20% of the points.\nNote: Finger exercises are not available on OCW.\nExtension and Dropping Problem Sets Policy\nWe do not grant any extensions. Instead, we offer late days and the option of rolling at most 2 problem set grades into the final exam score.\nLate Days\nAt the beginning of the term, students are given two late days that they can use on problem sets. Starting with Problem Set 1, additional late days can be accumulated for each assignment, one late day for each day the assignment is turned in ahead of the deadline. Up to three late days may be accumulated in this fashion in this course, i.e., you can only have a maximum of 3 late days at any point in time. Late days are discrete (a student cannot use half a late day). The staff will keep track of late days and feedback for each problem set will include the number of late days the student has remaining. Any additional late work beyond these late days will not be accepted. To avoid surprises, we suggest that after you submit your problem set, you double check to make sure the submission was uploaded correctly.\nRolling Over Problem Sets\nAs we assign final grades, we will maximize your score based on the choice to roll the weight of at most two problem sets into your final exam score. If rolled, the percent that the problem sets are worth will be rolled into the final exam score. We strongly urge you to see the late days and dropping the problem sets as backup in case of an emergency. Your best strategy is to do the problem sets early before work starts to pile up.\nCalendar\nSESÂ #\nTOPICS\nKEY DATES\n1\nIntroduction and Optimization Problems\nProblem set 1 out\n2\nOptimization Problems\nÂ\n3\nGraph-theoretic Models\nÂ\n4\nStochastic Thinking\nProblem set 1 due\nProblem set 2 out\n5\nRandom Walks\nÂ\n6\nMonte Carlo Simulation\nProblem set 2 due\nProblem set 3 out\n7\nConfidence Intervals\nÂ\n8\nSampling and Standard Error\nProblem set 3 due\nProblem set 4 out\n9\nUnderstanding Experimental Data\nProblem set 4 due\nProblem set 5 out\n10\nUnderstanding Experimental Data (cont.)\nÂ\n11\nIntroduction to Machine Learning\nÂ\n12\nClustering\nÂ\n13\nClassification\nProblem set 5 due\n14\nClassification and Statistical Sins\nÂ\n15\nStatistical Sins and Wrap Up\nFinal Exam\nCourse Info\nInstructors\nProf. Eric Grimson\nProf. John Guttag\nDr. Ana Bell\nDepartments\nElectrical Engineering and Computer Science\nAs Taught In\nFall\n2016\nLevel\nUndergraduate\nTopics\nEngineering\nComputer Science\nMathematics\nProbability and Statistics\nLearning Resource Types\ntheaters\nLecture Videos\nassignment\nProblem Sets\nnotes\nLecture Notes\nassignment\nProgramming Assignments\nDownload Course\nOver 2,500 courses & materials\nFreely sharing knowledge with learners and educators around the world.\nLearn more\nÂ© 2001â2025 Massachusetts Institute of Technology\nAccessibility\nCreative Commons License\nTerms and Conditions\nProud member of:\nÂ© 2001â2025 Massachusetts Institute of Technology\nYou are leaving MIT OpenCourseWare\nclose\nPlease be advised that external sites may have terms and conditions,\nincluding license rights, that differ from ours. MIT OCW is not responsible\nfor any content on third party sites, nor does a link suggest an endorsement\nof those sites and/or their content.\nStay Here\nContinue"}
{"url": "https://dsc10.com/syllabus/", "text": "📖 Syllabus | DSC 10\nSkip to main content\nLink\nSearch\nMenu\nExpand\nDocument\n(external link)\nDSC 10\n🏠 Home\n📖 Syllabus\n📆 Calendar\n📚 Resources\n🐞 Debugging\n👩‍🏫 Staff\nThis site uses\nJust the Docs\n, a documentation theme for Jekyll.\n🙋 Campuswire\n💯 Gradescope\n📌 Reference\n💪 Practice\n✅ CC\n🎥 Podcasts\n📖 Syllabus\nTable of contents\n🧐 About\nAcknowledgements\n👨‍🏫 Course Meetings\nLecture\nPods\nDiscussion\nQuizzes and Pod Meetings\nOffice Hours\n🚦 Getting Started\nTechnology\nSyllabus Check\nWelcome Survey\nPretest\n💬 Communication\n📕 Readings\n🧪 Assignments\nLab Assignments\nHomework Assignments\nProjects\nDeadlines and Slip Days\nSubmission Errors\n📝 Assessments\nExams\nQuizzes\n📆 Weekly Schedule\n🙋 Participation\n💯 Grades\nRegrade Requests\nLetter Grades and Incompletes\n🤝 Academic Integrity Policies\nWhy is academic integrity important?\nWhat counts as cheating?\nUse of Generative Artificial Intelligence\n🤗 Support\nAccomodations\nDiversity and Inclusion\nSatisfactory Academic Progress for Financial Aid\n❓ Waitlist FAQs\n🧐 About\nWelcome to DSC 10 at UC San Diego! This course aims to teach you how to draw conclusions about data. We will learn how to explore data and make predictions using data. Programming is a useful tool to help us analyze large datasets, and so we will learn how to program in Python towards this goal. We will learn some of the core techniques of data science, and we will practice applying them to real datasets from a variety of different disciplines.\nPrerequisites: None. This course is an introduction to data science with no prior background assumed beyond high school algebra. Make sure you are well-prepared by taking\nthis pretest\n.\nIf you are not planning on entering the DSC major/minor and have already taken a programming class and a statistics class, you may wish to take a more advanced course. If you are a DSC major/minor, DSC 10 is absolutely required, as later courses heavily reference its specific content.\nAcknowledgements\nThe contents of this course come from UC Berkeley’s Data 8 course, created by Ani Adhikari, John DeNero, and many others. This offering builds off of earlier offerings of DSC 10 by Justin Eldridge, Suraj Rampure, Janine Tiefenbruck, and many others. Thanks to all those who have a played a role in shaping this amazing course!\n👨‍🏫 Course Meetings\nLecture\nThere are four lecture sections:\nSection A: MWF 9-9:50AM in\nPCYNH 106\n.\nSection B: MWF 10-10:50AM in\nPCYNH 106\n.\nSection C: MWF 11-11:50AM in\nPCYNH 106\n.\nSection D: MWF 9-9:50AM in\nPODEM 1A19\n.\nLecture is meant to introduce you to the main concepts of the course. In-person attendance is never required, but is strongly encouraged when possible, as you’ll get the opportunity to ask questions, answer ungraded concept-check polls, and participate in discussion.\nYou can attend any lecture section, but if space fills up, priority will be given to students officially enrolled in that section. For the Midterm Exam, you must attend the lecture section in which you are officially enrolled.\nLectures will be podcasted\n(UCSD’s term for “recorded”). Podcast recordings will be available online at\npodcast.ucsd.edu\nwithin a few hours.\nPods\nOutside of lecture, this class has two additional hours designated for this class in the schedule of classes. One of these hours, on Monday afternoon, appears as DI in the schedule of classes, and will be used for discussion sections. The other hour, on Wednesday afternoon, appears as LA in the schedule of classes, and will be used for both quizzes and small group (pod) meetings.\nPods will be groups of 20 to 30 students, mentored by a couse tutor. Pods will consist of students who will all attend the same lecture, discussion, quiz times, and pod meetings. Pods are meant to give you the experience of being in a “microclass” within a much larger course.\nTo help us assign you to a pod that works for your schedule, please let us know your availability and preferences on the\nWelcome Survey\n. You will be assigned to a pod based on your preferences and the availability of seats. We will confirm your assigned pod and meeting times by email before Monday of Week 1.\nDiscussion\nThere are four discussion sections:\nMondays 1-1:50PM in\nFAH 1450\n.\nMondays 3-3:50PM in\nPCYNH 106\n.\nMondays 4-4:50PM in\nPCYNH 106\n.\nMondays 5-5:50PM in\nPCYNH 106\n.\nYou will be assigned to a specific discussion section based on your availability and preferences as indicated on the\nWelcome Survey\n. You must attend your assigned discussion section to get credit for attendance.\nThe first discussion includes some useful instruction and tips for using Jupyter notebooks and Datahub, the programming tools we’ll be using in this course. It should be helpful to get you set up and comfortable with the technology you’ll be using all quarter.\nSubsequent discussion sections will be focused on quiz and exam preparation. Students will work through problems from past DSC 10 quizzes and exams and be able to get help from course staff. Attending discussion and working through practice problems gives you direct experience with the types of questions you will see on quizzes and exams, which are typically the hardest parts of the course.\nDiscussion sections will not be podcasted.\nThe purpose of discussion is to give you hands-on problem-solving experience, so you really need to attend and participate to reap the benefits.\nQuizzes and Pod Meetings\nOn five Wednesdays throughout the quarter, we will have short 20-minute quizzes. On four other Wednesdays throughout the quarter, you will meet with your pod and mentor. Pod meetings will be purely social and are designed to help you make connections with classmates and your mentor, not to work on any specific course-related material.\nQuizzes and pod meetings will be held on Wednesday afternoons at one of the following times.\nWednesdays 2-2:50PM in\nFAH 1101\n.\nWednesdays 3-3:50PM in\nPCYNH 106\n.\nWednesdays 4-4:50PM in\nPCYNH 106\n.\nWednesdays 5-5:50PM in\nPCYNH 106\n.\nYou will be assigned to a specific time for quizzes and pod meetings based on your availability and preferences as indicated on the\nWelcome Survey\n. You must attend at your assigned time to get credit for attendance.\nOffice Hours\nIn order to provide you with help on assignments and concepts, the course staff will hold several office hours throughout the week, all of which will be held in-person. See the\nCalendar\ntab of the course website for the most up-to-date schedule and instructions.\nWe use the term “office hours” but really, office hours are held in a common room where you can come to work on assignments, meet your classmates, and get help from course staff. We don’t bite and we would love to see you in office hours!\nOffice hours are your chance to ask for general help, clarification on assignments, and to review previous assignments. Our tutors have previously taken the class, done well, and been trained in how to help you. Course staff will not tell you if your answer is correct, and it is not appropriate to ask. Here are some really good questions to ask instead:\nI got confused about a concept in class. Can you explain it?\nWhen the assignment says X, does it mean A or B?\nMy code is giving a weird error - can you help me understand why?\nI can’t get this test to pass, so I must be doing something wrong. Can you help me figure it out?\nMy code is doing something different than what I expected. Can you explain what is happening?\nQuestions that you should never ask a tutor:\nIs this the right answer?\nCan you check my code and make sure it is right?\nWhat is the answer?\nWhat’s going to be on the exam?\nYour primary motivation when interacting with course staff should be\nlearning\n.\n🚦 Getting Started\nMake sure to complete the four items listed below by\nSaturday, September 27th at 11:59PM\n. If you join the course late, these items are due at 11:59PM the day after you join the class.\nJoin\nCampuswire\n(join code: 8258).\nCheck if you can access\nGradescope\n. If not, send a private message to the instructional staff on Campuswire with your name, PID, and email address, then we can add you so you can submit assignments.\nRead the syllabus and course website and complete the\nSyllabus Check\n.\nFill out the\nWelcome Survey\n.\nAfter that, start working on the\nPretest\n. You will need to submit your written solutions to\nGradescope\nalongside your first assignment, Lab 0.\nTechnology\nFirst and foremost, you will need access to a computer (or tablet with a keyboard) and a stable internet connection to participate in this course. UCSD has a\nLaptop Lending Program\nwhich may be helpful, but you should also contact us if you have any concerns about access to technology. Most students bring a computer to lecture, and a computer or tablet will be necessary for discussion sections. All course content will be linked from this website, but there are a few additional platforms that you’ll need to access:\nCampuswire:\nWe’ll be using Campuswire as our course message and discussion board. More details are in the\nCommunication\nsection below. If you didn’t already get an invitation,\njoin here\n(join code: 8258).\nGradescope:\nYou’ll submit all assignments and exams to\nGradescope\n. This is where all of your grades will live as well. You will be automatically added to Gradescope about 24 hours after enrolling in the course. If you need to submit assignments before then, please send a private message to the instructional staff on Campuswire with your name, PID, and email address.\nDataHub:\nAssignments in this course will involve programming in Python. DataHub (\ndatahub.ucsd.edu\n) is UCSD’s online data science and machine learning platform, where you will work on assignments. We will show you how to use it in class.\nMake sure you can access all three sites. It’s a good idea to bookmark them, too (though they’re all linked at the top of this website).\nWe will not be using Canvas this quarter. Please do not contact the staff through Canvas – we won’t be able to read it!\nSyllabus Check\nTo demonstrate that you have read and understood the policies on the syllabus and course website, you’ll be asked to complete a\nSyllabus Check\n, which is a short quiz about the information contained on the syllabus and course website.\nYou must complete the Syllabus Check before the deadline with a score of\n80% or higher to earn credit\n. You can only take this quiz once, so make sure to read the course website thoroughly before beginning.\nIf you have questions about any course-related policies in the future, always refer to the syllabus and course website first!\nWelcome Survey\nPlease fill out this short\nWelcome Survey\nat the start of the quarter. This is required of all students.\nPretest\nDSC 10’s only prerequisite is high school algebra. In order to gauge your preparedness for the type of math you’ll see in this class, you should work through the practice problems on this\nPretest\n. This Pretest will help you identify any gaps in your background knowledge and it will teach you some useful test-taking skills.\nThe Pretest will be graded based on honest effort, not on the correctness of your responses. You will earn some participation credit for working on the Pretest and submitting your written solutions to Gradescope by the deadline.\nWe’ll release solutions to the Pretest after the due date, and you are highly encouraged to check how you did and learn from it.\n💬 Communication\nThis quarter, we’ll be using\nCampuswire\n(join code: 8258) as our course message board.\nIf you have a question about anything to do with the course — if you’re stuck on a problem, want clarification on the logistics, or just have a general question about data science — you can make a post on Campuswire. If your post includes any part of your solution to a problem (e.g. code), please make your post private; otherwise, please make your post public so that other students can benefit from the interaction. You can also post anonymously if you prefer. Course staff will regularly check Campuswire and try to answer any questions that you have. You’re also encouraged to answer a question asked by another student if you feel that you know the answer – this is a great way to strengthen your understanding of the material.\nPlease use Campuswire\ninstead of email\n, as this helps us keep all course-related communication in one place. In particular, don’t send course staff questions about course content through email, Canvas, or social media – Campuswire is the place for that.\n📕 Readings\nOur readings will come from two free online sources.\nComputational and Inferential Thinking (“CIT”)\nis the main textbook for the course, written to support UC Berkeley’s version of this course, from which DSC 10 was adapted. This book uses some different Python commands (it does not use the\nbabypandas\nmodule), but the underlying concepts are the same.\nNotes on (Baby)Pandas (“BPD”)\nare a set of notes about the\nbabypandas\nmodule, written specifically for DSC 10 students.\n🧪 Assignments\nLab Assignments\nWeekly lab assignments are a required part of the course and will help you develop fluency in Python and working with data. The labs are designed to help you build the skills you need to complete homework assignments and projects in a low-stress setting.\nAs you complete the lab, you’ll be able to run a sequence of autograder tests, which check to make sure that your answers are correct. If you complete the assignment such that all the tests pass, you’ll get a perfect score!\nTo submit a lab, follow the instructions in the assignment to upload your notebook to Gradescope, which will run automated tests and assign your score. You should verify that all of your test cases pass on Gradescope\nbefore the deadline\n. Lab assignments will usually be due on Thursdays at 11:59PM, though you should refer to the\nhomepage of this website\nfor the most up-to-date schedule. We will release lab assignments roughly a week before they’re due.\nYour lowest lab score is dropped from your grade calculation at the end of the quarter.\nLabs must be completed and submitted individually, but we encourage you to discuss high-level approaches with others. See the\nAcademic Integrity Policies\nsection for more details.\nHomework Assignments\nWeekly homework assignments build off of the skills you have developed in labs. Homeworks will reinforce concepts from class, explore new ideas, and provide hands-on experience working with data.\nAn important difference between labs and homeworks lies in the way autograder tests are run. Unlike the tests in the labs, the tests in the homework cannot be used to guarantee that you have the correct answers. The tests in the homework only check to make sure that your answer is appropriately formatted, not that it is correct. For example, if a homework question asks you to calculate a percentage, the test in the homework might only check that the answer you provide is a number between 0 and 100.\nYou should make sure that all the tests pass before submitting your homework, but this will not guarantee a perfect score.\nAfter you submit your homework to Gradescope, and after the deadline for submissions has passed, a new set of hidden tests will be run to make sure that you have the correct answers. In the percentage example above, the hidden test might check that your answer equals 56, for example. Your score for the assignment will be based on the results of the hidden tests, which won’t be available immediately after submission. So if you see a perfect score upon submission, this only means that you’ve passed the formatting tests, not the hidden correctness tests that determine your score.\nTo submit a homework, follow the instructions in the assignment to upload your notebook to Gradescope. Homeworks will usually be due on Saturdays at 11:59PM, though you should refer to the\nhomepage of this website\nfor the most up-to-date schedule. We will release homework assignments roughly a week before they’re due.\nYour lowest homework score is dropped from your grade calculation at the end of the quarter.\nLike labs, homeworks must be completed and submitted individually, but we encourage you to discuss high-level approaches with others. See the\nAcademic Integrity Policies\nsection for more details.\nProjects\nThis class has two projects, a Midterm Project and a Final Project. Projects are like more challenging homeworks. They are longer than a typical homework, and they require you to pull together ideas from previous weeks, rather than just the last week. Projects also give you a chance to explore a dataset in-depth, which can be a lot of fun!\nProject tests are like homework tests – the provided tests only check if your answers have the correct format, not if they are correct. You’ll only be able to see your score on the project after the deadline, once all projects are submitted and the hidden correctness tests have been run.\nUnlike labs and homeworks, you may work with a partner on projects.\nYour partner can be anyone else in any section of the course. If you choose to work with a partner, start by reading these\nproject partner guidelines\n. If working with a partner, only one of you should submit the assignment, and you’ll be able to tag your partner in your Gradescope submission.\nDeadlines and Slip Days\nLabs, homeworks, and projects must be submitted by 11:59PM on the due date to be considered on time. You may turn them in as many times as you like before the deadline, and only the most recent submission will be graded, so it’s a good habit to\nsubmit early and often\n.\nWhen submitting any assignment to Gradescope, make sure to stick around until you see a confirmation that all tests have passed. If the Gradescope autograder cannot grade your work or you see a message saying “Your submission timed out,” this indicates an error with your code, and it is your responsibility to identify and solve the problem before the deadline.\nIt may take some time for Gradescope’s autograder to grade your submission. You are encouraged to submit with enough time to see the output of the autograder before the 11:59PM deadline, as it may alert you to a problem you need to fix. However, if you submit before 11:59PM and the autograder finishes running after 11:59PM, your assigment will still be considered on time.\nAfter submitting, check that you got a confirmation email from Gradescope to verify that your submission was successful. Save this email until you receive your grade on the assignment, in case of any issues with your submission.\nYou are allotted\nsix “slip days”\nto use throughout the quarter. A slip day extends the deadline of any one homework, lab, or project by 24 hours. You cannot turn in any assignments more than 48 hours late, meaning that you cannot use more than 2 slip days on any assignment.\nSlip days are designed to be a transparent and predictable source of leniency in deadlines. You can use a slip day if you are too busy to complete an assignment on its original due date. But slip days are also meant for things like the internet (or the DataHub server) going down at 11:58PM just as you go to submit your homework. Slip days are meant to be used in exceptional circumstances, so you probably should not need to use all six, but if you have something going on in your life that is impeding your ability to do your classwork on time, please reach out to us\nbefore\nusing up all your slip days.\nSlip days are applied automatically at the end of the quarter, and you don’t need to ask in order to use one.\nIt’s your responsibility to keep track of how many you have left. If you’ve run out of slip days and submit an assignment late, that assignment may still be graded, but you will receive a 0 on it when we calculate grades at the end of the quarter. However, in the event that you use all six slip days and submit another assignment late, we will allocate your slip days first to the Final Project and Midterm Project, then to your homeworks (in chronological order), and then to your labs (in chronological order). This is done to prevent you from receiving a 0 on, say, the Final Project, if you’ve used up all of your slip days at the end of the quarter; in such an example, you’d instead receive a 0 on an earlier assignment that isn’t weighted as much in your grade.\nIf you submit the Midterm Project or Final Project late and are working with a partner, both you and your partner will have to use slip days. For example, if you submit the Midterm Project two days late, both you and your partner will lose two slip days.\nSubmission Errors\nIt is your responsibility to ensure that your work is submitted correctly to Gradescope as a\n.ipynb\nfile, and that the Gradescope autograder can grade your work. Watch 20:05 and onwards of\nthis video\nto see two ways of downloading Jupyter notebooks as a\n.ipynb\nfile.\nWhen submitting your work, there are two common errors to watch out for:\nSubmitting your notebook in the wrong format, e.g. submitting as a\n.json\nor\n.txt\nfile instead of a\n.ipynb\nfile. If you do this, the Gradescope autograder will not be able to grade your work, and you will get a 0. This can almost certainly be avoided by watching the aforementioned video, and by waiting until you see confirmation from Gradescope that all tests have passed.\nSubmitting the wrong notebook, e.g. submitting your Lab 6 notebook to the Homework 6 assignment on Gradescope. This will also give you a 0, because the Gradescope autograder for a particular assignment can only grade your work for that assignment. To avoid this error, make sure to stick around on Gradescope after submission until you see that all tests have passed.\nTo prevent these issues, it is important that you let the autograder run on Gradescope until it shows you under “Public Tests” that all public test cases passed. Do not navigate away from Gradescope until you see this confirmation that your submission was able to be successfully graded!\nIf you happen to make one of the above mistakes and you notice it yourself within 48 hours of the deadline, please resubmit your assignment. Since we always grade your latest submission, a resubmission after the deadline will use up slip days. If it is more than 48 hours since the deadline, please reach out to a staff member and we may allow you to resubmit it late, at the cost of 2 slip days. It is your responsibility to ensure that all assignments are submitted correctly.\n📝 Assessments\nWe will assess your knowledge of course material frequently through quizzes and exams. Quizzes and exams will be administered on paper, without the use of computers or calculators. You’ll have access to a large collection of\npractice problems\nto help you prepare. You’ll see some of these problems in discussion sections and during in-class exam reviews, but the more you practice, the better prepared you’ll be for the assessments.\nExams and quizzes are designed to test your understanding of course material, therefore you must use methods of the course to earn credit. Solutions that are correct but outside of the scope of the course will not earn credit.\nExams\nThis class has one Midterm Exam and one Final Exam:\nMidterm Exam: Wednesday, October 29th,\nduring your enrolled lecture slot\n.\nFinal Exam: Saturday, December 6th from 3 to 6PM, location TBD.\nExams are cumulative, though the Final Exam will emphasize material after the Midterm Exam. Both exams will be held\nin-person and on-paper\n. You’ll be allowed to use one 8.5 by 11 inch page of double-sided handwritten notes, but no calculators, computers, or other resources.\nIf you have a conflict with either exam, you should let us know right away via the\nWelcome Survey\nto see if accomodations can be made. Without express permission otherwise, students are required to take both exams at the scheduled times.\nQuizzes\nQuizzes are designed to help you get more practice solving problems on-paper without a computer in front of you, as you’ll need to do on exams. Like exams, quizzes are in-person and on-paper. You’ll be allowed to use one 8.5 by 11 inch page of double-sided handwritten notes, but no calculators, computers, or other resources. Quiz questions are meant to be more straightforward than exam questions, but they will help you build the skills you need to perform well on exams, as well as help you identify any areas you need more practice in before the exam.\nThere are five quizzes throughout the quarter, administered during your assigned quiz time on the following dates:\nQuiz 1: Wednesday, October 15th\nQuiz 2: Wednesday, October 22nd\nQuiz 3: Wednesday, November 12th\nQuiz 4: Wednesday, November 19th\nQuiz 5: Wednesday, December 3rd\nWe will count only your three highest quiz scores towards your grade. In other words, we will drop your two lowest quiz scores.\nQuizzes are designed to give you low-stakes opportunities to practice solving problems on paper, with room for failure. You don’t need to do well on every quiz to do well in the course.\nWe will not offer makeup quizzes. If you are sick, traveling, or otherwise need to miss a quiz, you have some flexibility because not all scores will be factored into your grade.\nYou must attend quizzes at\nyour assigned time\n; see the\nQuizzes and Pod Meetings\nsection of the syllabus for details.\n📆 Weekly Schedule\nTo summarize all of the events and deadlines, refer to this general weekly schedule. Please refer to the\nhomepage of this website\nfor the most up-to-date schedule of deadlines.\nMonday\nTuesday\nWednesday\nThursday\nFriday\nSaturday\nmorning\nLecture\nLecture\nLecture\nafternoon\nDiscussion\nQuiz or Pod Meeting\nevening\nLab due\nHomework due\n🙋 Participation\nActively participating in the course is highly beneficial to your learning. Engaging with the course material, the course staff, and your peers will set you up for success in this course and in other data science courses you may take in the future. A portion of your grade will be allocated towards participation.\nThere will be 17 participation points available:\n1 point for the Pretest, graded for honest effort.\n1 point for passing the Syllabus Check at 80% or higher.\n1 point for completing SETs (Student Evaluations of Teaching) and an internal End-Of-Quarter Survey.\n1 point for attending each discussion section (10 points total).\n1 point for attending each pod meeting (4 points total).\nScore 12 points or higher for full participation credit.\nIf you earn fewer than 12 points, your participation grade will be the number of points earned out of 12. There is no extra credit for earning more than 12 points.\n💯 Grades\nThe table below shows how your mastery of class material will be assessed and how grades will be computed:\nComponent\nWeight\nNotes\nParticipation\n10%\nLab Assignments\n10%\ndrop lowest score\nHomework Assignments\n20%\ndrop lowest score\nQuizzes\n10%\ndrop two lowest scores\nMidterm Project\n10%\nMidterm Exam\n10%\nFinal Project\n10%\nFinal Exam\n20%\nNote that in each category, all assignments in that category will be worth the same amount, regardless of the number of points they are graded out of.\nRegrade Requests\nIf you’d like to request a regrade on any assignment, you must do so within one week of the assignment being graded. If you think there is a problem with the autograder, please fill out the\nAutograder Regrade Request Form\n. If you think there is a problem with how a manually-graded question was graded, submit a regrade request through Gradescope.\nLetter Grades and Incompletes\nWe will use a standard scale for assigning letter grades:\nLetter Grade\nA\nA-\nB+\nB\nB-\nC+\nC\nC-\nD\nF\nPercentage\n93+\n90+\n87+\n83+\n80+\n77+\n73+\n70+\n60+\nbelow 60\nA+ grades are given at the instructor’s discretion. If you are taking the course P/NP, you will receive a grade of P if you meet the criteria for a C- grade, otherwise you will receive a grade of NP.\nGrades may be curved depending on overall averages. In recent quarters, there has been a small curve.\nIf you have extenuating circumstances that prohibit your completion of coursework, you may be eligible for an Incomplete grade. If you are considering using this option, the best thing you can do is let us know right away, and we can help you decide if this is an appropriate course of action. If you have any doubt about your ability to perform satisfactorily in this course due to something outside of your control, please contact us as soon as possible so we can figure out a plan.\n🤝 Academic Integrity Policies\nThe basic rule for DSC 10 is: Work hard. Make use of the expertise of the staff to learn what you need to know to really do well in the course. Act with integrity, and don’t cheat.\nIf you do cheat, we will enforce the\nUCSD Policy on Integrity of Scholarship\n. This means you will likely fail the course and the Dean of your college will put you on probation or suspend or dismiss you from UCSD. Students agree that by taking this course, their assignments will be submitted to third party software to help detect plagiarism.\nWhy is academic integrity important?\nAcademic integrity is an issue that is pertinent to all students on campus. When students act unethically by copying someone’s work, taking an exam for someone else, plagiarizing, etc., these students are misrepresenting their academic abilities. This makes it impossible for instructors to give grades (and for the University to give degrees) that reflect student knowledge. This devalues the worth of a UCSD degree for all students, making it imperative for the campus as a whole to enforce that all members of this community are honest and ethical. We want your degree to be meaningful and we want you to be proud to call yourself a graduate of UCSD!\nThe UCSD Policy on Integrity of Scholarship and this syllabus list some of the standards by which you are expected to complete your academic work, but your good ethical judgment (or asking us for advice) is also expected as we cannot list every behavior that is unethical or not in the spirit of academic integrity. Ignorance of the rules will not excuse you from any violations.\nWhat counts as cheating?\nIn DSC 10, you can read books, surf the web, talk to your friends and the DSC 10 staff to get help understanding the concepts you need to know to complete your assignments. However, no other person should complete your work for you or write any of the code you submit in this course, with the exception of the work you do with a project partner.\nThe following activities are considered cheating and are not allowed in DSC 10 (not an exhaustive list):\nUsing or submitting code acquired from other individuals.\nPosting your code online, including on Campuswire, unless privately to instructors only.\nHaving any other person complete any part of your assignment on your behalf.\nCompleting an assignment on behalf of someone else.\nProviding code, exam questions, or solutions to any other student in the course.\nSplitting up project questions with your project partner and each working on different questions.\nCollaborating with others on quizzes or exams.\nThe following activities are examples of appropriate collaboration and are allowed in DSC 10 (not an exhaustive list):\nDiscussing the general approach to solving homework problems or projects.\nTalking about problem-solving strategies or issues you ran into and how you solved them.\nDiscussing the answers to quizzes or exams once all students in all sections of the course have taken the assessment.\nUsing code provided in class or in any assigned readings or videos.\nGoogle searching for documentation on Python or babypandas.\nWorking together with other students on assignments without copying or sharing answers.\nPosting a question about your approach to a problem on Campuswire, without sharing your code.\nThe best way to avoid problems is by using your best judgment and remembering to act with Honesty, Trust, Fairness, Respect, Responsibility, and Courage. Here are some suggestions for completing your work:\nDon’t look at or discuss the details of another student’s code for an assignment you are working on, and don’t let another student look at your code.\nDon’t start with someone else’s code and make changes to it, or in any way share code with other students.\nIf you are talking to another student about an assignment, don’t take notes, and wait an hour afterward before you write any code.\nUse of Generative Artificial Intelligence\nGenerative Artificial Intelligence (GenAI) describes tools, such as\nChatGPT\nand GitHub Copilot, that are trained to generate responses to user-defined prompts, or questions. The existence of such tools is a major milestone in machine learning, and an impressive application of data science in the real world.\nOur course policy on the use of GenAI tools for coursework is simple: you may use these tools to build an understanding of course material and to assist you on assignments, keeping in mind that no tool is a substitute for a strong understanding of course concepts.\nBe mindful of how you are using GenAI tools. These tools can be very useful to help you preview material before lecture, summarize material after lecture, explain concepts you didn’t understand, and explore how different concepts are related. “Explain it like I’m five” can be a helpful prompt to give you a basic understanding of new concepts before being exposed to them in lecture. Consolidating your knowledge after learning something new and relating it to other things you know is important for learning and retention. Unfortunately, GenAI tools are not a consistently reliable source of quality information.\nFor example, we asked ChatGPT to tell us about the Central Limit Theorem, an idea we will learn about towards the end of the quarter. The answer we get back is actually quite\ngood\n.\nGood answer, ChatGPT!\nHowever, we also asked ChatGPT to tell us about permutation testing, another idea from the second half of the quarter. The answer we got back was\nwrong\nin very subtle ways, though it might sound correct to someone learning about permutation testing for the first time. Thinking about why ChatGPT’s answer is wrong is a useful learning exercise.\nNot quite...\nAs this example illustrates, be skeptical about anything you learn from GenAI tools. Because of how GenAI tools are trained, they are designed to provide answers that\nsound\ncorrect, not necessarily ones that\nare\ncorrect. A goal of your education is to develop an ability to identify and produce information that actually is correct and doesn’t just sound correct. Human supervision of GenAI tools is always necessary.\nIn addition, proceed with caution when using tools to assist you with your assignments. DSC 10 is a foundational class for your study of data science; you need to master the skills and concepts of this course if you want to use data science effectively. Through quizzes and exams, you will be tested on your independent ability to apply course material to novel problems. Homeworks, labs, and projects are meant to prepare you for these assessments, so overreliance on GenAI for assignments will rob you of opportunities to learn and make it hard for you to perform well on assessments.\nIf you do use GenAI to assist you on assignments, keep these guidelines in mind:\nDesign your prompts carefully.\nDon’t just ask one question; ask a follow-up question based on the output to the first. To use these tools effectively, you need to engineer your prompts carefully.\nTest the outputs.\nGenAI tools can and do make mistakes, and being able to verify the correctness of a proposed answer is an important skill for you to develop. Validate the output against course-provided references, or follow up with a search on Google or Stack Overflow. Remember that GenAI tools provide crowdsourced likely answers, not necessarily correct answers.\nDon’t submit any code that you don’t understand, or that uses content not taught in this class.\nIn this introductory course, we expose you to a limited set of Python tools that you can use to solve a wide range of problems. When you prompt a GenAI tool with a question from DSC 10, it will not be limited to our restricted toolkit, and may provide answers using much more complicated code. If you answer questions with out-of-scope content, you are not practicing the foundational skills that the course is meant to teach you. In addition, your code may not pass correctness tests that require your solution to use methods taught in the course.\nIf your assignment submission includes any content generated by an AI tool, it should be cited to acknowledge the source of the material. At the end of each assignment, you will be provided with a space to explain and reflect on your use of GenAI tool(s).\n🤗 Support\nAccomodations\nFrom the\nOffice for Students with Disabilities (OSD)\n:\nOSD works with students with documented disabilities to review documentation and determine reasonable accommodations. Disabilities can occur in these areas: psychological, psychiatric, learning, attention, chronic health, physical, vision, hearing, and acquired brain injuries, and may occur at any time during a student’s college career. We encourage you to contact the OSD as soon as you become aware of a condition that is disabling so that we can work with you.\nIf you already have accommodations via OSD, make sure that we receive your Authorization for Accommodation (AFA) letter at the start of the quarter so that we can make arrangements for accommodations. The Data Science OSD Liaison can be reached at\ndscstudent@ucsd.edu\n.\nDiversity and Inclusion\nWe are committed to an inclusive learning environment that respects our diversity of perspectives, experiences, and identities. Our goal is to create a diverse and inclusive learning environment where all students feel comfortable and can thrive. If you have any suggestions as to how we could create a more inclusive setting, please let us know. We also expect that you, as a student in this course, will honor and respect your classmates, abiding by the\nUCSD Principles of Community\n. Please understand that others’ backgrounds, perspectives and experiences may be different than your own, and help us to build an environment where everyone is respected and feels comfortable.\nSatisfactory Academic Progress for Financial Aid\nSatisfactory Academic Progress (SAP) refers to the academic standards students must maintain to remain eligible for federal, state, and institutional financial aid. If you are receiving financial aid, please ensure you review the\nSAP requirements and the appeals process\n.\nWe will not use a #FinAid survey, but we will certify academic activity for any student who submits any assignment, including the\nWelcome Survey\n.\n❓ Waitlist FAQs\nI am on the waitlist, but I really want to get into the course. Can you let me in?\nSorry, but instructors are not able to enroll students in classes. There is nothing we can do let you into the course.\nI am on the waitlist, so how can I keep up with the course?\nWaitlisted to students may attend lecture and discussion, space-permitting, and can also watch podcast recordings. You can (and should) still submit assignments if you are on the waitlist. If you get off the waitlist and are able to join the class, you will not get any extensions on past-due assignments.\nWaitlisted students should have access to DataHub to work on assignments. You may need to add yourself to some course tools; see the\nGetting Started\nsection of the syllabus. If you need access to Gradescope, send a private message to the instructional staff on Campuswire with your name, PID, and email address.\nWhat are my chances of getting off the waitlist?\nThe instructional staff is not equipped to answer this question. Many questions about enrollment are\nanswered here\n. Please direct your questions about enrollment to DSC advising. You can send an email to\ndscstudent@ucsd.edu\n, send a message through the Virtual Advising Center, or stop by drop-in advising hours. In short, seats in the class open up when students drop the class, which can be hard to predict.\nI have been added to Gradescope, Campuswire, and other course tools. Does this mean I am off the waitlist?\nNo. Students on the waitlist were added to all course tools, so they can complete assignments while they are on the waitlist. Check\nWebReg\nif you are not sure of your enrollment status."}
{"url": "https://discovery.cs.illinois.edu/stat107-sp22/", "text": "STAT 107 (Spring 2022): Data Science Discovery at The University of Illinois\nArchived Content\nThis website is an archive of the Spring 2022 semester of STAT 107: Data Science Discovery.\nâ¶ Click here for the main DISCOVERY page.\nData Science Discovery\nWelcome to Data Science! · Spring 2022 · STAT 107 / CS 107 / IS 107\nCourse Pages >>\nHome\nSyllabus\nSchedule\nStaff\nLabs, Projects & Homeworks\nResources\nUpcoming Deadlines\nFinal Grades are Posted!\nFinal grades are posted in Canvas.  Have an amazing summer!!\nJoin the DISCOVERY Team!\nInterested in helping develop DISCOVERY?\nApply to be a CA!\nlab_regression\n: Regression\nApril 26, 2022\nGo to Lab Regression\nWeek 15: Regression, Clustering, and Machine Learning\nThis week, we continue our journey with machine learning and youâll begin to write your first code to have a machine learn! The prelectures and topics for this weekâs lectures are listed below:\nMonday, April 25\n:\nMachine Learning Models with sk-learn\nWednesday, April 27\n:\nkMeans Clustering\nFriday, April 29\n:\nTowards Machine Learning in Python\nYou will also complete your final lab this week,\nlab_regression\n:)\nApril 23, 2022\nlab_hypothesis_tests\n: Hypothesis Tests\nApril 19, 2022\nGo to Lab Hypothesis Tests\nWeek 14: Towards Machine Learning\nThis week we will wrap up hypothesis testing and go into one of the most exciting areas of data science: machine learning!  Hereâs the plan:\nMonday, April 18\n:\nWe will finish up\nHypothesis Testing\nfrom last week\nPre-Lecture: Overview of Machine Learning\nNo new homeworks on Monday!\nWednesday, April 20\n:\nPre-Lecture: Correlation\nHomework m6-02\n, due April 22 by 11:59pm\nFriday, April 22\n:\nPre-Lecture: Linear Regression\nHomework m6-03\n, due April 25 by 11:59pm\nIn addition, remember that we you have your lab section every week and we have office hours every weekday (Monday-Friday)! :)\nApril 15, 2022\nProject 2: You and Data Science\nNerd out with your own data using what you learned in DISCOVERY!\nApril 13, 2022\nView Project\nlab_clt\n: CLT\nApril 12, 2022\nGo to Lab CLT\nData Science and Related Courses\nLast week, Wade and Karle discussed Data Science Courses offered at Illinois and related courses.  This is the slides from the talk:\nSlide Deck: Courses Related to Data Science at Illinois\nApril 11, 2022\nWeek 13: Confidence Intervals and Hypothesis Testing\nThis week you will explore two important statistical topics: Confidence Intervals and Hypothesis Testing! We will continue our discussion of random variables as we explore doing these both by hand and in Python!\nMondayâs Prelecture:\nConfidence Intervals\nWednesdayâs Prelecture:\nHypothesis Testing\nFridayâs Prelecture: More Hypothesis Testing- no prelecture for today, but the HW released today will be a review of what we covered this week.\nYou have 3 PL homeworks due this week at 11:59pm on Monday, Wednesday, and Friday! Youâll also get to nerd out more with lab_clt :)\nApril 11, 2022\nlab_random_variable\n: Random Variable\nApril  5, 2022\nGo to Lab Random Variable\nWeek 12: Distributions and Random Variables\nThis week we will spend some time on Monday talking about classes you can consider taking if you want to dive deeper into Data Science!  Weâll talk about our favorite courses on campus and the continue talking about distributions and random variables!  The pre-lectures and homeworks for this coming week:\nMonday, April 4\n:\nWe will discuss Data Science at Illinois, including courses you can take to further your knowledge in Data Science, Computer Science, and Statistics.\nWe will review\nBernoulli & Binomial Random Variables\n(covered in detail last week)\nHomework #24: Bernoulli and Binomial Distributions (m5-02)\n, Due Wednesday, April 6 at 11:59pm\nWednesday, April 6\n:\nPre-Lecture:\nCentral Limit Theorem\nHomework #25: Statistical Distributions in Python (m5-03)\n, Due Friday, April 8 at 11:59pm\nFriday, April 8\n:\nPre-Lecture: Polling and Sampling\nHomework #26: Central Limit Theorem (m5-04)\n, Due Monday, April 11 at 11:59pm\nIn addition, remember that we you have your lab section every week and we have office hours every weekday (Monday-Friday)! :)\nApril  1, 2022\nWeek 11: Midterm 2, Project, and Distributions\nThis week you will work on Project #1 (Image Mosaic) and dive more into the normal distribution:\nMondayâs Lectures:\nBernoulli and Binomial Distributions\nWednesdayâs Lecture:\nDistributions in Python\nFridaysâs Lecture: No Class Friday due to the midterm :)\nYou have one PL homework due this week â the practice exam!! During lab, you should work on your project. If you come to lab and work on your project, youâll get the 20 points for this week! If you finish your project before your lab, send a copy of your image mosaic to your lab TA\nbefore your lab starts\nto get the 20 points!\nMarch 28, 2022\nlab_justice\n: Justice\nMarch 22, 2022\nGo to Lab Justice\nWeek 10: Normal Distribution\nThis week you will work on Project #1 (Image Mosaic) and dive more into the normal distribution:\nMondayâs Lectures:\nNormal Distribution\nWednesdayâs Lecture:\nLaw of Large Numbers\nFridaysâs Lecture:\nRandom Variables\nYou have no PL homeworks this week â you should instead work on your project and prepare for the upcoming Midterm exam!  In lab, you will work on\nlab_justice\n. :)\nMarch 21, 2022\nProject 1: Image Mosaic\nCreate your own unique image mosaic!\nMarch 11, 2022\nView Project\nlab_simulation\n: Simulation\nMarch  9, 2022\nGo to Lab Simulation\nWeek 8: More Python- Conditionals and Functions\nThis week we will nerd out with more Python! Specifically, we will revisit conditionals and introduce the idea of functions. On Friday, we will introduce our first project of the semester. There are three pre-lectures for this week on Monday and Wednesday:\nMondayâs Lectures:\nSample Space\nand\nMore Conditionals in Python\nWednesdayâs Lecture:\nFunctions in Python\nFridayâs Lecture: No Prelecture- PROJECT INTRO DAY!\nIn addition to the pre-lectures, there is a quick, mastery-based homework after each lecture and youâll work on a new lab to practice the Python programming we have learned so far. :)\nMarch  7, 2022\nlab_birthday\n: Birthday\nMarch  1, 2022\nGo to Lab Birthday\nWeek 7: Simulation\nWe are just two weeks away from Spring Break and beginning my favorite part of the class!!  Next week we will finish up probability and begin to talk about simulation â weâll use Python to simulate real-world events including guessing on multiple-choice exams, playing casino games with various strategies, and much, much more!\nMondayâs Lecture:\nBayesâ Theorem\nWednesdayâs Lecture:\nOverview of Simulation\nFridayâs Lecture:\nFor-Loops in Python\nIn addition to the pre-lectures, there is a quick, mastery-based homework after each lecture and youâll work on a new lab to practice the Python programming we have learned so far. :)\nFebruary 28, 2022\nlab_gpa\n: GPA\nFebruary 22, 2022\nGo to Lab gpa\nWeek 6: Probability\nThis week is all about diving into probability â youâll continue to learn about how to solve complex probability problems with the Multiplication Rule, the Addition Rule, and finally, we will begin to look at conditional probability! There are three lecture for this week:\nMondayâs Lecture:\nThe Multiplication Rule\nWednesdayâs Lecture:\nThe Addition Rule\nFridayâs Lecture:\nConditional Probability\nIn addition to the prelectures, there is a quick, mastery-based homework after each lecture and youâll work on lab_gpa in lab to practice the Python progamming we have learned so far :) The HW assignments will be released right after each lecture.\nEnjoy Week 6!\nFebruary 18, 2022\nlab_plots\n: Plots\nFebruary 15, 2022\nGo to Lab Plots\nWeek 5: Midterm Exam Week\nThis week you will take your first midterm exam!  You must register for the time you will take your exam in the CBTF by visiting\nhttps://cbtf.engr.illinois.edu/\n.\nSince we have an exam next week (more on that below), thereâs only one pre-lecture next week and two lectures:\nMondayâs Lecture: No pre-lecture reading required\nWednesdayâs Lecture:\nComplete Random Numbers in Python\nFriday Lecture is Cancelled (Exam Week)\nIn addition to the prelectures, there is a quick, mastery-based homework after each lecture and youâll begin to work with grouping data in Python in lab_plots! :) These HW assignments will be released right after each lecture.\nGood luck with Week 5!\nFebruary 11, 2022\nlab_simpsons_paradox\n: Simpson's Paradox\nFebruary  9, 2022\nGo to Lab simpson\nWeek 4: Grouping Data and Visualizations\nThis week you will learn about how we form complex groups of data with Python and begin to dive into Wadeâs favorite topic (data visualizations)!\nBefore each class, make sure to watch the pre-lecture videos listed below:\nGrouping Data in Python\nâ watch before Mondayâs Lecture on Feb. 7\nVisualization â Histograms\nâ watch before Wednesdayâs Lecture on Feb. 9\nVisualization â Boxplots\nâ watch before Fridayâs Lecture on Feb. 11\nIn addition to the prelectures, there is a quick, mastery-based homework after each lecture and youâll begin to work with grouping data in Python in lab_simpsons_paradox! :) These HW assignments will be released right after each lecture.\nGood luck with Week 4!\nFebruary  4, 2022\nlab_exp_design\n: Experimental Design\nFebruary  1, 2022\nGo to Lab Experimental Design\nWeek 3: Conditionals and Descriptive Statistics\nThis week, you will learn how to filter data by the contents of the row using conditionals and learn about a practice called EDA or Exploratory Data Analysis.\nBefore each class, make sure to watch the pre-lecture videos listed below:\nDataFrames with Conditionals\nâ watch before Mondayâs Lecture on Jan. 31\nSoftware Version Control with git\nand\nExploratory Data Analysis Overview\nâ watch before Wednesdayâs Lecture on Feb. 2\nDescriptive Statistics\nâ watch before Fridayâs Lecture on Feb. 4\nIn addition to the prelectures, there is a quick, mastery-based homework after each lecture and youâll begin to work with DataFrames conditionals in Python in lab_exp_design! :) These HW assignments will be released right after each lecture.\nGood luck with Week 3!\nJanuary 31, 2022\nlab_pandas\n: Getting Started with Pandas\nThe primary Data Science library we will be using this semester is pandas.  This lab explores the basic usage of the pandas library and gets you ready for the Data Science challenges we will be beginning next week!\nJanuary 26, 2022\nGo to Lab pandas\nWeek 2: Working with Pandas + Experimental Design\nThis week, we will explore how to select a subset of rows from a DataFrame and different aspects of experimental design (observational studies, confounders, and Simpsonâs Paradox!). Class will meet\nin person\nthis week Mon/Wed/Fri from 12-12:50pm in Room 100 Noyes! We are so excited to meet you :)\nBefore each class, make sure to watch the pre-lecture videos listed below:\nRow Selection\nâ watch before Mondayâs Lecture on 1/24\nObservational Studies, Confounders, and Stratifcation\nâ watch before Wednesdayâs Lecture on 1/26\nSimpsonâs Paradox\nâ watch before Fridayâs Lecture on 1/28\nIn addition to the prelectures, there is a quick, mastery-based homework for every lecture and youâll begin to work with DataFrames in Python in lab_pandas! :) These HW assignments will be released right after each lecture.\nGood luck with Week 2!\nJanuary 24, 2022\nWeek 1: The Beginning\nWe (Prof. Wade and Prof. Karle) sent out an e-mail last week and again on Tuesday evening, make sure to view that for important links to the course discord, and more!  If you missed them, you can find them as Canvas announcements as well! :)\nThere will be an introduction to the course held on Zoom during the first meeting of DISCOVERY (Wednesday, Jan. 19).  Join us on Zoom at 12:00noon!\nIn addition to the introduction, you will explore the basics of data science through four micro-lectures:\nWhat is Data Science?\nTypes of Data\nExperimental Design and Blocking\nPython for Data Science: Introduction to DataFrames\nFinally, there are two small homeworks to complete and lab_intro (all due Monday, Jan 24 by 11:59pm):\nHomework 1: Experimental Design and Blocking (m1-02)\nHomework 2: Python for Data Science: Introduction to DataFrames (m1-03)\nlab_intro\nWe will see you on Zoom on Wednesday â and then IRL this coming Monday for the first lecture of DISCOVERY!\nJanuary 19, 2022\nlab_intro\n: Introduction to Data Science\nData scientists use powerful tools to help learn about data.  In this first lab, you will set up your account and computer for Data Science Discovery and begin to play around with your very first Python notebook!\nJanuary 18, 2022\nGo to Lab Intro\nWelcome to Data Science Discovery!\nData Science DISCOVERY is an in-person course, except that\nall UIUC courses will meet online during the first week back\n.\nMore details as we get closer to the first day of class. :)\nDecember 20, 2021"}
{"url": "https://courses.cs.washington.edu/courses/cse180/21sp/syllabus/#syllabus", "text": "CSE 180, Spring 2019 - Syllabus\nCSE 180: Introduction to Data Science\nHome\nEvents\nContact\nStaff\nSchedule\nSpring 2019\nRyan Maas\n(maas@cs.uw.edu)\nSyllabus\nCourse Goals\nWe live in a world that is increasingly driven by decisions based on analysis\nand inference on diverse data sets.\nThis course will give you an introduction to the conceptual knowledge and\npractical training for doing data science in this environment.\nBroadly we will cover these topics:\nTypes of data\nEvaluating data sets\nSimulation\nProbability\nHypothesis Testing\nEstimation\nLinear regression\nBasic classification\nCourse Content\nThe course uses an experimental application called\nSkillItUp\nthat runs in your browser. The software provides all the learning materials you\nneed and all the evaluations you will receive for the course. The skills section\nof the application provides links to resource Web pages and practice questions\nthat you can use to learn the course content. The challenges section of the\napplication provides the evaluations you will take. The activities section shows\nwhat you will do in class each day.\nClass content is self-paced but you are expected to complete the full set of\nassignments by the end of the quarter.\nLarge class time will consist of activities that you participate in and lab\nsections will give you time to take the evaluations. Project evaluations are\n“take-home” and can be submitted at any time. You must get full credit for each\nevaluation but can take an evaluation as many time as you need to.\nGrading\nGrades will be based both on percentage of challenge assignments completed in\nSkill it Up, and on class participation. The class participation score is\ndetermined both by attendance and filling out the in-class activities, with an\nextra score component for leading discussion and contributing to group work.\nPolicies\nAttendance\nCourse attendance is implicit in participating in the in-class activities, for\nwhich participation credit is assigned. While it's not always possible to make\nevery class, extra scores achieved for leading discussion can more than make up\nfor missing a few activities, so it's important to attend class every day.\nAcademic Misconduct\nAll work turned in is expected to be your own. Although students are encouraged\nto study together, each student is expected to produce his or her own solution\nto the challenges. Copying or using sections of someone else's program, even if\nit has been modified by you, is not acceptable and will result in us referring\nthe situation to the university. Similarly, participation credit codes such as\nBumps are for the recipient to enter only, and if used by another student will\nresult in the same academic consequences."}
{"url": "https://eecs.wsu.edu/~assefaw/CptS483-06/", "text": "Introduction to Data Science: CptS 483-06 -- Syllabus\nLinks:\nSyllabus in PDF\nSchedule and Lecture Material\nCourse information\nCredit hours: 3\nSemester: Fall 2015\nMeeting times and location: MWF 12:10–13:00, Sloan 163\nCourse website:\nwww.eecs.wsu.edu/~assefaw/CptS483-06\nRelevant course material, including this syllabus, and course related resources will be\nmade available at the course website.  Additionally, the online portal OSBLE\n(https://osble.org) will be used for posting lecture material, assignments, announcements, etc\nand for handling submissions.\nInstructor information\nAssefaw Gebremedhin\nOffice: EME 59\nEmail: assefaw AT eecs DOT wsu DOT edu\nHomepage:\nwww.eecs.wsu.edu/~assefaw\nOffice hours\nTentative office hours: Tuesdays 2:00-3:00pm, or by appointment.\nCourse Description\nData Science is the study of the generalizable extraction of knowledge from data. Being a data scientist requires an integrated skill set spanning mathematics, statistics, machine learning, databases and other branches of computer science along with a good understanding of the craft of problem formulation to engineer effective solutions. This course will introduce students to this rapidly growing field and equip them with some of its basic principles and tools as well as its general mindset. Students will learn concepts, techniques and tools they need to deal with various facets of data science practice, including data collection and integration, exploratory data analysis, predictive modeling, descriptive modeling, data product creation, evaluation, and effective communication. The focus in the treatment of these topics will be on breadth, rather than depth, and emphasis will be placed on integration and synthesis of concepts and their application to solving problems. To make the learning contextual, real datasets from a variety of disciplines will be used.\nLearning outcomes\nAt the conclusion of the course, students should be able to:\nDescribe what Data Science is and the skill sets needed to be a data scientist.\nExplain in basic terms what Statistical Inference means. Identify probability distributions\ncommonly used as foundations for statistical modeling. Fit a model to data.\nUse R to carry out basic statistical modeling and analysis.\nExplain the significance of exploratory data analysis (EDA) in data science.\nApply basic tools (plots, graphs, summary statistics) to carry out EDA.\nDescribe the Data Science Process and how its components interact.\nUse APIs and other tools to scrap the Web and collect data.\nApply EDA and the Data Science process in a case study.\nApply basic machine learning algorithms\n(Linear Regression, k-Nearest Neighbors (k-NN), k-means, Naive Bayes)\nfor predictive modeling. Explain why Linear Regression and k-NN are poor choices\nfor Filtering Spam. Explain why Naive Bayes is a better alternative.\nIdentify common approaches used for Feature Generation. Identify basic\nFeature Selection algorithms (Filters, Wrappers, Decision Trees, Random Forests)\nand use in applications.\nIdentify and explain fundamental mathematical and algorithmic ingredients that constitute a Recommendation Engine (dimensionality reduction, singular value decomposition, principal competent analysis). Build their own recommendation system using  existing components.\nCreate effective visualization of given data (to communicate or persuade).\nWork effectively (and synergically) in teams on data science projects.\nReason around ethical and privacy issues in data science conduct and apply ethical practices.\nAudience\nThe course is suitable for upper-level undergraduate (or graduate) students in computer science, computer engineering, electrical engineering, applied mathematics, business, computational sciences, and related analytic fields.\nPrerequisites\nStudents are expected to have basic knowledge of algorithms and reasonable programming experience (equivalent to completing a data structures course such as CptS 223), and some familiarity with basic linear algebra (e.g. solution of linear systems and eigenvalue/vector computation) and basic probability and statistics.\nIf you are interested in taking the course,  but are not sure if you have the right background, talk to the instructor. You may still be allowed to take the course if you are willing to put in the extra effort to fill in any gaps.\nCourse work\nThe course consists of lectures (three times a week, 50 min each), and involves a set of assignments (about 3 or 4) and a project.  A project could take one of several forms: analyzing an interesting dataset using existing methods and software tools; building your own data product; or creating a visualization of a complex dataset. Students are encouraged to work in teams of two or three for a project. Assignments, on the other hand, are to be completed and submitted individually. Besides the assignments and a project, there will be frequent opportunities for in-class exercises and ``thought experiments\".\nGrading\nYour final grade will be determined based on your performance on each of the following items;\nthe percentages in parenthesis show the weight each item carries to the final grade.\nClass participation (10%)\nAssignments (30%)\nProject (30%)\nFinal exam (30%)\nLetter grades:\nA (93--100%), A- (90--92.99%), B+ (87--89.99%), B (83--86.99%),\nB- (80--82.99%), C+ (77--79.99%), C (70--76.99%), C- (67--69.99%),\nD (60--66.99%), F (less than 60%).\nGrading scale may be adjusted depending on class average.\nTopics and Course Outline\nIntroduction: What is Data Science?\nBig Data and Data Science hype -- and getting past the hype\nWhy now? -- Datafication\nCurrent landscape of perspectives\nSkill sets needed\nStatistical Inference\nPopulations and samples\nStatistical modeling, probability distributions, fitting a model\nIntro to R\nExploratory Data Analysis and the Data Science Process\nBasic tools (plots, graphs and summary statistics) of EDA\nPhilosophy of EDA\nThe Data Science Process\nCase Study: RealDirect (online real estate firm)\nThree Basic Machine Learning Algorithms\nLinear Regression\nk-Nearest Neighbors (k-NN)\nk-means\nOne More Machine Learning Algorithm and Usage in Applications\nMotivating application: Filtering Spam\nWhy Linear Regression and k-NN are poor choices for Filtering Spam\nNaive Bayes and why it works for Filtering Spam\nData Wrangling: APIs and other tools for scrapping the Web\nFeature Generation and Feature Selection (Extracting Meaning From Data)\nMotivating application: user (customer) retention\nFeature Generation (brainstorming, role of domain expertise, and place for imagination)\nFeature Selection algorithms\nFilters; Wrappers; Decision Trees; Random Forests\nRecommendation Systems: Building a User-Facing Data Product\nAlgorithmic ingredients of a Recommendation Engine\nDimensionality Reduction\nSingular Value Decomposition\nPrincipal Component Analysis\nExercise: build your own recommendation system\nMining Social-Network Graphs\nSocial networks as graphs\nClustering of graphs\nDirect discovery of communities in graphs\nPartitioning of graphs\nNeighborhood properties in graphs\nData Visualization\nBasic principles, ideas and tools for data visualization\nExamples of inspiring (industry) projects\nExercise: create your own visualization of a complex dataset\nData Science and Ethical Issues\nDiscussions on privacy, security, ethics\nA look back at Data Science\nNext-generation data scientists\nBooks\nThe following book will be used as a textbook and primary resource to guide the discussions, but will be heavily supplemented with lecture notes and reading assignments from other sources. The lecture notes and reading material will be posted on the course's website or\nthe associated OSBLE page as the course proceeds.\nCathy O'Neil and Rachel Schutt. Doing Data Science, Straight Talk From The Frontline. O'Reilly. 2014.\nAdditional references and books related to the course:\nJure Leskovek, Anand Rajaraman and Jeffrey Ullman. Mining of Massive Datasets. v2.1, Cambridge University Press. 2014. (free online)\nKevin P. Murphy. Machine Learning: A Probabilistic Perspective. ISBN 0262018020. 2013.\nFoster Provost and Tom Fawcett. Data Science for Business: What You Need to Know about Data Mining and Data-analytic Thinking. ISBN 1449361323. 2013.\nTrevor Hastie, Robert Tibshirani and Jerome Friedman. Elements of Statistical Learning, Second Edition. ISBN 0387952845. 2009. (free online)\nAvrim Blum, John Hopcroft and Ravindran Kannan. Foundations of Data Science. \\\\\n(Note: this is a book currently being written by the three authors. The authors have made the first draft of their notes for the book available online. The material is intended for a modern theoretical course in computer science.)\nMohammed J. Zaki and  Wagner Miera Jr. Data Mining and Analysis: Fundamental Concepts and Algorithms. Cambridge University Press. 2014.\nJiawei Han, Micheline Kamber and Jian Pei. Data Mining: Concepts and Techniques, Third Edition. ISBN 0123814790. 2011.\nPolicies\nMissing or late work\nSubmissions will be handled via the OSBLE page of the course.\nStudents are expected to submit assignments by the specified due date and time.\nAssignments turned in up to 48 hours late will be accepted with\na 10% grade penalty per 24 hours late.  Except by prior arrangement,\nmissing or work late by more than 48 hours will be counted as a zero.\nAcademic Integrity\nAcademic integrity will be strongly enforced in this course.\nAny student who violates the University's standard of conduct relating to academic integrity will receice\nan F as a final grade in this course, will not have the option to withdraw from the course and will be\nreported to the Office of Student Standards and Accountability.\nCheating is defined in the Standards for Student Conduct WAC 504-26-010 (3).\nYou can learn more about Academic Integrity on the WSU campus at\nhttp://conduct.wsu.edu\n.\nPlease also read this link carefully:\nEECS Academic Integrity Policy\n.\nUse these resources to ensure that you do not inadvertently violate WSU's standard of conduct.\nSafety on Campus\nWashington State University is committed to enhancing the safety of the students, faculty, staff, and visitors. It is highly recommended that you review the Campus Safety Plan\n(\nhttp://safetyplan.wsu.edu/\n) and\nvisit the Office of Emergency Management web site\n(\nhttp://oem.wsu.edu/\n) for a comprehensive listing of university policies, procedures, statistics, and information related to campus safety, emergency management, and the health and welfare of the campus community.\nStudents with Disabilities\nReasonable accommodations are available for students with a documented disability. If you have a disability and need accommodations to fully participate in this class, please either visit or call the Access Center (Washington Building 217; 509-335-3417) to schedule an appointment with an Access Advisor. All accommodations MUST be approved through the Access Center.\nFor more information, consult the webpage\nhttp://accesscenter.wsu.edu\nor email at\nAccess.Center@wsu.edu\n.\nImportant Dates and Deadlines\nStudents are encouraged to refer to the academic calendar often to be aware of critical\ndeadlines throughout the semester. The academic calendar can be found at\nwww.registrar.wsu.edu/Registrar/Apps/AcadCal.ASPX\n.\nWeather Policy\nFor emergency weather closure policy, consult:\nhttp://alert.wsu.edu\n.\nChanges\nThis syllabus is subject to change. Updates will be posted on the course\nwebsite."}
{"url": "https://ds-wm.github.io/course/intro/syllabus/index.html", "text": "Syllabus | Intro to Data Science\nSyllabus | Intro to Data Science\nData Science @ William & Mary\nSpring 2021\nCourse Overview\nIn this course students will learn the fundamentals of data processing and modeling in the context of Data Science. Emphasis will be placed on careful planning and deliberate decision making when working with data and building models. Programming will be done in the Python language and we will be making extensive use of the\nscikit-learn\ncollection.\nAfter learning about the basics of having a good Data Pipeline, students will be introduced to a variety of supervised and unsupervised machine-learning techniques including various methods for regression, classification, and clustering. By the end of the course, students are not expected to be an expert on any particular technique, but should exhibit a solid high-level understanding of the goals of each method, be able to determine when a particular type of model is more or less suitable to a real-world problem and, most importantly, demonstrate a keen attention to detail when working with data.\nThroughout the course, there will be a very strong emphasis placed on understanding why we are doing what we are doing.\nCatalog Number\nDATA 146\nSection 2\nCRN 25117\nPre-/co-requisites\n“Programming for Data Science” (DATA 141 or CSCI 140) or “Computational Problem Solving” (CSCI 141)\nSemester\nSpring 2021 (2021-Jan-27 to 2021-May-18)\nLocation\nThis course is taught online (remotely); therefore, it can be completed from anywhere.\nClass Times\nMo/We/Fr 1100–1150\nInstructor\nDr. Tyler W. Davis\nEmail:\ntwdavis@wm.edu\nPhysical Office: Center for Geospatial Analysis, Swem Library Rm 213\nVirtual Office:\nNooks\nPhone: 757-221-6449\nWebsite:\nhttps://ds-wm.github.io\nOffice Hours\nSchedule is posted on virtual office website\nAppointments are welcome outside normally scheduled office hours; please message or email to set up a time.\nThere may be certain days when office hours will be either canceled or rescheduled; notifications will be sent ahead of time.\nDelivery\nCourse will delivered\nRSOF\n, which is fully remote and predominantly synchronous, off campus.\nSome aspects of the class (e.g., lectures, lessons, or demonstrations) will be made available as a recording for to watch either before or after class\nSynchronous class sessions\nwill not\nnecessarily be recorded; you are responsible for missed content\nFinal Exam Period\nTuesday, 18 May 2021 @ 09:00\nMinimum Passing Grade\nD-\nCommunication\nInstant messaging (e.g.,\nSlack\n)\nFor instant delivery of content or for questions that need quick responses.\nYou will be invited to our Slack using your W&M email.\nCourse materials delivered using\nBlackboard\nThis will serve as a primary content hub; all other content will be linked from here.\nYou need access to Blackboard for this class.\nVideo conferencing (e.g,\nZoom\nor\nNooks\n)\nVideo conferencing is for office hours, video chats, and synchronous class meetings where “face-to-face” communication or screen sharing is required.\nZoom room links are posted on Blackboard.\nPlease note that Nooks presently does not support mobile devices or Safari web browser :(\nEmail (\ntwdavis-at-wm-dot-edu\n)\nThe new snail mail; use this for personal communication or whenever sharing is inappropriate.\nTextbook\nThere is no textbook for this class.\nCourse Materials\nLaptop or desktop computer (\nrequired\n)\n*\nYour computer should have at least 500 MB of free disk space, have at least 8 GB of memory, and run a modern desktop OS (e.g,. PC, Mac, or Linux).\nYou should have access to headphones and a microphone for virtual class meetings; these will minimize the feedback and allow for an easier time with class discussions.\nCourse Structure\nMost weeks will be organized as follows:\nMonday: Lecture\nWednesday: Guided Examples\nFriday: In-class exercises\nNot all topics are guaranteed to fit nicely into a single week, so some adjustments to this schedule may be made along the way. Additionally, we have a few short weeks due to the distribution of Spring Break days throughout the semester. Aside from these nuances, the general structure of the class is as follows:\nSince we have SO MANY students interested in Data Science, we are running four concurrent sections of DATA 146 this semester!\nOur Monday lectures will be held as a large Zoom meeting with all four sections, and delivered by one of the four faculty members teaching DATA 146 (Dr. Tyler Frazier, Dr. Tyler Davis, Dr. Daniel Vasiliu, Dr. Ron Smith).\nOn Wednesdays, your instructor will walk you through some examples where we will learn how to write the code to apply the techniques introduced in the Monday lecture.\nOn Fridays, you will be given exercises to work on in class, with the help of your classmates and instructor.\nCourse Grading Policy\nMost weeks you will be given a lab to work on outside of class. These labs will usually be assigned on Mondays and will due the following Sunday at midnight.\nThe midterm and final projects will be similar to the labs, but more substantial (and cumulative). All assignments will consist of a mixture of conceptual questions, as well as adapting the techniques we have learned to new data sets and reporting/interpreting the results. All assignments will be completed on Blackboard.\nImportant note:\nYou may only make one submission per assignment! This is to encourage you to carefully double-check your work before you submit.\nThe grade breakdown is as follows:\nLabs: 60%\nAssigned on Monday and due the following Sunday by midnight\nMidterm & Final Projects: 30% (15% each)\nParticipation: 10%\nBelow is a Python function to compute your final letter grade, based on your numerical grade.\ndef GetLetterGrade(pct_score):\n\"\"\"\nName:     GetLetterGrade\nInputs:   float, final percentage score (pct_score)\nOutputs:  str, final letter grade\nFeatures: Returns your letter grade given your percentage score\n\"\"\"\nif pct_score > 0.91:\nreturn \"A\"\nelif pct_score > 0.9:\nreturn \"A-\"\nelif pct_score > 0.89:\nreturn \"B+\"\nelif pct_score > 0.81:\nreturn \"B\"\nelif pct_score > 0.8:\nreturn \"B-\"\nelif pct_score > 0.79:\nreturn \"C+\"\nelif pct_score > 0.71:\nreturn \"C\"\nelif pct_score > 0.7:\nreturn \"C-\"\nelif pct_score > 0.69:\nreturn \"D+\"\nelif pct_score > 0.61:\nreturn \"D\"\nelif pct_score > 0.6:\nreturn \"D-\"\nelse:\nreturn \"F\"\nCollaboration\nCollaboration is both allowed and encouraged! Most of the time in life we are not working in isolation, and it is both wise and efficient to use all resources available to you, including professors, coworkers, other students, the internet, etc.\nThe only thing that is off limits is the discussion of specific answers to any graded assignment.\nAdditionally, although we are conducting this course remotely - you may very well make some lifelong friends along the way, and the chances of this become greater the more you choose to interact with others!\nNever underestimate the power of community, collaboration, and cooperation, and don’t allow pride, ego, or shyness to interfere with the development of your own creative potential. Always ask for help when you need it, and help others when you are able!\nCommunication\nOur preferred method of communication will be Slack and\nPiazza\n. You will receive a Slack invitation prior to our first class, and I encourage you to make a post and introduce yourself!\nI encourage you to post any general questions about course material here first. You are free to use either one or both of these tools, choose whichever works best for you. Just note that you may need to adjust your preferences so that you don’t get inundated with notifications every time someone makes a post.\nYou may ask questions of each other, as well as contact me either publicly or privately. Regular participation (both asking and answering questions) is strongly encouraged.\nResources\nThe in-class examples will be presented in a Jupyter notebook format (.ipynb files).\nWhen coding in class, I typically use the\nJupyterHub\n; however, you are free to use whatever editor/IDE you prefer (we will discuss several options in class).\nBefore contacting me with technical issues, I only ask that you test your code on JupyterHub first, as this ensures that you and I will both have the exact same installation, version numbers, etc. (\nNote\n: last semester, a few students were getting different answers than I was even when running identical code, which ended up being due to a difference in the random number algorithm that the computer was using caused by running an older version of one of the code libraries we were using. This took a bit of time to troubleshoot!).\nSome useful links are below:\nAnaconda:\nhttps://www.anaconda.com/\nCourse Schedule\nThis course will be presented in several modules. Expect for each module to span somewhere between 1-3 weeks; this will depend both on the progress of the class as well as the amount of material in the module.\nFor our first day of class I will review the syllabus and course expectations with you, and give you a brief introduction to the history of Data Science.\nModule 0: Python Review\nSome preliminary review and practice with Python using JupyterHub.\nModule 1: The Data Pipeline\nAfter some preliminary review and practice with Python, we will talk about what it means to have a good Data Pipeline (which will be a recurring theme throughout the semester).\nAs an example, we will write a program to retrieve data from The Covid Tracking Project (\nhttps://covidtracking.com/\n), perform some basic preprocessing, and create a plot of selected COVID-19 statistics for states in the US. Once complete, we will be able to get up to date data and produce new output with only a few lines of code, using functions we have written.\nKeywords\npandas\nmatplotlib\nDataFrame\ndata preprocessing\ndata pipeline\nModule 2: Data Preprocessing and Descriptive Analysis\nBefore building any model, it is always a good idea to “get to know” your data. Summary statistics and visualizations are often a good way to go about this. Additionally, it is not uncommon to have to make corrections to your data, either due to inaccuracies/missing data, or to facilitate future modeling steps.\nThe topics In this module will include some common data preprocessing steps, basic data visualizations, how to handle missing data, and dimensionality reduction techniques such as PCA and tSNE. The topics discussed in this module will be used throughout the remainder of the semester.\nKeywords\nscatter plot\nbox plot\nhistogram\ncentral tendency\nvariability\npercentile\nquantile\nsummary statistic\ndimensionality reduction\nPrincipal Component Analysis (PCA)\ntSNE\nModule 3: Intro to Modeling and Model Validation\nIn this module we will be introduced to modeling via linear regression (ordinary least squares). We will also discuss how to assess things like whether a model is overfit using a procedure known as K-fold cross validation. We will then look at types of regularization, namely Ridge, Lasso, and Elastic Net regression. These processes can, among other things, sometimes help to prevent overfitting. We will also discuss the importance of “feature scaling” in this module.\nKeywords\nlinear regression\nordinary least squares\ninternal validity\nexternal validity\nK-fold cross validation\nregularization\nhyperparameter\nRidge regression\nLasso regression\nElastic Net regression\nReview and Midterm\nThe midterm will be completed on Blackboard, similar to our weekly lab assignments but more substantial. We will devote at least one day to review, and you will be given one class period’s time off to work on the project.\nModule 4: Classification\nIn this module we will be introduced to several classification methods, all of which are types of supervised learning. While the overall goal of each method is similar, the methods and results can be quite different. We will explore the differences between these methods when applied to the same data sets and discuss some of the pros and cons of each.\nKeywords\nLogistic Regression\nK-nearest neighbors\nsupervised learning\nModule 5: Decision Trees and Random Forests (Classification & Regression)\nIn this module, we will learn about Decision Trees and Random Forests. Primarily motivated for the purposes of classification; however, we will also see how they can be used for regression.\nKeywords\nDecision Tree Classification/Regression\nRandom Forest Classification/Regression\ngini impurity\nensemble models\nModule 6: Clustering\nIn this module we will be introduced to several clustering methods, all of which are types of unsupervised learning. We will also discuss the difference between supervised and unsupervised learning, by contrasting these approaches with the classification methods seen in the previous module.\nKeywords\nK-means\nDBSCAN\nAgglomerative Hierarchical Clustering\nunsupervised learning\nModule 7: Neural Networks\nIn our final module we will be introduced to neural networks, starting with the classic multilayer perceptron, and then moving into more state-of-the-art techniques such as convolutional neural networks.\nKeywords\nneural network\nhidden layer\nmultilayer perceptron (MLP)\nconvolutional neural network (CNN)\nReview and Final\nThe final project will be similar in length to the midterm, and you will need to leverage techniques learned throughout the entire semester.\nOther Important Dates\nLast day of add/drop: February 5\nLast day to withdraw: March 29\nAccommodations\nIf you need accommodations,\nyou have a right to have these met\n, so it is best to notify the instructor as soon as possible.\nIt is the policy of William & Mary to accommodate students with disabilities and qualifying diagnosed conditions in accordance with federal and state laws. Any student who feels s/he may need an accommodation based on the impact of a learning, psychiatric, physical or chronic health diagnosis should be referred to\nStudent Accessibility Services\nstaff at 757-221-2509 or at\nsas@wm.edu\n. SAS staff will work with you to determine if accommodations are warranted, and if so, to help you obtain an official letter of accommodation."}
{"url": "https://www.ifi.uzh.ch/en/dast/teaching/FDS.html", "text": "Foundations of Data Science | Department of Informatics  | UZH\nSkip navigation\nHeader\nLogo of the University of Zurich, to homepage\nSearch\nOpen/Close Navigation\nDepartment of Informatics\nData Systems and Theory\nQuicklinks\nHome\nContact\nSearch\nMain navigation\nNews\nZurück\nNews\nNews\nMenü schliessen\nGroup Events\nZurück\nGroup Events\nGroup Events\nMenü schliessen\nOpen Positions\nZurück\nOpen Positions\nOpen Positions\nMenü schliessen\nPeople\nZurück\nPeople\nPeople\nMenü schliessen\nResearch\nZurück\nResearch\nResearch\nMenü schliessen\nPublications\nZurück\nPublications\nPublications\nMenü schliessen\nCode\nZurück\nCode\nCode\nMenü schliessen\nStudent Projects\nZurück\nStudent Projects\nStudent Projects\nMenü schliessen\nTalks\nZurück\nTalks\nTalks\nMenü schliessen\nFunding\nZurück\nFunding\nFunding\nMenü schliessen\nTeaching\nZurück\nTeaching\nTeaching\nMenü schliessen\nAwards\nZurück\nAwards\nAwards\nMenü schliessen\nMore\nMenü schliessen\nHome\nData Systems and Theory\nTeaching\nFoundations of Data Science\nFoundations of Data Science\nThe target groups for this course are the MSc students (with major or minor in data science, or studying computer science) and PhD students across the university.\nLearning Outcomes\nThis course introduces gradually a wealth of supervised and unsupervised learning methods and models.\nStudents will learn the algorithms which underpin popular machine learning techniques, as well as developing an understanding of the theoretical relationships between these algorithms.\nDuring the seven exercise sessions, the students will apply the concepts taught in the lectures to further strengthen their understanding of these concepts. The last exercise session is a revision class in preparation for the written exam.\nThe three practical tasks will concern the application of machine learning to a range of real-world problems.\nCourse Topics\nIntroduction to Data Science\nWhat is Data Science?; Origins of Data Science; Full Scope of Data Science; Scope of This Course\nData Science vs: Computer Science, Statistics, Machine Learning\nThe Future of Data Analysis (Tukey); The Two Cultures (Breiman)\nThe Big Data Buzz\nIntroduction to Machine Learning\nWhat is Machine Learning? Programming vs Learning; Evolution of Machine Learning; Machine Learning in Action\nAn Early Automatic Classification Example and  The Perceptron Algorithm\nModels and Methods Covered in This Lecture\nApplications: House Price Prediction; Object Detection and Classification\nLearning Flavours: Supervised (Regression, Classification); Unsupervised (Dimensionality Reduction, Clustering); Active; Semi-Supervised; Collaborative Filtering; Reinforcement Learning\nMathematics for Machine Learning\nLinear Algebra: Vectors (Vector Norms, Inner Product Spaces); Matrices (Operations); Eigenvectors and Eigenvalues; Positive (Semi-)Definiteness\nCalculus: Continuous and Differentiable Functions of One or Multiple Variables; Finding Extrema (First Derivative Test, Second Derivative Test, Critical Points); Partial Derivatives, Gradients, Hessian, Jacobian; Matrix Calculus, Chain Rule in Higher Dimensions; Optimality with Side Conditions, Lagrange Multipliers\nProbability Theory: Probability Space; Conditional Probability, Bayes Rule; Random Variables; Joint Probability Distributions; Expectation, Variance, Standard Deviation, Covariance; Discrete and Continuous Probability Disctributions (Bernoulli, Binomial, Multivariate Normal, Laplace)\nLinear Regression\nLinear Regression by Example\nDefinition, Bias, Noise, One-hot Encoding, Learning vs Testing\nLeast Squares Objective, Gradient, Computing the Paramters\nFinding Optimal Solution using Matrix Calculus, Differentiating Matrix Expressions, Deriving the Least Squares Estimates\nComputational Complexity of Parameter Estimation\nLeast Squares Estimate in the Presence of Outlliers\nMaximum Likelihood\nProbabilistic vs Optimisation Views in Machine Learning\nMaximum Likelihood Principle, Examples\nProbabilistic Formulation of the Linear Model via Maximum Likelihood, Gaussian Noise Model\nMaximum Likelihood Estimator vs Least Squares Estimator, (Log, Negative Log) Likelihood of Linear Regression\nOutliers, Maximum Likelihood for Laplace Noise Model\nBasis Expansion, Learning Curves, Overfitting, Validation\nBasis Expansion: Polynomial, Radial Basis, using Kernels, Kernel Trick\nHow to Choose Hyperparameters for RBF Kernel?\nGeneralisation Error, Bias-Variance Tradeoff, Learning Curves\nOverfitting: How Does it Occur? How to Avoid it?\nValidation Error, Training and Validation Curves, Overfitting on the Validation Dataset (Kaggle Learderboard)\nk-fold Cross-Validation, Grid Search\nRegularisation\nEstimate for Ridge Linear Regression, Lagrangian (Constrained Optimisation) Formulation\nLASSO: Least Absolute Shrinkage and Selection Operator\nEffect of Ridge and Lasso Hyperparameter on Weights\nFeature Selection\nGoal, Premise, and Motivation\nFeature Selection to Reduce Overfitting\nFeature Selection Methods: Wrapper methods (Forward Stepwise Selection), Filter methods (Mutual Information, Pearson Correlation Coefficient), Embedded methods (LASSO, Elastic Net Regularisation)\nConvex Optimisation\nConvex Sets, Examples, Proving Common Cases of Convex Sets (PSD Cone, Norm Balls, Polyhedra)\nConvex Functions, Examples\nConvex Optimisation Problems: Classes (Linear Programming, Quadratically Constrained Quadratic Programming), Local vs Global Optima, Proof of Local=Global Theorem\nExamples: Linear Model with Absolute Loss, Minimising the Lasso Objective, Linear Regression with Gaussian Noise Model\nFirst-Order and Second-Order Optimisation\nCalculus Background: Gradient Vectors, Contour Curves, Direction of Steepest Increase, Sub-gradient, Hessian\nGradient Descent: Algorithm, Geometric Interpretation, Choosing Step Size (Backtracking Line Search), Convergence Test, Stochastic vs (Mini-)Batch, Sub-gradient Descent\nConstrained Convex Optimisation: Projected Ggradient Descent\nNewton’s Method: second-order Taylor Function Approximation, Geometric Interpretation, Computation and Convergence\nGenerative Models for Classification\nDiscriminative vs Generative Models\nSupervised Learning: Regression vs Classification\nGenerative Classification Model: Definition, Prediction\nMaximum Log-Likelihood Estimator for Class Probability Distribution\nNaïve Bayes Classifier: Training and Predicting with Missing Data\nGaussian Discriminant Analysis: Maximum Likelihood Estimator, Quadratic/Linear Discriminant Analysis, Two-Class Linear Discriminant Analysis, Decision Boundaries, Sigmoid and Softmax Functions\nLogistic Regression\nModels for Binary Classification\nLogistic Regression: Definition, Prediction, Contour Lines Represent Class Label Probabilities, Negative Log-Likelihood vs Cross-Entropy, Maximum Likelihood Estimate, Newton Method for Optimising the Negative Log-Likelihood, Iteratively Re-Weighted Least Squares\nMulticlass Classification\nOne-vs-One, One-vs-Rest, Error Correcting Approach\nSoftmax, Multiclass Logistic Regression\nMeasuring Performance for Classification\nConfusion Matrix, Sensitivity, Recall, Specificity, Precision, Accuracy; Examples\nROC (Receiver Operating Characteristic) Curve, Confusion Matrices for Different Decision Boundaries, Area under the ROC Curve\nPrecision-Recall Curve\nSupport Vector Machines\nMaximum Margin Principle, Support Vectors, Formulation as Convex Optimisation Problem in the Linearly (Non-)Separable Case\nHinge Loss Optimisation, Hinge vs Logistic\nPrimal vs Dual Formulation, Constrained Optimisation with Inequalities, Karush-Kuhn-Tucker Conditions, When to Prefer the Dual Formulation\nKernel Methods: Mercer Kernels in SVM Dual Formulation, Kernel Engineering, Examples with Polynomial, RBF, and String Kernels\nNeural Networks\nMulti-layer Perceptrons: Example, Matrix Notation, Multi-layer Perceptron vs Logistic Regression\nThe Backpropagation Algorithm: Example, Forward and Backward Equations, Computational Aspects\nTraining Neural Networks: Difficulties (Saturation, Vanishing Gradient, Overfitting), Known Hacks (Early Stopping, Adding Data, Dropout), Rectified Linear Unit, Dying ReLU, Leaky ReLU, Initialising Weights and Biases, Examples\nConvolutional Neural Networks: Convolution, Pattern-Detecting Filters, Convolutional Layers, Pooling, Popular Convolutional Neural Networks, Training\nClustering\nClustering Objective\nk-Means Clustering: Algorithm, Convergence, Choosing k,\nTransforming input formats: Euclidean Space, Dissimilarity Matrix, Singular Value Decomposition, Multidimensional Scaling\nHierarchical Clustering: Linkage Algorithms\nSpectral Clustering\nPrincipal Component Analysis\nDimensionality Reduction\nMaximum Variance View vs Best Reconstruction View of Principal Component Analysis\nFinding Principal Components using Singular Value Decomposition and Iterative Method\nApplications: Reconstruction of an Image using PCA, Eigenfaces, Latent Semantic Analysis\nPracticals\nThe practical tasks require implementation using jupyter notebooks, Python, Scikit-learn, and TensorFlow.\nImplementation of Linear Regression (Ridge, Lasso)\nComparison of Generative and Discriminative Models\nClassification of Handwritten Digits using the MNIST dataset and TensorFlow 2.0\nExercise Sessions\nMathematical Basics\nLinear Regression; Perceptron\nMaximum Likelihood; Regularisation\nOptimisation; Generative Models\nLogistic Regression; Support Vector Machines; Kernel Methods\nNeural Nets; Clustering\nRevision Class\nPrerequisites\nIntroductory courses on: (1) Calculus, (2) Linear Algebra, (3) Probability Theory, (4) Design and Analysis of Algorithms. The course is not recommended for students without the necessary mathematical background. The students who would like to recall necessary background should consult the following resources:\nVery brief overview on\nMathematics for Machine Learning\nMultivariate Calculus\nLinear Algebra\nLinear Algebra and its Applications\nFamiliarity with Python and jupyter notebook is of advantage as these languages will be used in the practicals.\nRecommended Resources\nMost material covered in the course can be found in the following books (available online for free, search for them).\nC. M. Bishop. Pattern Recognition and Machine \tLearning. Springer 2006.\nI. Goodfellow, Y. Bengio, A. Courville. Deep Learning, MIT Press 2016.\nK. P. Murphy. Machine Learning: A Probabilistic Perspective. MIT Press 2012.\nIn addition, students may find the following books useful as supplementary reading.\nT. Hastie, R. Tibshirani and J. Friedman. The Elements of Statistical Learning. Springer 2011. (Available for download on the authors' web-page)\nM. Nielsen. Neural Networks and Deep Learning.\nGéron, Aurélien. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. O'Reilly Media, 2019.\nS. Boyd, L. Vandenberghe. Convex Optimization, Cambridge University Press 2004.\nAdditional links\n© 2023 Universität Zürich\nAbout this site\nContact\nData Protection Statement"}
{"url": "https://scds.uoregon.edu/ds/undergraduate-program/courses/dsci-101", "text": "DSCI 101 : Foundations of Data Science I | Data Science | School of Computer and Data Sciences\nSkip to main content\nOne Stop\nApply\nVisit\nGive\nSearch\nSearch this site\nSearch\nMenu\nSchool of Computer and Data Sciences Menu\nComputer Science\nData Science\nDirectory\nAbout\nAbout Overview\nExecutive Director\nTake Action\nOne Stop\nApply\nVisit\nGive\nCollege of Arts and Sciences\nSchool of Computer and Data Sciences\nData Science\nDepartment Navigation\nHow to Apply\nUndergraduate Program\nEmphasis Domains\nMeet Our Students\nExperiential Learning\nResearch\nDirectory\nContact Us\nDSCI 101 : Foundations of Data Science I\nDSCI 101 is an introductory course intended to provide students with an understanding of fundamental concepts in data science. This is the first of two foundational courses, the next course in the series is\nDSCI 102\n.\nThis course utilizes a quantitative approach to explore fundamental concepts in data science.\nStudents will develop key skills in programming and statistical inference as they interact with real-world data sets across a variety of domains. Ethical ramifications of data collection, data-driven decision-making, and privacy will be explored. This course is designed to be accessible to students without prior experience in computer programming or statistics.\nLectures and Labs\nTwo 80-minute lectures are delivered each week. Mandatory attendance at a 110-minute lab each week is also required.\nPrerequisites\nNone - This course is designed for entry-level students from any major. It is explicitly designed for students who have not previously taken statistics or computer science courses. No math beyond basic addition.\nTextbooks and Readings\nTextbook:\nComputational and Inferential Thinking: The Foundations of Data Science\n, a free online textbook that includes Jupyter notebooks and public data sets for its examples.\nExpected Learning Outcomes\nUpon successful completion of this course each student should be able to:\nDiscover, organize, analyze, and visualize data using the Python programming language\nIdentify potential errors in data collection and analysis and discuss their consequences\nApply concepts of statistical inference including sampling and simulation to create and test models\nDevelop and test null and alternative hypotheses to answer domain-specific questions\nOutline ethical ramifications of data collection, data-driven decision making, data sharing, and privacy\nCourse Requirements and Grading\nThis course will be taught as two 80-minute live lectures and one 110-minute lab each week. Aside from the required textbook, all course materials (project assignments, lab assignments, tutorial videos, sample exam material) will be available from Canvas. We will be using Slack for asynchronous questions and answers.\nGrading will be based on the following criteria:\nPercentage\nComponent\n6\nLab attendance (8 x 0.75%)\n16\nLab assignments (8 x 2%)\n28\nHomework (7 x 4%)\n10\nProject 1 (1 x 10%)\n10\nProject 2 (1 x 10%)\n10\nQuizzes (2 x 5%)\n20\nFinal (1 x 20%)\nDSCI majors must take DSCI 101 graded; all others may take it graded or P/N\nGrading Scale\n+\n-\nA\n96.67-100.0\n93.34-96.66\n90.00-93.33\nB\n86.67-89.99\n83.34-86.66\n80.00-83.33\nC\n76.67-79.99\n73.34-76.66\n70.00-73.33\nD\n66.67-69.99\n63.34-66.66\n60.00-63.33\nF\n0.00-59.99\nAbout\nExecutive Director\nCourses\nDSCI 101 : Foundations of Data Science I\nDSCI : 102 Foundations of Data Science II\nDSCI 299 : Data Structures in Python\nDSCI 311 : Principles and Techniques of Data Science\nDSCI 345 : Probability and Statistics for Data Science\nDSCI 372 : Machine Learning for Data Science\nDSCI 411 : Capstone Project\nSample Schedules\nSchool of Computer and Data Sciences\nOur mission is to empower a diverse population of students and faculty working to advance knowledge in computer and data science, train the next generation of scholars, and engage with the wider world to tackle interdisciplinary challenges.\nTo do this, we start by applying our knowledge and experience at home across the University of Oregon campus.\nCollege of Arts and Sciences\nSchool of Computer and Data Sciences\n1202 University of Oregon\nEugene\n,\nOR\n97403\nSCDS Administrative Office: Pacific Hall , Suite 203\nDepartment of Data Science: 203 Pacific Hall\nDepartment of Computer Science: 120 Deschutes Hall\nReport a Concern\nNondiscrimination and Title IX\nAccessibility\nPrivacy Policy\nCareers\nAbout\nFind People\n©\nUniversity of Oregon\n.\nAll Rights Reserved."}
{"url": "http://www.idssp.org/pages/purpose.html", "text": "International Data Science in Schools Project: Purpose\nThe last decade has seen unprecedented growth in the availability of\ndata in most areas of human endeavor.  Whole branches of science have\nbeen developed to allow corporations to transform the way marketing is\nconducted, to drive scientific progress in areas such as Bioinformatics,\nand to inform decision-making at all levels in governments and industry.\nFurther, the scale and complexity of much of these data are beyond\nthe capability of a single computer to manage or a single individual\nto analyze.\nThese realities generate a very significant imperative to\nensure that there is an adequate supply of people entering\nthe workforce who are equipped to handle the new challenges\nof learning from data. There is a compounding factor:  on\nthe evidence available, demand for data scientists is not\nonly massively outstripping supply, but the situation is\nworsening, and this is a world-wide problem.\nAnd beyond this, there is an equally pressing need for people in our\nsocieties to be more capable of understanding, interpreting and making\ndecisions based on quantitative data as they cope with the vagaries\nof life.\nThe purpose of this international collaborative project is\nto transform the way education in\nData Science\nis carried\nout in the last two years of school, with two objectives:\nTo ensure that school students acquire a sufficient\nunderstanding and appreciation of how data can be acquired\nand used to make decisions so that they can make informed\njudgments in their daily lives, as students and then as\nadults.  In particular, we envisage future generations of\nlawyers, journalists, historians, and many others, leaving\nschool with a basic understanding of how to work with data\nto make decisions in the presence of uncertainty, and how\nto interpret quantitative information presented to them in\nthe course of their professional and personal activities.\nTo instil in more scientifically able school students\nsufficient interest and enthusiasm for Data Science\nthat they will seek to pursue tertiary studies in Data\nScience with a view of making a career in the area.\nIn both cases, we want to teach people how to Learn from Data.\nOur goal is to provide the content for a pre-calculus course\nin Data Science that is fun to learn and fun to teach.\nA total of some 240 hours of instruction is envisaged. As\na parallel development we will devise a program will enable\nteachers from a wide variety of backgrounds â basically any\ndiscipline that involves data, or mathematics teachers â to\nlearn to present the course well. It is also planned to\nmake the course available in a variety of modes of delivery.\nThe project will be carried out in two phases. The initial focus is on Phase 1.\nPhase 1:  In the Curriculum phase (approximately 18\nmonths), an international Curriculum Team (CT) comprising\nwell-regarded computer scientists and statisticians,\naided by an Advisory Group of computer scientists,\nstatisticians, school teachers and curriculum experts,\nwill develop curriculum frameworks for the student and teacher\nprograms.\nPhase 2:  In the Implementation phase, the curriculum frameworks\ndevised in Phase 1 will provide the basis for developing resources to support\ncourses in a variety of formats, suitable for different modes of delivery\n(classroom, MOOC, self-learning, ...).\nThe project involves computer scientists, statisticians,\nschool teachers, curriculum experts and educators from\nAustralia, Canada, England, Germany, New Zealand and the\nUnited States.\nUpdated 02 Apr 2018, Wesley Burr."}
{"url": "https://github.com/UVADS/DS1001", "text": "GitHub - UVADS/DS1001: Repo for Foundations of Data Science\nSkip to content\nNavigation Menu\nToggle navigation\nSign in\nAppearance settings\nPlatform\nAI CODE CREATION\nGitHub Copilot\nWrite better code with AI\nGitHub Spark\nBuild and deploy intelligent apps\nGitHub Models\nManage and compare prompts\nMCP Registry\nNew\nIntegrate external tools\nDEVELOPER WORKFLOWS\nActions\nAutomate any workflow\nCodespaces\nInstant dev environments\nIssues\nPlan and track work\nCode Review\nManage code changes\nAPPLICATION SECURITY\nGitHub Advanced Security\nFind and fix vulnerabilities\nCode security\nSecure your code as you build\nSecret protection\nStop leaks before they start\nEXPLORE\nWhy GitHub\nDocumentation\nBlog\nChangelog\nMarketplace\nView all features\nSolutions\nBY COMPANY SIZE\nEnterprises\nSmall and medium teams\nStartups\nNonprofits\nBY USE CASE\nApp Modernization\nDevSecOps\nDevOps\nCI/CD\nView all use cases\nBY INDUSTRY\nHealthcare\nFinancial services\nManufacturing\nGovernment\nView all industries\nView all solutions\nResources\nEXPLORE BY TOPIC\nAI\nSoftware Development\nDevOps\nSecurity\nView all topics\nEXPLORE BY TYPE\nCustomer stories\nEvents & webinars\nEbooks & reports\nBusiness insights\nGitHub Skills\nSUPPORT & SERVICES\nDocumentation\nCustomer support\nCommunity forum\nTrust center\nPartners\nOpen Source\nCOMMUNITY\nGitHub Sponsors\nFund open source developers\nPROGRAMS\nSecurity Lab\nMaintainer Community\nAccelerator\nArchive Program\nREPOSITORIES\nTopics\nTrending\nCollections\nEnterprise\nENTERPRISE SOLUTIONS\nEnterprise platform\nAI-powered developer platform\nAVAILABLE ADD-ONS\nGitHub Advanced Security\nEnterprise-grade security features\nCopilot for Business\nEnterprise-grade AI features\nPremium Support\nEnterprise-grade 24/7 support\nPricing\nSearch or jump to...\nSearch code, repositories, users, issues, pull requests...\nSearch\nClear\nSearch syntax tips\nProvide feedback\nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancel\nSubmit feedback\nSaved searches\nUse saved searches to filter your results more quickly\nName\nQuery\nTo see all available qualifiers, see our\ndocumentation\n.\nCancel\nCreate saved search\nSign in\nSign up\nAppearance settings\nResetting focus\nYou signed in with another tab or window.\nReload\nto refresh your session.\nYou signed out in another tab or window.\nReload\nto refresh your session.\nYou switched accounts on another tab or window.\nReload\nto refresh your session.\nDismiss alert\nUVADS\n/\nDS1001\nPublic\nNotifications\nYou must be signed in to change notification settings\nFork\n14\nStar\n7\nRepo for Foundations of Data Science\n7\nstars\n14\nforks\nBranches\nTags\nActivity\nStar\nNotifications\nYou must be signed in to change notification settings\nCode\nIssues\n0\nPull requests\n1\nActions\nProjects\n0\nSecurity\nUh oh!\nThere was an error while loading.\nPlease reload this page\n.\nInsights\nAdditional navigation options\nCode\nIssues\nPull requests\nActions\nProjects\nSecurity\nInsights\nUVADS/DS1001\nmain\nBranches\nTags\nGo to file\nCode\nOpen more actions menu\nFolders and files\nName\nName\nLast commit message\nLast commit date\nLatest commit\nHistory\n377 Commits\n.venv\n.venv\ncode\ncode\nddsbook\nddsbook\n.gitignore\n.gitignore\nREADME.md\nREADME.md\nrequirements.txt\nrequirements.txt\nView all files\nRepository files navigation\nREADME\nDS 1001: Think Like a Data Scientist (TLaDS)\nLogistics:\n* Lecture: Nau Hall 101, 2-3:15 pm Mon & Wed\n* Lab: Data Science 206 or 306 @ 12, 1, 2, or 3 pm\nInstructor Information:\n* Professor Brian Wright (brianwright@virginia.edu)\n* Office Hours: Tuesdays @ 2:00 - 4:00 pm, Data Science 434\n* TA Office Hours: Amelia and Anna on Monday 12:30-1:30pm. Aidan and Carissa on Friday 10:30am-11:30am\nMiscellaneous:\n* SIS Title: Foundation of Data Science\n* Subject Area and Catalog Number: Data Science, DS 1001\n* Year and Term: 2025 Spring\n* Level and Credit Type: Undergraduate, Grade (A-F)\nN.B. There is an associated lab class that must be enrolled simultaneously (50 minute Laboratory section, Friday @ 12, 1, 2, or 3 pm).\nA Little Bit About the Course\nThis course introduces students to a broad range of foundational topics and skills that form the data science pipeline. A central feature of the course is a guided, semester-long project that allows students to continuously apply what they learn in a practical context. Our guide will be the\nVirginia Model of Data Science\n. Students will engage with the material through lectures, small group discussions, hands-on lab activities, and guest presentations by industry experts, all designed to support and enrich their understanding and skills. Throughout the semester, students will learn to think like data scientists - approaching problems methodically, making evidence-based decisions, and applying analytical techniques to uncover insights. Students will develop a variety of competencies, including setting up a computing environment, creating data visualizations, developing research questions, building models, and examining biases throughout the data science process. In the final weeks, students will repeat this process independently by designing and executing their own project, reinforcing their skills and deepening their understanding through self-directed practice.\nWhat you’ll learn along the way\nPrime Learning Objective: You will be able to Think Like a Data Scientist (TLaDS). This starts with being able to define Data Science and explain it to friends and family, grows to being able to describe the field of Data Science and its emerging sub-fields, and finally approaching a problem as a data scientist in your final project.\nSecondary Objective: Identify how you see yourself in the field of Data Science. (Ranging from \"I love it and want a career\" to \"I hate it, never again\", our goal is for you to understand the mindset of Data Science and figure out if it is a path you want to follow).\nIn each of the areas we will specifically focus on:\nSystems\nStudents Will Be Able To\nexplain the components of a computer system and how they interact to support data science work.\nSWBAT compare hardware and software choices to choose the best tools for a problem.\nSWBAT use an IDE (Integrated Development Environment) to solve simple problems.\nDesign\nSWBAT create and interpret data representations using models, databases, graphics, and visualizations.\nSWBAT identify key experimental design choices that happen throughout the DS pipeline and how those choices impact the result.\nSWBAT use data summary and visualization tools to understand and describe a problem.\nAnalytics\nSWBAT define and give examples of a Data Science model.\nSWBAT describe the key types of Machine Learning and their uses.\nSWBAT distinguish between target/feature variables, identify true/predicted values, and interpret common evaluation metrics in a model.\nValue\nSWBAT describe the 5 Data & Society subfields and their relevance to data science practice.\nSWBAT analyze how responsibility for decisions is distributed across stages of the ML pipeline.\nSWBAT identify common sources of bias and error in data and models across the ML pipeline.\nHow You’ll Know You Are Learning (Assignments)\nEvery graded assignment in this class falls into one of 4 categories outlined below. Each assignment has a rubric to indicate the purpose, task, and criteria for the assignment. They are graded using the specifications grading system based on\nSpecifications Grading\nBy Linda Nilson. We will spend time in class to help you understand this system, especially if it is new for you.\nSpecifications Grading has been demonstrated to provide much greater equity in the classroom and as a result improves achievement of learning objectives. However this system may be new to you. It does take some time to understand and we are ready to help you with any questions you may have. Please take advantage of office hours. You can read more about the\nspecifications grading policy here\n.\nApproach\nThis course does not have exams or the concept of \"points\". Instead there are bundles of assignments, that when completed earn letter grades. Every individual assignment is marked as \"meets spec\" or \"does not meet spec yet\". In order to understand what \"meets spec\", every assignment is accompianed by a single-level rubric that outlines three things:\nThe purpose (Why am I doing this?)\nThe task (What am I going to do?)\nThe criteria (A detailed description of the necessary components of a \"meets spec\" submission)\nThe goal is to make the assignments as transparent as possible and not withold information from the students. For example in a traditional exam the students are told a list of subjects that may be on the test. The uncertainty causes anxiety and wastes an immense ammount of time. Instead of giving exams this class provides clear instruction on tasks to perform which yield the same result (mastery of learning objectives) without the anxiety and timewasting of studying for the unknown.\nBundles\nThe following table summarizes the assignmenmts required to \"meet spec\" to earn certain letter grades.\nCode\nAssignment Type\n#\nAvg. Time\nC\nB\nA\nLABS\nLabs\n12*\nIn class\n12\n12\n12\nREAD\n\"Read\" & Review\n12\n2 hours\n10\n11\n12\nCASE\nCase Study Assignment\n8\n8 hours\n--\n1\n3*\nFINL\nFinal Project\n1\n8 hours\n1\n1\n1\nWeekly Assignments\nThe LABS and READ assignments for each week are due that Friday at 11:59pm on Canvas every week.\nLABS - There are 12 labs and all grade bundles require completion of all 12 labs. They are designed to be done in class and may require some additional polishing done outside of class time. There is a make up lab day and any student may make up a lab that day for any reason, no excuse is necessary.\nREAD - The READ assignments are posted to Canvas a week before the due date and take less than two hours to complete. Late submissions are not accepted. Extenuating circumstances can be excused after discussion with Professor Wright during office hours. We suggest completion of these assignments well in advance of the deadline.\nAssignment Descriptions\nLABS - there is a lab section for this course and every student is expected to enroll and complete the lab assignments. The definition of \"lab\" is loose as the assignments performed in the lab sections vary. The goal is for the majority of the work to be done during the class lab period, but some final details like formatting and reflection may need to be done outside of class time.\n\"READ\" and Review - every week supplemental material will be posted to enhance the in class activities. This is not just reading but can also include other forms of media. The deliverable for this assignment is a short review and reflection.\nCASE Study Assignment - Each module has two case study assignments. These assignments are designed to dive deeper into material covered in class or to explore material not covered in class. They will require using external resources and some significant self-directed research. You’ll have some choice in the topics - so pick the ones that interest you most.\nFor the A bundle you can do 4 cases but no more to work to get 3 above spec, for the B bundle you can do 2\nFinal Project - This assignment is the your opportunity to synthesize the semester and show mastery of the primary learning objective \"thinking like a data scientist\". This will reflect the project work done throughout the semester.\nFlexibility\nLabs: There is a make up lab day at the end of the term where students can complete a lab they were unable to complete. No excuse is necessary.\nResubmission: After grading, weekly assignments (LABS & READ) marked \"does not meet spec, yet\" can be revised and resubmitted\nonce\nfor full credit. For some submissions that are far off the mark an office hour visit may be necessary before resubmission is granted.\nCASE and FINL assignments can not be revised.\nTech Stack (Course Delivery Tools)\nThere are several technological tools used in this class:\nEmail: Official communication from UVA is sent via UVA email\nCanvas: The official Learning Management System for this course is Canvas, all assignments are accessed, submitted, and graded through Canvas (including lab assignments). Course announcements will also be sent through Canvas, so make sure your notifications are turned on, or you are checking Canvas regularly. Assignments submitted outside of Canvas will not be accepted.\nPersonal Computer: We will using online tools, compiling documents, and doing some introductory coding in this class. Your laptop does not need any special hardware or software for our work.\nSchedule of Topics\nThis is a tentative schedule, subject to change.\nWeek\nSection\nDates\nLecture\nLab\n1\nIntro\nM X\nW 8/27\nF 8/29\nWhat is Data Science?\nX\n2\nSystems\nM 9/1\nW 9/3\nF 9/5\nSoftware\nVirtual Environments\nLABS-1: Hardware & Software\n3\nSystems\nM 9/8\nW 9/10\nF 9/12\nHardware\nKarsten Siller Guest Lecture\nLABS-2: GPU\n4\nSystems\n(project)\nM 9/15\nW 9/17\nF 9/19\nGitHub\nIDEs\nLABS-3: Systems\n5\nDesign\nM 9/22\nW 9/24\nF 9/26\nDS Lifecycle\nNur Yildirim Guest Lecture\nLABS-4: Projection\n6\nDesign\nM 9/29\nW 10/1\nF 10/3\nCarrie O'Brien Guest lecture\nData storytelling\nLABS-5: LUPI\n7\nDesign\n(project)\nM 10/6\nW 10/8\nF 10/10\nDS Lifecylce in Code\nUsing Data Viz\nLABS-6: Design\n8\nAnalytics\nM\nno class\nW 10/15\nF 10/17\nFALL BREAK\nWhat is ML? + Probability Video\nLABS-7: Random Variable Carnival\n9\nAnalytics\nM 10/20\nW 10/22\nF 10/24\nUnsupervised Learning\nSupervised Learning\nLABS-8: kNN on a Board\n10\nAnalytics\n(project)\nM 10/27\nW 10/29\nF 10/31\nModel development\nModel evaluation\nLABS-9: Analytics\n11\nValue\nM 11/3\nW 11/5\nF 11/7\nTBA\nTBA\nLABS-10: Evaluating the Implementation of ML: Decisions & Impacts\n12\nValue\nM 11/10\nW 11/12\nF 11/14\nML Fairness\nGuest Lecture: Prof Manny Moss\nLABS-11: GIGO\n13\nValue\n(project)\nM 11/17\nW 11/19\nF 11/21\nTBA\nTBA\nLABS-12: Value\n14\nProject\nM 11/24\nW\nno class\nF\nno class\nTBA\nTBA\nno lab\n15\nProject\nM 12/1\nW 12/3\nF 12/5\nTBA\nTBA\nLab Makeup Day\n16\nOutro\nM 12/8\nCourse Summary\nAdditional Dates\n9/5 - This is the first lab day and the first READ assignment is due.\n12/5 - Lab makeup day\n12/9 - Final due date for all assignments\nGuest Speakers\nSystems -\nProfessor Karsten Siller\nDesign - Carrie O'Brien: User Experience & Interface Designer at Capital One: Messaging, Web, and Human-Centered Design\nProfessor Nur Yildirim\nAnalytics - N/A\nValue -\nProfessor Brent Kitchens\nAdditional - TBD\nCourse Bibliography\nThink Like a Data Scientist\nChance, Logic, and Intuition by Tijms\nThe 4+1 Model of Data Science\nby Alvarado\n[\nhttps://arxiv.org/abs/2311.03292](Data\nScience from 1963 to 2012)\nThe Mathematical Theory of Communication by Shannon and Weaver\nAcademic Bibliography: (\nhttps://github.com/UVADS/DS1001/blob/main/Datalogy.bib\n)\nSystems\nFundamentals of Data Engineering\nby Reis and Housley\nDesign\nThe Design of Everyday Things by Norman\nHow charts lie : getting smarter about visual information\nObserve, Collect, Draw! by Lupi and Posavec\nAnalytics\nR for Data Science\nPython for Data Analysis\nProbability: Basic Probabilty by Tijms\nValue\nWeapons of Math Destruction\nA few policies that govern the class\nAttendance:\nLecture: Every student is responsible for the material covered in lecture. Attendence during lecture is expected and the material is integrated with the READ/LABS assignments that week and CASE Study assignments for that module. On Mondays READ & LABS assignments will be reviewed. On Wednesdays we will preview Friday's lab to show the connection between lecture and lab. In the event of a missed class we strongly advise reviewing the material before the next lab period (a friend's notes, office hours, etc.).\nLab assignments can only be completed in class on Friday (there is often special equipment and the need for a partner). There is a lab makeup day on the final Friday of classes during the normal lab times. No excuse is needed for a missed lab, you are already granted permission to make it up on makeup day.\nHonor:\nUniversity of Virginia Honor System: All work should be pledged in the spirit of the Honor System at the University of Virginia. The instructor will indicate which assignments and activities are to be done individually and which permit collaboration. For more information, visit\nwww.virginia.edu/honor\n.\nGenAI:\nGenerative AI (GenAI) tools can be a helpful part of your workflow when used well. Think of them like a study partner: great for clarifying questions, polishing wording, or giving feedback. What they shouldn’t do is replace your own learning, so it is inappropriate to ask it assignment questions, copy large sections of output, or pass off GenAI ideas as your own. A good rule of thumb: if you wouldn’t do it with a friend, don’t do it with GenAI. When in doubt, check with a TA or instructor.\nCourse Evaluations:\nStudent feedback is critical to the school, the instructor, and future students. Students are expected to complete anonymous and confidential course evaluations in a timely manner for each course at the end of each term.\nDiscrimination/Harassment/Retaliation:\nUVA prohibits discrimination and harassment\nbased on age, color, disability, family medical or genetic information, gender identity or expression, marital status, military status (which includes active duty service members, reserve service members, and dependents), national or ethnic origin, political affiliation, pregnancy (including childbirth and related conditions), race, religion, sex, sexual orientation, veteran status.\nUVA policy\nalso prohibits retaliation. All faculty and TAs are also responsible employees for disclosures or reports of potential discrimination, harassment, and retaliation.\nDisability and Pregnancy Accommodations:\nIf you anticipate or experience any barriers to learning in this course, please discuss your concerns with me. If you have a disability, or think you may have a disability, contact the Student Disability Access Center (“SDAC”) to request reasonable accommodation(s) for this course through their\nwebsite\n. If you have accommodations through SDAC, send me your Faculty Notification Letter as soon as possible and meet with me so we can develop an implementation plan together.\nStudents may be entitled to reasonable accommodations for pregnancy, childbirth, or related medical issues.  Please contact\nSDAC\nfor additional information. Pregnant and parenting students are encouraged to contact SDAC or EOCR to discuss plans and ensure ongoing access to their academic courses and program.  Information for pregnant and parenting students is also available on EOCR’s\nPregnancy and Parenting Resources webpage\n.\nReligious Academic Accommodations:\nUVA also provides reasonable accommodations when a student’s sincerely held religious beliefs or observances conflict with academic requirements. Students who wish to request an academic accommodation for a religious observance should submit their request to me by email as far in advance as possible.\nIf you have questions or concerns about your request, you may contact EOCR at\nUVAEOCR@virginia.edu\nor (434) 924-3200 or visit their Religious Accommodations webpage for additional information. Please note that receiving an accommodation does not relieve you of your responsibility to complete any coursework you miss as a result of the accommodation.\nReporting an Incident:\nJust Report It (JRI) is the University's online system for reporting:\nSexual and Gender-Based Harassment and Violence\nDiscrimination, Harassment, and Retaliation\nHazing\nClery Act Compliance (by CSAs)\nInterference with Speech Rights\nYouth Protection\nPreventing & Addressing Threats or Acts of Violence\nYou may access Confidential Resources if you wish to discuss a concern or incident without reporting to the University. Information you share with Confidential Resources will not be disclosed to University officials or any other person except in extremely limited circumstances. For more information on reporting an incident, visit this\nwebsite\n.\nStudent Mental Health and Wellbeing:\nThe University of Virginia is committed to advancing the mental health and wellbeing of its students, while acknowledging that a variety of issues directly impacts students’ academic performance. If you or someone you know is feeling overwhelmed, depressed, and/or in need of support, contact the CAPS Care Managers at\nCAPSCareMgrs@virginia.edu\n.\nFor help finding a community therapist, visit the\nCommunity Referrals\npage through CAPS.\nCare and Support Services (CASS) is a non-clinical resource available to all students providing emergency resources and support (withdrawing/returning to UVA, housing resources,  food insecurity, emergency funding, safety resources). The CASS team has a 24/7/365 phone line reserved for urgent non-clinical student needs that cannot wait until the next business day.\nMonday-Friday, 8 a.m. to 5 p.m.: (434) 924-7133\nAfter Hours: University Police Department: (434) 924-7166, ask for CASS on Call\nAbout\nRepo for Foundations of Data Science\nResources\nReadme\nUh oh!\nThere was an error while loading.\nPlease reload this page\n.\nActivity\nCustom properties\nStars\n7\nstars\nWatchers\n3\nwatching\nForks\n14\nforks\nReport repository\nReleases\nNo releases published\nPackages\n0\nNo packages published\nUh oh!\nThere was an error while loading.\nPlease reload this page\n.\nContributors\n4\nUh oh!\nThere was an error while loading.\nPlease reload this page\n.\nLanguages\nPython\n95.7%\nCython\n2.1%\nJupyter Notebook\n1.1%\nC++\n0.6%\nC\n0.5%\nTeX\n0.0%\nFooter\n© 2025 GitHub, Inc.\nFooter navigation\nTerms\nPrivacy\nSecurity\nStatus\nCommunity\nDocs\nContact\nManage cookies\nDo not share my personal information\nYou can’t perform that action at this time."}
{"url": "https://openstax.org/books/introduction-python-programming/pages/15-1-introduction-to-data-science", "text": "15.1 Introduction to data science - Introduction to Python Programming | OpenStax\nSkip to Content\nGo to accessibility page\nKeyboard shortcuts menu\nIntroduction to Python Programming\n15.1\nIntroduction to data science\nIntroduction to Python Programming\n15.1\nIntroduction to data science\nContents\nContents\nHighlights\nPrint\nSearch for key terms or text.\nSearch\nSearch\nClose\nSearch\nLearning objectives\nBy the end of this section you should be able to\nDescribe data science.\nIdentify different stages of the data science life cycle.\nName data science tools and software.\nUse Google Colaboratory to run code.\nData science life cycle\nData science\nis a multidisciplinary field that combines collecting, processing, and analyzing large volumes of data to extract insights and drive informed decision-making. The\ndata science life cycle\nis the framework followed by data scientists to complete a data science project. The data science life cycle is an iterative process that starts with data acquisition, followed by data exploration. The data acquisition stage may involve obtaining data from a source or collecting data through surveys and other means of data collection that are domain-specific. During the data exploration stage, data scientists will ensure that the data are in the right format for the data analysis stage through data cleanup and they may also visualize the data for further inspection. Once the data are cleaned, data scientists can perform data analysis, which is shared with stakeholders using reports and presentations. The\ndata analysis\nstage involves using data to generate insights or make a predictive model. Data science is increasingly being adopted in many different fields, such as healthcare, economics, education, and social sciences, to name a few. The animation below demonstrates different stages of the data science life cycle.\nCheckpoint\nData science life cycle\nAccess multimedia content\nConcepts in Practice\nWhat is data science?\n1\n.\nWhat is the first stage of any data science life cycle?\ndata visualization\ndata cleanup\ndata acquisition\n2\n.\nHow many stages does the data science life cycle have?\n3\n4\n5\n3\n.\nWhat does a data scientist do in the data exploration stage?\ndocument insights and visualization\nanalyze data\ndata cleaning and visualization\nData science tools\nSeveral tools and software are commonly used in data science. Here are some examples.\nPython programming language: Python is widely used in data science. It has a large system of libraries designed for data analysis, machine learning, and visualization. Some popular Python libraries for data science include NumPy, Pandas, Matplotlib, Seaborn, and scikit-learn. In this chapter, you will explore some of these libraries.\nR programming language: R is commonly used in statistical computing and data analysis, and it offers a wide range of packages and libraries tailored for data manipulation, statistical modeling, and visualization.\nJupyter Notebook/JupyterLab:\nJupyter Notebook\nand\nJupyterLab\nare web-based interactive computing environments that support multiple programming languages, including Python and R. They allow a programmer to create documents that contain code, visualizations, and text, making them suitable for data exploration, analysis, and reporting.\nGoogle Colaboratory:\nGoogle Colaboratory\nis a cloud-based Jupyter Notebook environment that allows a programmer to write, run, and share Python code online. In this chapter, you will use Google Colaboratory to practice data science concepts.\nKaggle Kernels:\nKaggle Kernels\nis an online data science platform that provides a collaborative environment for building and running code. Kaggle Kernels support Python and R and offers access to datasets, pre-installed libraries, and computational resources. Kaggle also hosts data science competitions and provides a platform for sharing and discovering data science projects.\nExcel/Sheets:\nMicrosoft Excel\nand\nGoogle Sheets\nare widely used spreadsheet applications that offer basic data analysis and visualization capabilities. They can help beginners get started with data manipulation, basic statistical calculations, and simple visualizations.\nCheckpoint\nGoogle Colaboratory ecosystem\nAccess multimedia content\nConcepts in Practice\nData science tools and software\n4\n.\nBetween Python, R, and Java, which is the most popular language in data science?\nPython\nR\nJava\n5\n.\nWhich of the following is a data science-related library in Python?\nlist\nNumPy\narray\n6\n.\nGoogle Colaboratory can be used for reporting and sharing insights.\ntrue\nfalse\nProgramming practice with Google\nOpen the Google Colaboratory document below. To open the Colaboratory document, you need to login to a Google account, if you have one, or create a Google account. Run all cells. You may also attempt creating new cells or modifying existing cells. To save a copy of your edits, go to \"File > Save a Copy in Drive\", and the edited file will be stored in your own Google Drive.\nGoogle Colaboratory document\nPrevious\nNext\nCitation/Attribution\nThis book may not be used in the training of large language models or otherwise be ingested into large language models or generative AI offerings without OpenStax's permission.\nWant to cite, share, or modify this book? This book uses the\nCreative Commons Attribution License\nand you must attribute OpenStax.\nAttribution information\nIf you are redistributing all or part of this book in a print format,\nthen you must include on every physical page the following attribution:\nAccess for free at https://openstax.org/books/introduction-python-programming/pages/1-introduction\nIf you are redistributing all or part of this book in a digital format,\nthen you must include on every digital page view the following attribution:\nAccess for free at\nhttps://openstax.org/books/introduction-python-programming/pages/1-introduction\nCitation information\nUse the information below to generate a citation. We recommend using a\ncitation tool such as\nthis one\n.\nAuthors: Udayan Das, Aubrey Lawson, Chris Mayfield, Narges Norouzi\nPublisher/website: OpenStax\nBook title: Introduction to Python Programming\nPublication date: Mar 13, 2024\nLocation: Houston, Texas\nBook URL:\nhttps://openstax.org/books/introduction-python-programming/pages/1-introduction\nSection URL:\nhttps://openstax.org/books/introduction-python-programming/pages/15-1-introduction-to-data-science\nÂ© Jul 30, 2024 OpenStax. Textbook content produced by OpenStax is licensed under a Creative Commons Attribution License .\nThe OpenStax name, OpenStax logo, OpenStax book covers, OpenStax CNX name, and OpenStax CNX logo\nare not subject to the Creative Commons license and may not be reproduced without the prior and express written\nconsent of Rice University.\nThis book utilizes the OpenStax Python Code Runner. The code runner is developed by Wiley and is All Rights Reserved.\nOpenStaxâs mission is to make an amazing education accessible for all.\nOpenStax is part of Rice University, which is a 501(c)(3) nonprofit.\nGive today\nand help us reach more students.\nHelp\nContact Us\nSupport Center\nFAQ\nSystem Status\nOpenStax\nPress\nNewsletter\nCareers\nPolicies\nAccessibility Statement\nTerms of Use\nLicensing\nPrivacy Policy\nÂ© 1999-2025, Rice University. Except where otherwise noted, textbooks on this site\nare licensed under a\nCreative Commons Attribution 4.0 International License\n.\nAdvanced Placement\nÂ®\nand AP\nÂ®\nare trademarks registered and/or owned by the College Board,\nwhich is not affiliated with, and does not endorse, this site."}
{"url": "https://dsc10.com/", "text": "🏠 Home | DSC 10\nSkip to main content\nLink\nSearch\nMenu\nExpand\nDocument\n(external link)\nDSC 10\n🏠 Home\n📖 Syllabus\n📆 Calendar\n📚 Resources\n🐞 Debugging\n👩‍🏫 Staff\nThis site uses\nJust the Docs\n, a documentation theme for Jekyll.\n🙋 Campuswire\n💯 Gradescope\n📌 Reference\n💪 Practice\n✅ CC\n🎥 Podcasts\nPrinciples of Data Science\nDSC 10, Fall 2025 at UC San Diego\nPeter Chi\nhe/him\npbchi@ucsd.edu\nLecture(s)\n: (D) MWF 9-9:50AM in\nPODEM 1A19\nJanine Tiefenbruck\nshe/her\njlobue@ucsd.edu\nLecture(s)\n: (A) MWF 9-9:50AM, (B) MWF 10-10:50AM, (C) MWF 11-11:50AM in\nPCYNH 106\nJump to the current week\nWeek 0 – Welcome to DSC 10!\nFri Sep 26\nLEC 1\nIntroduction\n💻 code\n✏️ write\nCIT 1.0-1.3\nKeywords:\ndata science, course structure, policies, syllabus, Little Women demo\nSat Sep 27\nSUR\nWelcome Survey\nSYL\nSyllabus Check\nWeek 1 – Python Basics\nMon Sep 29\nLEC 2\nExpressions and Data Types\n💻 code\n✏️ write\nBPD 1-6\nKeywords:\nJupyter notebooks, expressions, variables, assignment, functions, int, float\nDISC 1\nGetting Started with Jupyter Notebooks\nWed Oct 1\nLEC 3\nStrings, Lists, and Arrays\n💻 code\n✏️ write\nBPD 7-8\n,\nCIT 14.1\nKeywords:\nstring methods, mean, median, lists, arrays, array arithmetic\nPOD\nPod Meeting\nThu Oct 2\nPRE\nPretest\nLAB 0\nExpressions and Data Types\nFri Oct 3\nLEC 4\nArrays and DataFrames\n💻 code\n✏️ write\nBPD 9\nKeywords:\narray methods, np.arange, .read_csv, .get, .assign, .sort_values, .iloc, .loc, index\nWeek 2 – DataFrames and Visualization\nMon Oct 6\nLEC 5\nQuerying and Grouping\n💻 code\n✏️ write\nBPD 10-11\nKeywords:\n.set_index, Booleans, querying, .shape, &, |, .take, .groupby, aggregation\nDISC 2\nArrays and DataFrames\nWed Oct 8\nLEC 6\nGrouping and Data Visualization\n💻 code\n✏️ write\nCIT 7.0-7.1\nKeywords:\n.groupby, numerical vs. categorical, scatter plot, line plot, bar chart\nPOD\nPod Meeting\nThu Oct 9\nLAB 1\nArrays and DataFrames\nFri Oct 10\nLEC 7\nDistributions and Histograms\n💻 code\n✏️ write\nCIT 7.2-7.3\nKeywords:\ndistributions, density histograms, binning, total area, overlaid plots\nSat Oct 11\nHW 1\nBasic Python, Arrays, and DataFrames\nWeek 3 – Functions and Control Flow\nMon Oct 13\nLEC 8\nFunctions and Applying\n💻 code\n✏️ write\nBPD 6\n,\n12\nKeywords:\nfunctions, arguments, print vs. return, .apply, .reset_index\nDISC 3\nQuerying, Grouping, and Plotting\nWed Oct 15\nLEC 9\nGrouping on Multiple Columns, Merging\n💻 code\n✏️ write\nBPD 11\n,\n13\nKeywords:\n.groupby([col_1, col_2, …]), subgroups, MultiIndex, .merge, number of rows\nQUIZ 1\nQuiz 1 covers Lectures 1-5\nThu Oct 16\nLAB 2\nData Visualizations and Functions\nFri Oct 17\nLEC 10\nConditional Statements and Iteration\n💻 code\n✏️ write\nCIT 9.0-9.2\nKeywords:\nin, not, and, or, if, else, elif, for-loops, np.append, accumulator pattern\nSat Oct 18\nHW 2\nDataFrames, Data Visualization, and Functions\nWeek 4 – Probability and Simulation\nMon Oct 20\nLEC 11\nProbability\n✏️ write\n🕘 A\n🕙 B\n🕚 C\nCIT 9.5\nKeywords:\nevent, conditional prob., multiplication and addition rules, independence\nDISC 4\nFunctions, DataFrames, and Control Flow\nWed Oct 22\nLEC 12\nSimulation\n💻 code\n✏️ write\nCIT 9.3-9.4\nKeywords:\nnp.random.choice, replacement, np.count_nonzero, coin flipping, Monty Hall\nQUIZ 2\nQuiz 2 covers Lectures 6-10\nThu Oct 23\nLAB 3\nDataFrames, Control Flow, and Probability\nFri Oct 24\nLEC 13\nDistributions and Sampling\n💻 code\n✏️ write\nCIT 10.0-10.4\nKeywords:\nprobability vs. empirical distribution, SRS, .sample, parameter, statistic\nSat Oct 25\nHW 3\nDataFrames, Control Flow, and Probability\nSUR\nMid-Quarter Survey\nWeek 5 – Midterm Exam\nMon Oct 27\nREV\nMidterm Review\n✏️ write\n🕘 A\n🕙 B\n🕚 C\nDISC 5\nProbability and Simulation\nWed Oct 29\nEXAM\nMidterm Exam covers Lectures 1-12\nPOD\nPod Meeting\nFri Oct 31\nLEC 14\nBootstrapping and Confidence Intervals\n💻 code\n✏️ write\nCIT 13.0-13.2\nKeywords:\ninference, bootstrapping, resample, np.percentile, confidence interval\nSat Nov 1\nPROJ\nMidterm Project\nWeek 6 – Confidence Intervals and the Normal Distribution\nMon Nov 3\nLEC 15\nConfidence Intervals, Center, and Spread\n💻 code\n✏️ write\nCIT 13.3-13.4\nKeywords:\ninterpreting CIs, robust vs. sensitive, center, standard deviation\nDISC 6\nSampling, Bootstrapping, and Confidence Intervals\nWed Nov 5\nLEC 16\nStandardization and the Normal Distribution\n💻 code\n✏️ write\n🎥 watch\nCIT 14.2-14.3\nKeywords:\nChebyshev, standard units, normal distribution, CDF, inflection points\nPOD\nPod Meeting\nThu Nov 6\nLAB 4\nSimulation, Sampling, & Bootstrapping\nFri Nov 7\nLEC 17\nThe Central Limit Theorem\n💻 code\n✏️ write\nCIT 14.4-14.5\nKeywords:\ndistribution of the sample mean, square root law, CLT-based CIs\nSat Nov 8\nHW 4\nSimulation, Sampling, Bootstrapping\nWeek 7 – Hypothesis Testing\nMon Nov 10\nLEC 18\nChoosing Sample Sizes, Statistical Models\n💻 code\n✏️ write\nCIT 14.6\n,\n11.1\nKeywords:\nstandard deviation of 0s and 1s, np.random.multinomial, Robert Swain jury\nDISC 7\nStandardization and the Normal Distribution\nWed Nov 12\nLEC 19\nHypothesis Testing\n💻 code\n✏️ write\nCIT 11.3\nKeywords:\nnull and alternative hypotheses, test statistic, fair or unfair coin\nQUIZ 3\nQuiz 3 covers Lectures 13-15\nThu Nov 13\nLAB 5\nVariability and the Normal Distribution\nFri Nov 14\nLEC 20\nHypothesis Testing and Total Variation Distance\n💻 code\n✏️ write\nCIT 11.2\n,\n11.4\nKeywords:\nfair or unfair coin, p-value, midterm exam scores, Alameda County jury, TVD\nSat Nov 15\nHW 5\nThe Normal Distribution and the Central Limit Theorem\nWeek 8 – Hypothesis and Permutation Testing\nMon Nov 17\nLEC 21\nTVD, Hypothesis Testing, and Permutation Testing\n💻 code\n✏️ write\nCIT 12.0-12.1\nKeywords:\nconfidence intervals for hypothesis testing, body temperature, smoking/babies\nDISC 8\nThe CLT and Hypothesis Testing\nWed Nov 19\nLEC 22\nPermutation Testing\n💻 code\n✏️ write\nCIT 12.3\nKeywords:\nsmoking/babies, np.random.permutation, shuffling, Deflategate\nQUIZ 4\nQuiz 4 covers Lectures 16-18\nThu Nov 20\nLAB 6\nHypothesis Testing\nFri Nov 21\nLEC 23\nCorrelation\n💻 code\n✏️ write\nCIT 15.0-15.2\nKeywords:\nassociation, correlation coefficient (r), predicting heights, regression line (su)\nWeek 9 – Prediction\nMon Nov 24\nLEC 24\nRegression and Least Squares\n💻 code\n✏️ write\nCIT 15.2-15.4\nKeywords:\nregression line in original units, outliers, errors, RMSE, best fit, least squares\nDISC 9\nTotal Variation Distance and Permutation Testing\nTue Nov 25\nHW 6\nHypothesis Testing and Permutation Testing\nWed Nov 26\nLEC 25\nResiduals and Inference\n💻 code\n✏️ write\nCIT 15.5-16.3\nKeywords:\nresiduals, residual plots, patterns, datasaurus dozen, prediction intervals\nFri Nov 28\nNo Lecture (Thanksgiving Break🦃)\nWeek 10 – Review\nMon Dec 1\nREV\nReview\n✏️ write\n🕘 A\n🕙 B\n🕚 C\nDISC 10\nRegression\nWed Dec 3\nREV\nReview\n✏️ write\n🕘 A\n🕙 B\n🕚 C\nQUIZ 5\nQuiz 5 covers Lectures 19-22\nThu Dec 4\nPROJ\nFinal Project\nLAB 7\nRegression\nFri Dec 5\nREV\nReview, Conclusion\n💻 code\n✏️ write\n🕘 A\n🕙 B\n🕚 C\nSat Dec 6\nEXAM\nFinal Exam (3-6PM)\nSUR\nSETs and End-of-Quarter Survey (due 8AM)"}
{"url": "https://mine-cr.com/teaching/sta199/", "text": "STA 199 - Introduction to Data Science | Mine Çetinkaya-Rundel\nAbout\nProjects\nTeaching\nPublications\nTalks\nBlog\nCV\nSTA 199 - Introduction to Data Science\nDuke University\nFall 2025\nFall 2024\nSpring 2024\nFall 2022\nSpring 2018\nIntro to data science and statistical thinking. Learn to explore, visualize, and analyze data to understand natural phenomena, investigate patterns, model outcomes, and make predictions, and do so in a reproducible and shareable manner. Gain experience in data wrangling and munging, exploratory data analysis, predictive modeling, and data visualization, and effective communication of results. Work on problems and case studies inspired by and based on real-world questions and data. The course will focus on the R statistical computing language.\nThe materials for this course are licensed under a\nCreative Commons Attribution-NonCommercial 4.0 International License\n.\nPosted on:\nJanuary 1, 2024\nLength:\n1 minute read, 94 words\nCategories:\ncourse\ndata-science\nSee Also:\nSTA 313 - Advanced Data Visualization →\n© 2025 Mine Çetinkaya-Rundel\nMade with\nHugo Apéro\n.\nBased on\nBlogophonic\nby\nFormspree\n.\nLicense\nContact"}
{"url": "https://www.ucladatascienceed.org/introduction-to-data-science-curriculum", "text": "Introduction to Data Science Curriculum | Introduction to Data Science\nHome\nCurriculum\nIDS Curriculum\nTechnology Suite\nPartnership\nPartnership\nList of Partners\nProfessional Development\nProfessional Development\nPD Calendar\nFacilitators\nIDS News\nIDS News\nPublications & Presentations\nIDS Blog\nAbout IDS\nContact Us\nVision\nHistory\nContributors\nIntroduction to Data Science Curriculum\nIntroduction to Data Science (IDS) Curriculum teaches students to reason with, and think critically about, data in all forms. The Common Core State Standards (CCSS) for High School Statistics and Probability relevant to data science are taught along with the data demands of good citizenship in the 21st century. Additionally, IDS provides access to rigorous learning that fuses mathematics with computer science through the use of R/RStudio, an open-source programming language/environment that has long been the standard for academic statisticians and analysts in industry.\nIDS is a “c”-approved mathematics course\nin the\nUniversity of California A-G requirements\n. IDS directly addresses the CCSS-Math for High School Statistics and Probability and Practice for Modeling.\nWe invite you to download and review our\ncurriculum\n.\nCurriculum Overview\nUnit #\nTitle\nDescription\nUnit 1\nData and Visualizations\nIntroduces students to fundamental notions of data analysis—such as distribution and multivariate associations and emphasizes creating and interpreting visualizations of real-world processes as captured by data\nUnit 2\nDistributions, Probability, and Simulations\nStudents use numerical summaries to describe distributions and introduces probability through the lens of computer simulations for informal inference\nUnit 3\nData Collection Methods: Traditional and Modern\nPrepares students to learn about the various ways of collecting data, including Participatory Sensing, and the effect that data collection has on their interpretation of the patterns they discover\nUnit 4\nPredictions and Models\nStudents learn to make and how to use mathematical and statistical models to predict future observations and how data scientists measure the success of these predictions\nD\nDownload the IDS Curriculum\n4\nCCSS-Math addressed by IDS\n(\nTest Drive Our Technology\n5\nIDS Topic Outline\n4\nIDS Table of Contents\nu\nIDS Essential Concepts Outline\n%\nIDS Participatory Sensing Campaigns\nFood Habits\nTime Use\nStress-Chill\n</table align=”center”>\n\"After a semester of taking IDS I have learned how to code and answer statistical questions that apply to real life.\"\n\"IDS has actually made math easy for me to do. It has taught me how to code and use graphs. IDS gives me a better visual on math.\"\n\"Through charts and graphs it is easier to break down the mathematics of the class.\"\n- Students\n\"I had a bad experience managing groups in the past. IDS has helped me manage groups better and be more confident overall.\"\n- Teacher\n\"[IDS is] helping me understand math by graphing my own data.\"\n\"I see this fitting for my future because it uses data and analyzing data in our daily life.\"\n- Students\n\"I like the list of Instructional Strategies and discovering how they use them in the curriculum. It inspires me use them in my non-IDS classes!\"\n\"IDS has made me excited about teaching again. It is great to work with a class that is applicable and meaningful.\"\n- Teachers\n\"IDS has made me more aware of how data is collected in various ways. This class has been really eye opening [on] to collect data.\"\n\"I see IDS fitting into my future...I am able to put IDS on my college application, and if I would ever want to go into computers as a career I would already know how to code.\"\n- Students\n\"This class can benefit me in college, internship and work. I think I might use this code professionally in the future if RStudio advances.\"\n\"Coding is easier, it makes math easier than before.\"\n- Students\n\"Teaching IDS has continued to show me that I am a lifelong learner in the content area of math. Observing my students see math in the tangible real life context with everyday activities involving their electronic devices has allowed me to see the kind of connection and engagement that is not frequently seen in the traditional curriculum of mathematics. Overall, teaching this curriculum has been an eye-opening experience with increased student engagement.\"\n- Teacher\n\"IDS has allowed me to view statistics in the world of business, and has showed me how math is applied in the real world today.\"\n\"One thing I know now that I did not know before is that to code we have to be very precise.\"\n- Students\n\"IDS has taught me how to analyze different graphs and frequency tables. Also, I learned about the data cycle and how it's used in our lives.\"\n\"I think this class will help [me] with future jobs or get into a better college.\"\n- Students\n\"[IDS] has stimulated me as a teacher - especially the coding part. It has made me and my students pay attention [to the] real and true essence and value of data and the data process.\"\n- Teacher\n\"IDS has taught me how to code and learn a new style of math. I now know how to code and ask statistical questions. IDS is helping me understand math in a new way by being able to code and use a computer. IDS doesn't only help with math, but on how to use a computer.\"\n- Student\n\"IDS connects real social and current issues with math curriculum. It's brought more relevance to the math classroom. The IDS curriculum emphasizes that there is more than one way to answer a question - aligning it to the Common Core standards. It's an amazing class.\"\n- Teacher\nReviews\nVideo\nContact Us\nLeave Your Comment\n© 2022\nThis material is based upon work supported by the National Science Foundation under Grant Number 0962919. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.\n@uclaIDS\nParent Survey\nFirst Name\nLast Name\nEmail\nState\n---\nAlabama\nAlaska\nArizona\nArkansas\nCalifornia\nColorado\nConnecticut\nDelaware\nFlorida\nGeorgia\nHawaii\nIdaho\nIllinois\nIndiana\nIowa\nKansas\nKentucky\nLouisiana\nMaine\nMaryland\nMassachusetts\nMichigan\nMinnesota\nMississippi\nMissouri\nMontana\nNebraska\nNevada\nNew Hampshire\nNew Jersey\nNew Mexico\nNew York\nNorth Carolina\nNorth Dakota\nOhio\nOklahoma\nOregon\nPennsylvania\nRhode Island\nSouth Carolina\nSouth Dakota\nTennessee\nTexas\nUtah\nVermont\nVirginia\nWashington\nWest Virginia\nWisconsin\nWyoming\nWho benefitted from the application of data science\n---\nMyself\nMy child\nOther\nYour message\nΔ\n×\nIntroduction to Data Science - About IDS\nCLOSE\nContact Us\nName\nEmail\n*\nMessage\nreCAPTCHA\nIf you are human, leave this field blank.\nSubmit\nΔ\n×\nCourse Overview\nIntroduction to Data Science – Course Overview\nUnit\nUnit Title\nUnit Description\nUnit1\nData and Visualizations\nIntroduces students to fundamental notions of data analysis—such as distribution and multivariate associations and emphasizes creating and interpreting visualizations of real-world processes as captured by data\nUnit2\nDistributions, Probability, and Simulations\nStudents use numerical summaries to describe distributions and introduces probability through the lens of computer simulations for informal inference\nUnit3\nData Collection Methods: Traditional and Modern\nPrepares students to learn about the various ways of collecting data, including Participatory Sensing, and the effect that data collection has on their interpretation of the patterns theydiscover\nUnit4\nPredictions and Models\nStudents learn to make and how to use mathematical and statistical models to predict future observations and how data scientists measure the success of these predictions\n×"}
{"url": "https://amplab.github.io/datascience-sp14/", "text": "Introduction to Data Science\nCS 194-16 Introduction to Data Science - UC Berkeley, Spring 2014\nOrganizations use their data for decision support and to build data-intensive\nproducts and services. The collection of skills required by organizations to\nsupport these functions has been grouped under the term Data Science. This\ncourse will attempt to articulate the expected output of Data Scientists and\nthen equip the students with the ability to deliver against these expectations.\nThe assignments will involve web programming, statistics, and the ability to\nmanipulate data sets with code.\nLogistics\nCourse Number: CS 194-16, CS 294-16 Spring 2014, UC Berkeley\nInstructor:\nMike Franklin\nTime: Monday, 5.30pm - 8.30pm\nLocation: 145 Moffit\nTeaching Assistants: Daniel Bruckner, Evan Sparks and Shivaram Venkataraman\nDiscussion: Join\nPiazza\nfor\nannouncements and to ask questions about the course\nOffice hours:\nMike Franklin - T 3.30-4.30, Th 2.30-3.30 at 449 Soda\nGSIs - M 2-3 at 449 Soda, W 11-12 at 751 Soda\nPre-requisites\nPre-requisites for this course include 61A, 61B, 61C and basic programming\nskills. Knowledge of Python will be useful for the assignments. Students\nwill also be expected to run\nVirtualBox\non their laptops\nfor the assignments.\nPlease take the class survey\nhere\n.\nPlese set up your machine according to\nthese instuctions\n.\nGrading\nClass Participation and in-class labs: 20%\nMidterm: 20%\nFinal Project (in groups): 25%  Final Project Information is\nHere\nHomeworks : 30%  (3 @ 10% each:\nHomework 1\n;\nHomework 2\n; Homework 3)\n“Bunnies” : 5%\nSchedule\nClass Date\nLecture Material\nReading\nAssignments\nM 1/27\nL1: Introduction/Data Science Process\n[PPTX]\n[PDF]\nM 2/3\nL2: Data Preparation  (w/Unix Shell Lab)\n[PPTX]\n[PDF]\nEnterprise Data Analysis and Visualization: An Interview Study\nBunny 1\nby 5pm on 2/3\nLab 1\nM 2/10\nL3: Tabular Data (w/Pandas Lab)\n[PPTX]\n[PDF]\nFrom Databases to Dataspaces: A New Abstraction for Information Management\nSchemaless SQL\nand\nSchema on Write vs. Schema on Read\nBunny 2\nby 5pm on 2/10\nLab 2\nF 2/14\nHomework 1\nout. Due by 2/28\nM 2/17\nNo class - President's Day\nM 2/24\nL4: Data Cleaning (w/Open Refine Lab)\n[PPTX]\n[PDF]\nLab 3\nF 2/28\nHomework 1\nDue! Submit using glookup\nM 3/3\nL5: Part 1 - Guest Lecture:\nJosh Wills, Director of Data Science, Cloudera\n; followed by:\nPart 2- Data Integration (w/Pandas)\n[PPTX]\n[PDF]\nWebTables: Exploring the Power of Tables on the Web (Sections 1,2 and 4; others optional)\nand\nOpenRefine Data Augmentation (video)\nBunny 3\nby 5pm;\nLab 4\nFinal Project Group Lists\nDue Midnight\nM 3/10\nL6: Exploratory Data Analysis (with Python lab)\n[PPTX]\n[PDF]\nStatistical Thinking in the Age of Big Data\nExploratory Data Analysis\nFrom the O'Reilly Book \"Doing Data Science\" - available on campus or via the library VPN.\nIntroduction to Hypothesis Testing\nBunny 4\nby 5pm;\nLab 5\nFinal Project Proposals due Tues 3/11 Midnight.\nT 3/11\nHomework 2\nout. Due by 4/1\nM 3/17\nL7: Regression, Classification, intro to Supervised Learning (with R Lab)\nPart 1:\n[PPTX]\n[PDF]\nPart 2:\n[PPTX]\n[PDF]\nHomework Tips\nThree Basic Algorithms\nFrom the O'Reilly Book \"Doing Data Science\" - available on campus or via the library VPN.\nBunny 5\nby 5pm\nLab 6\nM 3/24\nNo Lecture: Spring Break\nM 3/31\nL8: Part 1 - Guest Lecture:\nPeter Skomoroch\n; Slides:\n[PDF](29MB)\n; followed by:\nPart2 -\nUnsupervised Learning and K-Means Clustering\n(in Python)\nK-Nearest Neighbors and K-Means clustering from\nThree Basic Algorithms\n.\nPart of the O'Reilly Book \"Doing Data Science\" - available on campus or via the library VPN.\nNo Bunny !\nLab 7\nT 4/1\nHomework 2\nDue. Submit using glookup\nM 4/7\nL9: Scaling Up Analytics (with Spark/EC2 Lab); Guest Lecturer:\nKay Ousterhout\n[PDF]\n[PPTX]\n\"MapReduce,\" \"Word Frequency Problem\", and \"Other Examples of MapReduce\" sections from O'Reilly \"Doing Data Science\" book (available\nonline\nor from the library) and\nSpark Short paper\nBunny 9\nby 5pm\nLab 8\nHomework 3, Part 1\nDue 4/14\nF 4/11\nFinal Project update due on glookup\nM 4/14\nL10: Visualization (D3 lab)\n[PPTX]\n[PDF]\nLab Slides\nChapter 9 on Data Visualization\nfrom \"Doing Data Science\" available online or from the library.\nD3: Data Driven Documents\nby Bostock et. al.\nOptional:\nReading about how the challenger disaster may have been prevented with data visualization\nby Edward Tufte\nBunny 10\nby 5pm\nHomework 3, Part 1\ndue\nLab 9\nTh 4/17\nMidterm - 6.00 to 7.30 pm\nF 4/18\nHomework 3, Part 2\nout.  Due by 4/25.\nM 4/21\nL11: Graph Processing (with GraphX Lab); Guest Lecturers:\nJoey Gonzalez\nand\nDan Crankshaw\n[PPTX]\n(19MB)\n[PDF]\n(19MB)\nChapter 2\nfrom \"Networks, Crowds, and Markets: Reasoning About a Highly Connected World\"\nBunny 11\nby 5pm\nLab 10\nF 4/25\nHomework 3, Part 2\ndue\nM 4/28\nL12: Putting it All Together\nBunny 12\nby 5pm"}
{"url": "https://github.com/doanthevu1910/uva-introduction-data-science", "text": "GitHub - doanthevu1910/uva-introduction-data-science: Introduction Data Science: Data Preprocessing (6011P0286Y)\nSkip to content\nNavigation Menu\nToggle navigation\nSign in\nAppearance settings\nPlatform\nAI CODE CREATION\nGitHub Copilot\nWrite better code with AI\nGitHub Spark\nBuild and deploy intelligent apps\nGitHub Models\nManage and compare prompts\nMCP Registry\nNew\nIntegrate external tools\nDEVELOPER WORKFLOWS\nActions\nAutomate any workflow\nCodespaces\nInstant dev environments\nIssues\nPlan and track work\nCode Review\nManage code changes\nAPPLICATION SECURITY\nGitHub Advanced Security\nFind and fix vulnerabilities\nCode security\nSecure your code as you build\nSecret protection\nStop leaks before they start\nEXPLORE\nWhy GitHub\nDocumentation\nBlog\nChangelog\nMarketplace\nView all features\nSolutions\nBY COMPANY SIZE\nEnterprises\nSmall and medium teams\nStartups\nNonprofits\nBY USE CASE\nApp Modernization\nDevSecOps\nDevOps\nCI/CD\nView all use cases\nBY INDUSTRY\nHealthcare\nFinancial services\nManufacturing\nGovernment\nView all industries\nView all solutions\nResources\nEXPLORE BY TOPIC\nAI\nSoftware Development\nDevOps\nSecurity\nView all topics\nEXPLORE BY TYPE\nCustomer stories\nEvents & webinars\nEbooks & reports\nBusiness insights\nGitHub Skills\nSUPPORT & SERVICES\nDocumentation\nCustomer support\nCommunity forum\nTrust center\nPartners\nOpen Source\nCOMMUNITY\nGitHub Sponsors\nFund open source developers\nPROGRAMS\nSecurity Lab\nMaintainer Community\nAccelerator\nArchive Program\nREPOSITORIES\nTopics\nTrending\nCollections\nEnterprise\nENTERPRISE SOLUTIONS\nEnterprise platform\nAI-powered developer platform\nAVAILABLE ADD-ONS\nGitHub Advanced Security\nEnterprise-grade security features\nCopilot for Business\nEnterprise-grade AI features\nPremium Support\nEnterprise-grade 24/7 support\nPricing\nSearch or jump to...\nSearch code, repositories, users, issues, pull requests...\nSearch\nClear\nSearch syntax tips\nProvide feedback\nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancel\nSubmit feedback\nSaved searches\nUse saved searches to filter your results more quickly\nName\nQuery\nTo see all available qualifiers, see our\ndocumentation\n.\nCancel\nCreate saved search\nSign in\nSign up\nAppearance settings\nResetting focus\nYou signed in with another tab or window.\nReload\nto refresh your session.\nYou signed out in another tab or window.\nReload\nto refresh your session.\nYou switched accounts on another tab or window.\nReload\nto refresh your session.\nDismiss alert\ndoanthevu1910\n/\nuva-introduction-data-science\nPublic\nNotifications\nYou must be signed in to change notification settings\nFork\n0\nStar\n1\nIntroduction Data Science: Data Preprocessing (6011P0286Y)\nstudiegids.uva.nl/xmlpages/page/2021-2022-en/search-course/course/92138\n1\nstar\n0\nforks\nBranches\nTags\nActivity\nStar\nNotifications\nYou must be signed in to change notification settings\nCode\nIssues\n0\nPull requests\n0\nActions\nProjects\n0\nSecurity\nUh oh!\nThere was an error while loading.\nPlease reload this page\n.\nInsights\nAdditional navigation options\nCode\nIssues\nPull requests\nActions\nProjects\nSecurity\nInsights\ndoanthevu1910/uva-introduction-data-science\nmain\nBranches\nTags\nGo to file\nCode\nOpen more actions menu\nFolders and files\nName\nName\nLast commit message\nLast commit date\nLatest commit\nHistory\n6 Commits\nassignment-1\nassignment-1\nassignment-2\nassignment-2\n.gitkeep\n.gitkeep\nREADME.md\nREADME.md\nView all files\nRepository files navigation\nREADME\nuva-introduction-data-science\nIntroduction Data Science: Data Preprocessing (6011P0286Y)\nAbout\nIntroduction Data Science: Data Preprocessing (6011P0286Y)\nstudiegids.uva.nl/xmlpages/page/2021-2022-en/search-course/course/92138\nTopics\nuniversity-of-amsterdam\nResources\nReadme\nUh oh!\nThere was an error while loading.\nPlease reload this page\n.\nActivity\nStars\n1\nstar\nWatchers\n1\nwatching\nForks\n0\nforks\nReport repository\nReleases\nNo releases published\nPackages\n0\nNo packages published\nLanguages\nR\n100.0%\nFooter\n© 2025 GitHub, Inc.\nFooter navigation\nTerms\nPrivacy\nSecurity\nStatus\nCommunity\nDocs\nContact\nManage cookies\nDo not share my personal information\nYou can’t perform that action at this time."}
{"url": "http://www.data8.org/", "text": "Data 8 | Foundations of Data Science\nData 8: The Foundations of Data Science\nCourse Description\nThe UC Berkeley Foundations of Data Science course combines three perspectives:\ninferential thinking, computational thinking, and real-world relevance. Given\ndata arising from some real-world phenomenon, how does one analyze that data so\nas to understand that phenomenon? The course teaches critical concepts and\nskills in computer programming and statistical inference, in conjunction with\nhands-on analysis of real-world datasets, including economic data, document\ncollections, geographical data, and social networks. It delves into social and legal issues surrounding data analysis, including issues of privacy and data ownership.\nOfferings\nFall 2025\nSummer 2025\nSpring 2025\nFall 2024\nSummer 2024\nSpring 2024\nFall 2023\nSummer 2023\nSpring 2023\nFall 2022\nSummer 2022\nSpring 2022\nFall 2021\nSummer 2021\nSpring 2021\nFall 2020\nSummer 2020\nSpring 2020\nFall 2019\nSummer 2019\nSpring 2019\nFall 2018\nSummer 2018\nSpring 2018\nFall 2017\nSummer 2017\nSpring 2017\nFall 2016\nSpring 2016\nFall 2015\nMaterials\nIt has been our vision since the beginning of Data 8 that these materials are publicly licensed as open educational resources. Most repositories are licensed with\nMIT\n,\nBSD\n, or\nCC\nlicenses which makes them free to use and adapt. However, the textbook is licensed with\nCC BY-NC-ND 4.0\nwhich allows free sharing of the material, but does not allow for the distribution of derived material.\nTextbook\n:\nComputational and Inferential Thinking: The Foundations of Data\nScience\nis a free online textbook that\nincludes interactive Jupyter notebooks and public data sets for all examples.\nThe textbook source is maintained on\nthis GitHub\n.\nAssignments\n:\nAll assignments for all offerings are available in the\nData 8 GitHub Organization\n, typically in\nmaterials-semYY\nrepositories as Jupyter Notebooks.\nThe notebooks assume a Python 3 installation with the standard modules from\nan Anaconda\ninstallation\nsuch as Numpy and Matplotlib,\nas well as the\ndatascience\nand, depending on the year,\nokpy\nor\notter-grader\nmodules.\nLecture Materials\n: All lecture videos, slides and demonstration notebooks from\nFall\n2016\nto current iterations of the course are available via links on the respective course calendars.\nTo request access to the source of the slides for\ninstructional purposes, please fill out our\nData 8 Instructor\nInterest\nform.\nInfrastructure\nAll of the software components of the course are maintained as open-source\nprojects. We encourage you to contact us if you want any help using them.\nWe also have prepared\na guide on how to set up course\ninfrastructure\n.\nThe\ndatascience\nmodule\n: The course uses a module\nfor table manipulation, charts, and maps that provides an interface appropriate\nfor an introductory course. The\nTable\nclass is similar to a\nDataFrame\nin\nPandas\n, but explicitly does not support row\nindexes, hierarchical indexes, time series data, missing values, slicing, and\nmany other advanced features that can complicate table manipulation for novices.\nThe charting features use Matplotlib, but customize the output to match the\npedagogical goals of the course. The mapping features are implemented by\nFolium\n, but aim to simplify\nworking with tables and geojson files. While the\ndatascience\nmodule can\ncertainly be used outside the context of the course, it was specifically\ndesigned to support the Data 8 curriculum, while setting up students to\ntransition to more standard tools such as Pandas.\nThe\notter-grader\nautomatic grading software\n: All notebooks are created using the otter-grader notebook creation format. This software generates two notebooks from a parent notebook. The first contains only “public” tests that are used to help students evaluate whether or not solutions to questions are correct – a type of client-side validation for the student. The second notebook contains solutions as well as “private” tests that students are not able to see. These tests are usually used to evaluate correctness and edge cases as well as assign points.  This system is used in conjuction with\nGradescope\nat Berkeley to grade and assign points to student work but an instructor is also able grade notebooks on their own machines, see the documentation at\notter-grader\n, as well as use a free service that we deployed called\notter-service-standalone\n.\nHosted Computing Environment\n:\nWe provide a hosted environment for our students to edit and execute their\nNotebooks: DataHub. DataHub is a tool that utilizes cloud computing infrastructure to deploy scalable resources that enable users to interact remotely with a standardized, common computing environment.\nAll students have access to the exact same computing environment and resources. As of Summer 2025, the\nData 8 Specific Datahub\nhas restricted access for only students enrolled in the current or previous semester’s offering of Data 8. The\ngeneral purpose DataHub\nis still available to all UC Berkeley students, staff, and faculty.\nIf you want more information about any of these materials or tools, please fill out our\nData\n8\nInterest\nform or email\nds-courses@berkeley.edu\n.\nAccessibility\nNondiscrimination\nCopyright ©2025, Regents of the University of California and respective authors."}
